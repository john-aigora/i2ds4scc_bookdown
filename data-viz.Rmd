```{r include=FALSE}
knitr::opts_chunk$set(echo = TRUE, eval = TRUE)
```

# Data Visualization {#data-viz}

Tables and graphs are the two fundamental vehicles to communicate information clearly and effectively. They are useful visual elements to summarize and organize information to show patterns and relationships. Tables and graphs allow the audience/reader to easily and quickly get a clear idea of the data findings, make comparisons, get insights from it and ultimately, draft conclusions without much effort.

The best medium of communication, whether a table, a bar chart, a line chart, or a radar plot, will highly depend on the type of data, the amount of data to be displayed (e.g. number of attributes or samples), and the purpose of the analysis. Usually, tables are meant to be read, so they are ideal when you have data that can not easily be presented by other communication elements, or when the data requires more specific attention. However, if you encounter a situation where you have a very long and/or wide table, which is common to see in QDA results, where the average and postdoc test are displayed for all the attributes and samples evaluated, other or at the very least additional vehicle of communication should be considered. The opposite applies to a graphical visualization, in the way that you have very little data to be displayed, the tables can be best suited. 

Sometimes (if not often) you have to play with your data, and test displaying it as a table or different types of plots, maybe share it with a colleague for feedback, before you pick the best one. Remember, to select the best way to communicate your data, you must understand the needs of your audience, the purpose for which various forms of display can be effectively used and also the strengths and weaknesses of tables and each type of graphical representation.

## Design Principles

Regardless of the way you decide to display your data, you must understand visual perception and its application to graphical communication. It is important to spend some time with the design and aesthetic aspects of your visualization. You should be able to recognize smart design by becoming familiar with some aspects and examples of great design. Inattention to the visual design such as tables with improper alignment of numbers and excessive use of lines and fill colors, can greatly diminish their effectiveness. We will summarize some important preattentive aspects that you should be aware of, but to read more about visual perception and graphical communication, as well as some examples of great design, we strongly recommend *Storytelling with Data* by Cole Nussbaumer Knaflic and *Show me the Number: Designing Table and Graphs to Enlighten* by Stephen Few.

We can easily demonstrate the difference between preattentive processing and attentive processing using an example provided by  Stephen Few in his book *Show me the Number: Designing Table and Graphs to Enlighten*. First, take a look at the numbers below and determine, as quickly as you can, how many times the number 5 appears:

98734979027513649782316497802316487415113697412369846321
12346879231648791300023665698774646821397486248797964312
12369874474578962341680021364789613469174312679812439612
12332146987412361789461230502135467980213648126498731203

How many did you count? Probably this was a tedious task and it took you a few seconds or even minutes because it involved **attentive processing**. The list of numbers did not have any hint or called preattentive attributes that could help you to easily distinguish the number five from the other numbers, so we are forced to perform a sequential search throughout the whole list.

Let's do it again, but now using the list of numbers below:

98734979027**5**1364978231649780231648741**5**113697412369846321
1234687923164879130002366**5**698774646821397486248797964312
12369874474**5**78962341680021364789613469174312679812439612
12332146987412361789461230**5**0213**5**467980213648126498731203

This time the task is much easier and you can count the number of times the number 5 appears much fast. This is because we used the **preattentive attribute** of color intensity to distinguish the number five, standing it out in contrast to the rest. This remarkable example shows in a brilliant way the power of preattentive attributes for effective visual communication. As stated by Cole Nussbaumer Knaflic in her book *Storytelling with Data*, when we use pre-attentive attributes strategically, we enable our audience to see what we want them to see before they even know they are seeing it!

The various preattentive attributes that can be used to draw your audience's attention quickly and create a visual hierarchy of information include **attributes of form** such as line length, line width, orientation, shape, size, added marks, and enclosure, **attributes of color** which would be hue and intensity, also spatial position and motion. Some of the strategies for a smart design for graphical communication described by Cole Nussbaumer include:

- **Highlight the important stuff** - use tools such as bold, italics, underlining, uppercase text, color, and different sizes to draw your audience's attention to what you want them to focus on. 

- **Eliminate Distractions** - while some elements should be highlighted, unnecessary or irrelevant items or information should be identified to be cut or de-emphasized to minimize your audience's distraction. Get rid of noncritical data or components, things that wouldn't change the main message, and summarize when details aren't needed. When a piece of information is necessary to come along with your visualization but is not really a message-impacting, you should de-emphasize it - light gray usually works well for that purpose. 

Let's now focus on how to make nice tables and plots in R.

## Table Making
 
Let's start using the package `{flextable}` to build tables using as an example the sensory data (Sensory Profile.xlsx). Let's first load the necessary libraries.

```{r, message=FALSE, warning=FALSE, echo = TRUE, eval = TRUE}

library(here)
library(readxl)
library(tidyverse)

```

In a situation where we are interested to display the mean for the appearance attributes evaluated in the 11 biscuits, we would need first to prepare the data, which means, selecting the wanted attributes and calculating the mean scored by panelists.

```{r, message=FALSE, warning=FALSE, results='hide', echo = TRUE, eval = TRUE}

# Sensory Profile Data

file_path <- here("data","Sensory Profile.xlsx") 

# Sensory Appearance Attributes Mean

mean_sensory <- read_xlsx(file_path, sheet="Data") %>% 
  select(Product, "Shiny":"Color contrast") %>%
  group_by(Product) %>%
  summarize(across(.cols = where(is.numeric),.fns = mean))

```

Now that we are satisfied with the data we want to display, we can create the table from it. 

```{r flextablebasic, message=FALSE, warning=FALSE, echo = TRUE, eval = TRUE, tab.cap="Appearance Attributes Mean (Basic Flextable)"}
library(flextable)  

flex_table <- mean_sensory %>% 
  flextable()

flex_table

```


As you can see, we have a very simple and overcrowded table that clearly needs some design work to make it nicer. We can start improving it with some basic elements such as standardizing the number of decimals, changing the font size, adjusting the cell widths and heights, highlighting the header, and aligning the text.

```{r flextablebasic2, message=FALSE, warning=FALSE, echo = TRUE, eval = TRUE, tab.cap="Appearance Attributes Mean (Basic Flextable 2)"}

flex_table_design <- flex_table %>%
  colformat_double(digits = 2) %>%
  fontsize(part = "all", size = 10) %>% 
  bold(bold = TRUE, part = "header") %>%
  autofit() %>%
  align(align = "center", part = "all")

flex_table_design

```


After the basic aesthetic changes in the table, we can add additional elements such as the table title and also, depending on our purpose and where we want to call the audience's attention, use other strategies such as set background color. Let's here just highlight the optimized formulation.

```{r, flextabledesigned, message=FALSE, warning=FALSE, echo = TRUE, eval = TRUE, tab.cap="Appearance Attributes Mean (Improved Flextable)"}

flex_table_design_2 <- flex_table_design %>%
  bg (i=11, j = NULL, bg = "orange") %>%
  add_header_lines(values = "Sensory Profile for Appearance of breakfast biscuits with varying contents of proteins and fibers") %>%
  fontsize(size = 13, part = "header", i = 1) %>%
  italic(italic = TRUE, part = "header")

flex_table_design_2

```


The table now looks much nicer and can be further improved with other preattentive attributes according to the main objective of your message. If you are interested in learning more about `{flextable}` package, we recommend the book *Using the flextable R package* by David Gohel (https://ardata-fr.github.io/flextable-book/index.html).

Another interesting package to create tables is the `{gt}` package. This package make it simple to produce nice-looking tables for a report or presentation. Let's first install and load the `{gt}` package.

```{r, message=FALSE, warning=FALSE, echo = TRUE, eval = TRUE}
library(gt)

```

Focusing now on the consumer study (Consumer Test.xlsx), suppose we want to display a table with the average the consumers spent in the booth and the number of biscuits eaten for each product. We need to transform the time columns (expressed as min and s) to a double format and express them as minutes units, and then group them by product to get the average for the time spent and the number of biscuits eaten.

```{r, message=FALSE, warning=FALSE, results='hide', echo = TRUE, eval = TRUE}

# Consumer Data

file_path <- here("data","Consumer Test.xlsx") 

# Average of Consumption Time (min) and Number of Biscuits

mean_consumer <- read_xlsx(file_path, sheet="Time Consumption") %>%
  select(Product, `Time (min)`, `Nb biscuits`) %>%
  separate(`Time (min)`, c("Time (min)", "time_sec"), sep = "min") %>%
  mutate(time_sec = as.numeric(time_sec)) %>%
  mutate(time_min_2 = time_sec/60) %>%
  mutate(`Time (min)` = as.numeric(`Time (min)`)) %>%
  mutate(`Time (min)` = `Time (min)` + time_min_2) %>%
  select(-c("time_sec", "time_min_2")) %>%
  group_by(Product) %>%
  summarise_if(is.numeric, mean, na.rm = TRUE)

```

Now that the data is ready, we can display it as table and make basics adjustments to make it look nicer.

<!-- Table cap doesn't appear --> 
```{r gttablebasic, message=FALSE, warning=FALSE, echo = TRUE, eval = TRUE, tab.cap="Consumption time and number of biscuits eaten"}

consumer_gt_table <- mean_consumer %>%
  gt () %>%
  cols_align(align = "center", columns = everything()) %>%
  fmt_number(columns = c( "Time (min)", "Nb biscuits") , decimals = 2) %>%
  tab_header(title = md ("**Consumption time and number of biscuits eaten**"), 
             subtitle = md ("*Average taken from 99 consumers*"))

consumer_gt_table

```


Note that we used Markdown to style the title and subtitle by wrapping the values passed to the title or subtitle with the md() function. For Markdown ** makes the text bold and * makes the text italic.

The `{gt}` package offers several resources to make beautiful tables using preattentive attributes. As an example, let's now focus on the average number of biscuits eaten only, since we saw that the consumption time was very similar among products. The idea is to use pre-attentive attributes for the audience to clearly see the formulation that got the most to the least biscuits eaten. Let's first prepare the data and calculate the overall time consumption considering all products.

```{r,message=FALSE, warning=FALSE, results='hide', echo = TRUE, eval = TRUE}

# Average of Number of Biscuits

mean_consumer_2<- mean_consumer %>%
  select(- "Time (min)") %>%
  arrange(desc (`Nb biscuits`))

mean_time_consumption <- mean(mean_consumer$`Time (min)`) %>%
  round(digits = 2)

```

Now that the data is ready, we will make the basic table following the same style as before, but now displaying only the number of biscuits eaten. We will also add a source note expressing the average time for the biscuit consumption.

```{r gttabledesigned, message=FALSE, warning=FALSE, results='hide', echo = TRUE, eval = TRUE}

table_source <- str_c("Mean consumption time was ", mean_time_consumption, " min")

consumer_gt_table_2 <-  mean_consumer_2 %>%
  gt () %>%
  cols_align(align = "center", columns = everything()) %>%
  fmt_number(columns = "Nb biscuits" , decimals = 2) %>%
  tab_header(title = md ("**Number of biscuits eaten**"), 
             subtitle = md ("*Average taken from 99 consumers*")) %>%
  tab_source_note(source_note = table_source)

consumer_gt_table_2

```

Now, we will use a nice tool to explicitly color across the range number of biscuits eaten range, so the most and least eaten products can be easily identified.

<!-- Table cap doesn't appear --> 
```{r gttablefinal, message=FALSE, warning=FALSE, echo = TRUE, eval = TRUE, tab.cap="Number of biscuits eaten"}

library (scales)

min_nb_biscuits <- min(mean_consumer_2$`Nb biscuits`)
max_nb_biscuits <- max(mean_consumer_2$`Nb biscuits`)
biscuits_palette <- scales::col_numeric(c("#FEF0D9", "#990000"), domain = c(min_nb_biscuits, max_nb_biscuits), alpha = 0.75)

consumer_table_final <- consumer_gt_table_2 %>% 
    data_color(columns = c(`Nb biscuits`), colors = biscuits_palette)

consumer_table_final

```


Applying this strategy of coloring the number of biscuits eaten according to their range makes the table much nicer and easier to get insights. In our case, we can quickly see that product 10 was the most eaten and product 4 the least eaten by the consumers.

The package `{gtExtras}` provides some additional features that are currently not yet built in `{gt}`. The `{gtExtras}` package includes three different themes, additional formatting capabilities, opinionated diverging color palette, extra tools for highlight, possibility of embed bar plots in the table, among several other resources

Some other packages to build tables include `{huxtable}`, `{kable}` and `{kableExtra}`.


## Chart Making


"A picture is worth 1000 words". This saying definitely applies to Statistics as well, since visual representation of data often appears clearer than the values themselves stored in a table. It is hence no surprise that R is a powerful tool for graphics. 

In practice, there are various ways to build graphics in R. In fact, R itself comes with a powerful way of building graphs through the `plot()` function. An extensive description can be found in (*R Graphics 2nd edition Paul Murrell CRC Press*). Due to its philosophy, its simplicity, and the point of view adopted in this book, we will limit ourselves to graphics built using the `{ggplot2}` package. 


### Philosophy of `{ggplot2}`


`{ggplot2}` belongs to the `{tidyverse}`, and was developed by H. Wickham and colleagues at RStudio. It is hence no surprise that a lot of the procedures that we are learning throughout this book also applies to `{ggplot2}`. More generally, building graphics with `{ggplot2}` fits very well within the pipes (`%>%`) system from `{magrittr}`. As we will see, `{ggplot2}` also works with a piping system, except that the symbol used is `+` instead of `%>%`.

In practice, `{ggplot2}` is a multi-layer graphical tools, and graphics are built by adding layers to existing graphs. The advantage of such procedure is that `ggplot` objects are not fixed: They can be printed at any time, and can still be improved by adding other layers if needed. To read more about `{gglot2}` and its philosophy, please refer to <http://vita.had.co.nz/papers/layered-grammar.pdf>[link](http://vita.had.co.nz/papers/layered-grammar.pdf).

Note that since building graphics is limited to one's imagination, it is not possible to tackle each and every possibilities offered by `{ggplot2}` (and its extensions). For that reason, we limit ourselves to describing the principles of how `{ggplot2}`works. Additionally, we provide in this section and throughout the book examples of graphics that are useful in Sensory and Consumer research. This should be more than sufficient to get you started, and should cover 90% of your daily needs. Still, if that should not be sufficient, we invite you to look into the online documentation or to references such as [REFS].


### Getting started with `{ggplot2}`

To use `{ggplot2}`, it needs to be loaded. This can either be done directly using:

```{r}
library(ggplot2)
```

However, if you load the `{tidyverse}` package, this step can be ignored as `{ggplot2}` is included within the list of packages it contains:

```{r}
library(tidyverse)
```

To illustrate the use of `{ggplot2}`, both the sensory data (*Sensory Profile.xlsx*) and the number of biscuit eaten by each respondents (*Consumer Test.xlsx*) are used.

```{r}
library(here)
library(readxl)

# Sensory Profiles Data
file_path <- here("data","Sensory Profile.xlsx") 
p_info <- read_xlsx(file_path, sheet="Product Info") %>% 
  dplyr::select(-Type)

sensory <- read_xlsx(file_path, sheet="Data") %>% 
  inner_join(p_info, by="Product") %>% 
  relocate(Protein:Fiber, .after=Product)

# Number of Biscuits Eaten Data
file_path <- here("Data","Consumer Test.xlsx")

Nbiscuit <- read_xlsx(file_path, sheet="Time Consumption") %>% 
  mutate(Product = str_c("P", Product)) %>% 
  rename(N = `Nb biscuits`)

```

To initiate a graph, the function `ggplot()` is called.
Since the data to be used are stored in `sensory`, `ggplot()` is applied on `sensory`:

```{r}
p <- ggplot(sensory)
```

Running this line of code generates an empty graphic stored in `p`. This is logical since no layers have been added yet.
So let's imagine we want to look at the overall relationship between `Sticky` and `Melting`. To evaluate this relationship, a scatter plot with `Sticky` in the x-axis and `Melting` in the y-axis can be created. 
To do so, two types of information are required:

 - the type of visual (here a scatter point);
 - the information regarding the data to plot (what should be represented).

Such information can be provided as such:

```{r}
p + geom_point(aes(x=Sticky, y=Melting))
```

As can be seen, a layer that consists of points (defined by `geom_point()`) in which the x-axis coordinates is defined by `Sticky` and the y-axis coordinates by `Melting` defined through aesthetics (or `aes()`) is added to the already existing graph `p` .

#### Introduction to Aesthetics

In the previous example, one can notice that many points are being printed. This surprising result is logical since `sensory` contains the raw sensory data, meaning that there are as many points as there are assessors evaluating products.

Let's color the points per products to see if we can see any patterns. Since the color code is specific to the data (more precisely to `Product`), it should be informed within the aesthetics by adding `colour=Product` within `aes()`:

```{r}
p + geom_point(aes(x=Sticky, y=Melting, colour=Product))
```

As you can see, any parameters provided within `aes()` may depend on a variable (e.g. `colour` in the previous example). 
If for any reasons, a specific setting should uniformly be applied to all the elements of the graph, then it should be stated outside `aes()`. 

Let's illustrate this by providing a simple example in which we change the type of the dots from circle to square using `pch`, and by increasing their size using `cex`:

```{r}
p + geom_point(aes(x=Sticky, y=Melting, colour=Product), pch=15, cex=5)
```

Depending on the `geom_*()` considered, different parameters should be informed within `aes()`. Here is a list of the most common `aes()` you would use:

 - `x`, `y`, `z`, provides the coordinates on the X, Y, Z dimensions respectively;
 - `colour`/`color`, `fill` controls for the color code^[You can also use `alpha` to control for the transparency of the elements by defining values between 0 (completely transparent) to 1 (no transparency)] that is being applied to the different elements of a graph;
 - `group` makes the distinction between points that belong to different groups^[Note that `colour` and `fill` are specific cases of groups as they additionally provide a visual cue on the groups through the color code];
 - `text`, `label` prints text on the graph;
 - `size` controls the size of the element (this should preferably be used with numerical variables).
 
Examples highlighting various types of aesthetics are presented throughout the book.

#### Introduction to `geom_*()` functions

Since `{ggplot2}` is a multi-layer graph, let's add another layer. For example, the name/code of the panelists associated to each point can be printed. 

Such procedure is done thorugh the use of another `geom_*()` function in `geom_text()`^[Try using `geom_label()` instead of `geom_text()` to see the difference between these two] which requires in `aes()` the position of the labels (`x` and `y`) as well as the `label` itself.

To avoid having the label overlapping with the point, the text is slightly shifted vertically using `nudge_y`:

```{r}
ggplot(sensory)+
  geom_point(aes(x=Sticky, y=Melting, colour=Product))+
  geom_text(aes(x=Sticky, y=Melting, label=Judge), nudge_y=1)
```

One interesting remark is that some information required in `aes()` is being repeated across the different `geom_*()` used. Such writing can be simplified by providing the `aes()` information that applies to all `geom_*()` to the original `ggplot()` call. The previous code hence can be simplified to:

```{r}
p <- ggplot(sensory, aes(x=Sticky, y=Melting, label=Judge))+
  geom_point(aes(colour=Product))+
  geom_text(nudge_y=1)
```
 
With this new code, you'll notice that:

 - although `label` is only relevant for `geom_text()`, it can still be provided at the beginning as it will be ignored by `geom_point()` which does not require it;
 - `colour` should only be provided within `geom_point()` else the text would also be colored according to `Product` (which we do not want here);
 - `nudge_y` is defined outside `aes()` as it applies to all the text.

Since the graphics look at the relationship between two quantitative variables, let's add another layer to the previous graph that shows the regression line between:

```{r}
line_p <- p + geom_smooth(method="lm", formula="y~x", se=FALSE)
  
```

This code adds a regression line to the graphic. It is built using the `lm()` engine in which the simple linear regression model `y~x` is fitted. This result is somewhat surprising since we have not run any regression yet, meaning that `geom_smooth()` is actually performing the required analysis on the data in the background. 

In fact, most `geom_*()` function comes with a statistical process attached to it. This means that on the raw data, the `geom_*()` function calls its `stat_*()` function that runs the corresponding analysis. In the previous example, `geom_smooth()` calls `stat_smooth()`.

Let's illustrate this concept again using another example: bar-charts that is applied on the data stored in `Nbiscuit`. 
Here, we want to see the distribution (through bar-charts) of number of biscuits eaten per consumer. A quick look at the data shows that some respondents ate portions of the cookies. To simplify the analysis, let's consider the total number of entire cookies eaten: if a respondent has eaten say 3.5 biscuits, it will be rounded down to 3 full cookies. 

```{r}
Nbiscuit <- Nbiscuit %>% 
  mutate(N = floor(N))
```

To create such distribution, a first solution consists in counting for each product how many respondents ate 0 biscuit, 1 biscuit, 2 biscuits, etc. This is automatically done using `geom_bar` and `stat="count"`. The parameter `position="dodge"` is used to get the results per biscuit side by side rather than stacked up (value by default):

```{r}
bar_p <- ggplot(Nbiscuit, aes(x=N, fill=Product))+
  geom_bar(stat="count", position="dodge")
```

In the background, this corresponds to grouping the data by `Product`, summarizing the results by counting `N`, and then performing `geom_bar()` in which no transformation is required (we set `stat="identity"`)^[This code could even be simplified by using `geom_col()` since `geom_col()` corresponds to `geom_bar()` with `stat="identity"` as default.]:

```{r}
Nbiscuit %>% 
  count(Product, N) %>% 
  ggplot(aes(x=N, y=n, fill=Product))+
  geom_bar(stat="identity", position="dodge")
```

As can be seen, the two graphics are identical. 

#### Making graphs pretty

In the two previous graphs generated (stored in `line_p` and `bar_p`), some features can be changed to produce clearer visualizations. Currently, the background is grey with vertical and horizontal white lines, the legend is positioned on the right side, the axis is defined based on the data itself (and so are the axis titles), there is no title, etc. and all these points (amongst many more) that are being improved in this section.

Let's start with a quick win by completely changing the overall appearance of the graph. To do so, predefined *themes* with pre-set background (with or without lines), axis lines, etc. can be applied. The two themes we use the most are `theme_minimal()` and `theme_bw()` (see <https://ggplot2.tidyverse.org/reference/ggtheme.html>[link](https://ggplot2.tidyverse.org/reference/ggtheme.html) for a complete list of pre-defined themes.)

Let's start with improving `bar_p` using `theme_minimal()`:

<!-- Should we standardize and always use "<-" --> 
```{r}
bar_p = bar_p + theme_minimal()
```

Rather than using pre-defined themes (or to complement pre-defined themes), the different parameters of the graph can be controlled through `theme()`.

Next, let's modify the axes by changing their names and by applying more logical breaks. For instance, the limits of the x-axis can be extended to -1 and 11 to ensure that all the histograms are visible, else R removes some and returns a warning: `Removed 10 rows containing missing values`.

```{r}
bar_p = bar_p +
  scale_x_continuous(name="Number of Biscuits eaten", 
                     breaks=seq(0,10,1), 
                     labels=c("None", 1:9, "All of them"), 
                     limits=c(-1,11))+
  ylab("Number of Respondents")
```

Last but not least, a title is being added to the graph using `ggtitle()`:

```{r}
bar_p = bar_p +
  ggtitle("Distribution of the number of biscuits eaten","(Results are split per biscuit type)")
```

Let's apply a similar transformation to `line_p`. Here, we are aiming in having a more *realistic* plot using cartesian coordinates, a nice theme, no legend, and a title to the graph.

```{r}
line_p = line_p +
  theme_bw()+
  scale_x_continuous(breaks=seq(0,50,10), limits=c(0,60))+
  scale_y_continuous(breaks=seq(0,50,10), limits=c(0,60))+
  coord_fixed()+
  ggtitle("Relationship between Melting and Sticky", "Biscuits perceived as more sticky tend to be less melting.")+
  guides(colour="none")
```

### Common Charts

You have now an overview of the basics of `{ggplot2}` and its philosophy. You'll find plenty of other examples throughout this book to help you develop your skills in building graphics in R.

Since making an exhaustive list of plots that are relevant in sensory and consumer science is out of the scope for this book, it is not going to be further developed here. Yet, here is a summary of the `geom_*()` that could be of interest for you:

* Scatter points: 
  * `geom_point()`: create a scatter point (see example...)
* Line charts:
  * `geom_line()`: create a line that connects points (see example...);
  * `geom_smooth()`: add a regression line (see ...);
  * `geom_hline()` (resp. `geom_vline()`): add a horizontal (resp. vertical) line using `yintercept` (resp. `xintercept`);
  * `geom_segment()`: draw a segment going from (`x`;`y`) to (`xend`;`yend`)^[This function can also be used to draw arrows through the parameter `arrow` and the function of that same name `arrow()`.].
* Bar charts: 
  * `geom_col()` and `geom_bar()`: produce bar-charts by either using the raw values, or by computing the frequencies first (see example...);
  * `geom_histogram()` and `geom_freqpoly()`: work in a similar way as `geom_bar()` except that it divides the x axis into bins before counting the number of observation in each bin and either represent it as bars (`geom_histogram`) or lines (`geom_freqpoly()`).
* Distribution:
  * `geom_density()`: build the density plot;
  * `geom_boxplot()`: build the well-known boxplot;
  * `geom_violin()`: application of `geom_density()` displayed in `geom_boxplot()` fashion. 
* Text and Labels:
  * `geom_text` and `geom_label`: add text to the graph (see example...);
  * the package `{ggrepel}` provides alternative functions (`geom_text_repel()` and `geom_label_repel()`) that re-position labels to avoid overlapping (*repel* stands for *repulsive*).
* Rectangles^[In Sensory and Consumer science, this will often be used for building surface plot responses (e.g. external preference map), and hence is associated to `geom_contour()` to show the different lines.]:
  * `geom_tile()`, `geom_rect`: create area either using its center point (`geom_tile()`) or its four corner (`geom_rect()`) defined by `xmin`, `xmax`, `ymin`, and `ymax` (see example...); 
  * `geom_raster()`: high performance alternative to `geom_tile()`/`geom_rect` where all the tiles have the same size. 

Besides `geom*()`, a lot of graphical parameters can further be controlled. This includes of course the `theme()` and the `aes()`:

* For pre-defined themes, see example;
* `axis` parameters including its title (`axis.title`), text (`axis.text`), ticks (`axis.ticks`), line (`axis.line`), and all their sub-levels.
* `legend` parameters including its position (`legend.position`), direction (`legend.direction`), its text (`legend.text`, `legend.title`), the design of the box (`legend.box`, `legend.background`) etc. 
* `panel` parameters including its background (`panel.background`), the grid lines (`panel.grid`), the border (`panel.border`), etc.
* `plot` parameters including the different titles (`plot.title`, `plot.subtitle`, `plot.caption`), the background (`plot.backgorund`), etc.
  
Most of these parameters can be controlled at different levels of granularity:

* overall, e.g. `panel.grid`;
* more detailed, e.g. `panel.grid.major` and `panel.grid.minor`;
* most detailed, e.g. `panel.grid.major.x`, `panel.grid.major.y`, etc.

Depending whether the option to modify is some text, a line, or a rectangle, `element_text()`, `element_line()`, or `element_rect()` would be respectively used to control them. These functions provide general (e.g. `color`) as well as specific options (e.g. `family` and `face` for text, `linetype` for lines etc.) to each type. 

Note that if some elements should be left blank, `element_blank()` can be used regardless of the nature of the element.

Let's illustrate these concepts using our previous graph stored in `line_p`. Here, the goal is to remove the grid line, to replace the x and y axis lines by arrows, and to re-position the axis titles to the far end of the axis so that it is next to the arrow head. 

```{r}
line_p +
  theme(panel.grid=element_blank(), 
        panel.border=element_blank(),
        axis.line=element_line(arrow = arrow(ends = "last", type = "closed")),
        axis.title=element_text(hjust=1))
```

Similarly to the theme, aesthetics can also be adjusted. In previous examples, the x-axis in `bar_p` as adjusted by setting limits, providing breaks and replacing the values by certain labels using `scale_x_continuous()`. 
Most aesthetics parameters can be controlled by equivalent functions for which the name is using the following structure  `scale_*nameaes*_*typescale*`, and where: 

* *nameaes* corresponds to any aesthetics including `x`, `y`, `colour` or `fill`, `alpha`, etc.
* *typescale* corresponds to the type of scale, where it is `continuous`, `discrete`, or `manual` amongst others.

Such functions fully control how the corresponding aesthetic should behave, by providing the correspondence between a variable level and its color for instance. In the graph saved in `bar_p`, remember that we filled in the bar chart using the product information. Let's imagine that we are particularly interested in biscuit P3, and want to compare it to the rest of the biscuits. We propose to make P3 stand out by filling it in orange, and by setting all the other biscuits in the same gray tone.
Such procedure can be done using `scale_fill_manual()`.

```{r}
bar_p + 
  scale_fill_manual(values=c("P1"="gray50", "P2"="gray50", "P3"="darkorange", "P4"="gray50", "P5"="gray50",
                             "P6"="gray50", "P7"="gray50", "P8"="gray50", "P9"="gray50", "P10"="gray50"))
```

When multiple aesthetics are being used, the legend might become overwhelming or redundant. It is possible to turn off some of these visuals within the `scale_*()` functions, or by using `guides()` and by setting `nameaes='none'` as shown in the `line_p` example.

### Miscealleneous

#### Structuring the axis

By default, `ggplot()` generates plot that fits the data and that fits within the output screen. This means that some graphics might not be perfectly representing the data due to some distortion. In a previous example (`line_p`), the dimensions were made comparable through `coord_fixed()`. 

Other transformation can be performed. For instance, the graphic can be transposed using `coord_flip()` as in the following example:

```{r}
bar_p + coord_flip()
```

To conclude this section, and summarize most concepts presented in this chapter, let's introduce the well-known spider plots. The use of such plots are quite polarizing amongst analysts and the reason of this choice here is purely educational, as 1. there are no pre-defined options in `{ggplot2}` that provides such charts, and 2. they present some interesting challenges.

Let's start with deconstructing a spider-plot: a spider plot is a line chart presented in a circular way. So let's start with building a line chart of our sensory profiles (the means are considered here). For more clarity, only two of the samples (`P03` and `POpt`) are represented.

```{r}

# Constructing the Mean Table
sensory_mean <- sensory %>% 
  pivot_longer(Shiny:Melting, names_to="Variables", values_to="Scores") %>% 
  mutate(Variables = fct_inorder(Variables)) %>% 
  group_by(Product, Variables) %>% 
  summarize(Mean = mean(Scores)) %>% 
  ungroup() %>% 
  filter(Product %in% c("P03", "POpt"))

# Building the Line Chart
spider_line <- ggplot(sensory_mean, aes(x=Variables, y=Mean, colour=Product, linetype=Product))+
  geom_point(pch=20, cex=2)+
  geom_line(aes(group=Product), lwd=1)+
  theme_minimal()+
  xlab("")+
  scale_y_continuous(name="", labels=NULL, limits=c(0,50))+
  scale_colour_manual(values=c("P03"="darkorange", "POpt"="grey50"))+
  scale_linetype_manual(values=c("P03"="solid", "POpt"="dashed"))
```

Next step is to represent this line chart in a circular way. This can be done using `coord_polar()`:

```{r}
spider_line + coord_polar()
```

This already looks like a spider plot! However, a closer look at it highlights a point that needs improvement: There is no connection between the last attribute (`Melting`) and the first one (`Shiny`). 

To counter this, the following twofold solution is proposed:

  1. Associate each attribute to its position (e.g. `Shiny` is 1, `External color intensity` is 2, until `Melting` which would be 32);
  2. Duplicate the last attribute (`Melting`) and associate it to position 0.

```{r}
var <- levels(sensory_mean$Variables)
sensory_mean_pos <- tibble(Variables = c(var[length(var)], var),
                  Position = 0:length(var)) %>%
  full_join(sensory_mean, var_pos, by="Variables")

```

The previous graph is then rebuilt by forcing the position of the attributes on the x-axis using `Position` (`Variables` is used for the labels). Here position 0 is voluntarily omitted (`breaks = 1:length(var)` and `labels = var`), meaning that only the labels going from 1 to the last variable are being showed. However, the x-axis is forced to go from 0 to the number of attributes (`limits = c(0, length(var))`).

```{r}
spiderplot <- ggplot(sensory_mean_pos, aes(x=Position, y=Mean, colour=Product, linetype=Product))+
  geom_point(pch=20, cex=2)+
  geom_line(aes(group=Product), lwd=1)+
  theme_minimal()+
  scale_x_continuous(name="", breaks=1:length(var), labels=var, limits=c(0,length(var)))+
  scale_y_continuous(name="", labels=NULL, limits=c(0,50))+
  scale_colour_manual(values=c("P03"="darkorange", "POpt"="grey50"))+
  scale_linetype_manual(values=c("P03"="solid", "POpt"="dashed"))+
  coord_polar()
```

By using this trick, the connection between the first and last attributes is established.

#### Combining plots

When multiple plots should be generated using the same pattern on subset of data, it is possible to generate them automatically using `facet_wrap()` or `facet_grid()`. 
The difference between these two functions rely in the number of variables to use for the split: In `facet_wrap()`, the graphics are *vectorized*, meaning that each element of the split is represented independently. For `facet_grid()` however, the graphics is represented in a matrix, meaning that two blocks of split variables are required, one defining the columns and one the rows.

An example of `facet_wrap()` is provided in (ref data analysis). 

For these two functions, the parameter `scales` is particularly interesting as it allows each separate graph to use its own axis scales (`free` or individually using `free_x`/`free_y`) or not (`fixed`).

To go further, consider also the function `facet_trelliscope()` from the `{trelliscopejs}`.
This function generates the same type of graphs as `facet_wrap()` or `facet_grid()` with some powerful twists. After generating the plots, they are still editable thanks to an interactive menu that controls for the *Grid*, *Labels*, *Filter*, and *Sort*. For example, the number of plots to show per row/column can be adjusted, tables with descriptive statistics (e.g. mean, minimum, maximum) can be added under each graph, etc. Moreover, readers that are familiar with the interactivity of `{plotly}` can make great use of it through the `as_plotly = TRUE` parameter, which is then applied to each individual graph!


Such procedure is very handy to produce multiple graphs all at once...when the data allow it. 
When multiple plot are being generated separately (using different data set, or producing different types of plots), it can still be relevant to combine them all in one. To perform such collage, the package `{patchwork}` becomes handy thanks to its simplicity and flexibility.

`{patchwork}` is a package that allows combining `ggplot()` graphs using *mathematical* operations.
To add two elements next to each others, the `+` sign is used. To add two elements on top of each others, they should be separated using `/`. This operation can be combined with `()` to generate fancier collage.

Let's illustrate this by creating a plot with on the left side `spiderplot`, and on the right side `bar_p` on top of `line_p`.

```{r}
library(patchwork)

p = spiderplot + (bar_p / line_p)
p

```

A general title can be added, as well as tag levels (handy for publications!) using `plot_annotation()`.

<!-- the plots/annotations seem to be overlapping --> 
```{r}
p + plot_annotation(title = "Example of 'ggplots' I've learned today", tag_levels='a')
```

### Few Tips and Tricks

#### Combining data transformation and `{ggplot2}` grammar

Both the `{tidyverse}` and `{ggplot2}` are using pipes to combine lines of code or layers. 
However, the pipes themselves are defined differently since `{maggritr}` uses `%>%` whereas `{ggplot2}` uses `+`.
It is however possible to combine both systems one after each other, just remember to switch from `%>%` to `+` as you transition from data transformation/tidying to building your graph (see example...).

#### Ordering elements in a plot

When building a graph using a categorical variables, `{ggplot2}` tends to represent the different levels in alphabetical order, especially if the variable is defined as character. Such situation can make the graph more difficult to read, as the categories may not be presented in a logical order (e.g. fall, spring, summer, winter instead of spring, summer, fall, winter).

<!-- What is this example you are referring to? --> 
To ensure that the elements are in the right order, either consider transforming the variables into factor (using `factor()` by indicating the levels order of your choice, or through `fct_inorder()` to keep the order from the file, see example...) or by using a position variable as in the `spiderplot` example. The former option also works for ordering elements in the legend.

If the order of the elements should be changed *within the charts* (simple changes such as reverting the order), it can be done directly within the `geom_*()` function. This is for instance the case with stacked bar chart, in which the order may be reverted using the parameter `position = position_fill(reverse = TRUE)` for instance (suggesting here that the split was defined through `fill` in `aes()`).

#### Fixing overlapping axis text

When `ggplot()` are being built using categorical variables, the labels used on the x-axis are often overlapping (some of the labels being then unreadable). A first good/easy solution consists in reducing the size of the label, and/or to shortening them as long as it does not affect its readability/clarity. However, this might not always be possible or sufficient, and other adjustment are required. Let's use `spider_line` as illustration to show three possible solutions.

The first option consists in using `theme()` and rotating the labels (here at 45 degrees, but use 90 degrees to get the names vertically). Note that by default, `ggplot()` center the labels: to avoid having them crossing the x-axis line, they are being left-centered using `hjust=1`:


```{r}
spider_line + 
  theme(axis.text.x = element_text(angle=45, hjust=1))
```


A second option consists in dodging one every two labels along the x-axis. This option works fine, especially when the labels are not too long. In our example unfortunately, some overlap can still be seen. Note that this option is accessible within `scale_x_discrete()`, not within `theme()` as we would expect:

```{r}
spider_line + 
  scale_x_discrete(guide = guide_axis(n.dodge = 2))
```

Last option consists in transposing the graph using `coord_flip()`. This solution works well since labels on the y-axis are written horizontally. However, this option is not always suitable due to conventions: if it is recommended for bar charts, it may not be for line charts for instance. 

#### Exporting graphs

There are various ways to save or export `ggplot()` charts. To save these plots to your computer in various formats (e.g. png, pdf, etc.), `ggsave()` can be used. By default, `ggsave()` exports the last plot built and saves it in the location defined by `filename`, in the format defined by `device` (additional information regarding the width, height, dpi etc. can also be configured).

For instance, the `spiderplot` generated earlier^[Since `spiderplot` is not the last plot generated, it needs to be defined in `plot`.] can be saved as following:

```{r}
ggsave(filename="spiderplot.png", plot=spiderplot, device="png")
```

As an alternative, `ggplot()` graphs can also be exported in PowerPoint or Word through the `{rvg}` package (see example).

#### Additional libraries

`{ggplot2}` is a very powerful tool for data visualization. By default, it offers a very large variety of possibilities, which should cover most situations that you would encounter. If not, please search as you will most likely find ggplot extensions in alternative packages. 

To help you further, here is a non-exhaustive list of relevant packages: 

 - `{ggcharts}`: This package provides nice and clear alternatives to some `{ggplot2}` options through simple functions in one line of code, including `bar_chart()`, `line_chart()`, `lollipop_chart()` and `dumbbell_chart()` just to name a few.
 - `{graffify}`: This package extends `{ggplot2}` by providing nice and easy functions to help data visualization and linear models for ANOVA. For example, it generates through one function bar chart with error bars through `plot_scatterbar_sd()`, or simultaneous boxplot and scatter plot through `plot_scatterbox()`.
 - `{factoextra}`: Although the latest version of `{FactoMineR}` also generates its graphs in `{ggplot2}` by default, `{factoextra}` is a great extension as it is easy to use and provides a wide variety of options to customize your plots.
 - `{ggcorrplot}`: There are many packages that propose to visualize graphically tables of correlations, however we particularly like this one for its simplicity and its flexibility.
 - `{ggwordcloud}`: It is a great package for building word-clouds as it provides a large degree of control. With this package, the words can either be positioned randomly, by matching a pre-defined shape, etc. But more interestingly, words can also be positioned semi-randomly, hence giving more interpretation power to the final results (for more information, please visit <https://lepennec.github.io/ggwordcloud/>[link](https://lepennec.github.io/ggwordcloud/)).
 - `{ggraph}`: This package provides neat solutions to build network visualization in `{ggplot2}`.
 - `{performance}`: This package provides pre-defined graphs that allow you evaluating the quality of your models through the single `check_model()` function. See also `{ggside}` if you want to print on the margin of your regression plot the marginal distributions (or density plot) of your different categories. 

To learn more about `{ggplot2}` basics, we recommend two additional source of information:

 - `{esquisse}`: After loading the package, run the function `esquisser()`. This command opens a window in which you can select your data set (the data set should be available within you R environment), the type of plot to build, and all the relevant information to build your plot (which variable to be used as x-axis, y-axis, etc.) through an easy-to-use interface. Ultimately, the graph is being generated, but more importantly, the code used to generate the plot is provided. This is hence an educational tool to learn build graphs with ggplot.
 - <https://www.data-to-viz.com/>[link](https://www.data-to-viz.com/) provides a wide gallery of graphics sorted by the type of data that you have. Each graphic proposed is illustrated with an example provided in R (often in `{ggplot2}`) and in Python. This website is hence inspirational and educational both at the same time!

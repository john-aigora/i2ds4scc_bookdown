```{r include=FALSE}
knitr::opts_chunk$set(echo = TRUE, eval = FALSE)
```
# Getting Started {#start-R}

## Introduction to R

### What is R?

First released in 1995, R is an open-source programming language and software environment. It is a free and powerful statistical software widely used for statistical analysis, graphics representation and reporting. R was created by Ross Ihaka and Robert Gentleman at the University of Auckland, New Zealand and is currently developed by the R Development Core Team. The name “R” was based on Ihaka’s and Gentleman’s first names and partly a play on the name of the Bell Labs Language S.

R is a scripting language (not a compiled language) that runs the codes or commands in order.
It is one of the most popular languages used by statisticians, data analysts, researchers and marketers to retrieve, clean, analyze, visualize and present data. It is currently the 7th most popular programming language in the world and one of the most known in the sensory and consumer field.

### Why Learn a Programming Language?

There are several reasons why you should learn a programming language. One of the top reasons is the CONTROL it gives you. Differently from statistical software to analyze/visualize data, you clearly see what is happening, what is behind the scenes, step by step. You are fully under control, and so it ends up teaching you abstract thinking and problem-solving. It allows you an INCREASED CAPABILITY and CONTINUOUS IMPROVEMENT, in the way you play with your data, extract the best you can and continuously improve it. The flexibility it gives you is just incredible!

Allied to this control, the SPEED is also something that stands out. In a few seconds, we run a long and complex script to make some plots, and if you decide to change something like removing a specific attribute or some panelists, for instance, you re-run everything in no time.

Learning a programming language also play an important role in REDUCING ERRORS, and this is in part because you are under control. You can run the script line by line and see what’s happening and check if things are working properly in every and each step. It also allows you REPRODUCIBLE RESULTS by embedding script, data sets and results in a single file.

Last, but not least, it IMPROVES COLLABORATION. When user uses a version control, which will be discussed shortly, it makes possible to track changes to source over time and collaboration with multiple developers. 

### Why R?

For sensory and consumer scientists, we recommend the R ecosystem of tools for three main reasons. The first reason is cultural - R has from its inception been oriented more towards statistics than to computer science, making the feeling of programming in R more natural (in our experience) for sensory and consumer scientists than programming in Python.  This opinion of experience is not to say that a sensory and consumer scientist shouldn't learn Python if they are so inclined, or even that Python tools aren't sometimes superior to R tools (in fact, they sometimes are).  This latter point leads to our second reason, which is that R tools are typically better suited to sensory and consumer science than are Python tools. Even when Python tools are superior, the R tools are still sufficient for sensory and consumer science purposes, plus there are many custom packages such as `{SensR}`, `{SensoMineR}`, and `{FactoMineR}` that have been specifically developed for sensory and consumer science.  Finally, the recent work by the RStudio company, and especially the exceptional work of Hadley Wickham, has lead to a very low barrier to entry for programming within R together with exceptional tools for data manipulation.

On top of the main reasons described above, R is well-supported with an active community in the way the extensive online help throughout the numerous forums or websites is readily available. Besides, there are several books, courses and other educational materials to support the user. As mentioned, the  universe of available packages is vast, being the programming language with the more specialized tools for sensory analysis. Lastly, R excels at data manipulation and results reporting.

### What is RStudio?

RStudio is a powerful and easy way to interact with R programming. It is an Integrated Development Environment (IDE) for R (also Python) that comes with a multi-panel window setup that provides access to all primary things on a single screen, which means that that all information you need to write code is available in a single window that includes a console, syntax-highlighting editor that supports direct code execution, as well as tools for plotting, history, debugging and workplace management (https://www.rstudio.com/). 

Besides the convenience of having all panels in a single screen, we strongly recommend you to go for RStudio instead of R software due to other important reasons such as having a text-editor that is full-proof and full featured, auto completion while writing scripts, many shortcuts and access to all objected created in the Environment tab. Also, the highlighting tool for editor makes coding easier and less error-prone.

### Installing R and RStudio

The first step in this journey is to install R.  For this, visit [The R Project for Statistical Computing](https://www.r-project.org/).  From there, follow the download instructions to install R for your particular platform. We suggest you to download the latest version of R and install it with default options. Note that if you are running R 4.0 or higher, you might need to install Rtools:
https://cran.r-project.org/bin/windows/Rtools/


Next you need to install RStudio. To do so, visit the [RStudio desktop download page](https://rstudio.com/products/rstudio/download/) and follow the installation instructions. Download and install the latest version of RStudio with default options and for adjustments:
- Uncheck “Restore .RData" into workspace at startup
- Select “Never” for “Save workspace to .RData on exit”
- Change color scheme to dark (e.g. “Idle Fingers”)
- Put console on right

Once you have installed R and RStudio, you should be able to open RStudio and enter the following into the Console to receive the number "3" as your output:

```{r}

x <- 1
y <- 2

x + y

```

## Getting Started in R

### Create a Local Project

We strongly recommend to always work in an RStudio project. RStudio projects make it straightforward to divide your work into multiple contexts, each with their own working directory, workspace, history, and source documents. It keeps all of your R scripts, R markdown documents, R functions and data together in one place. The projects keep your files (and activity) organized, help manage your file path (so your computer can find things) and allow for more advanced capabilities. RStudio project allow independence between project, which means that you can open more than one project at the same time and switch very easily between them without fear of them interfering with each other.

To create a new project locally in RStudio, select 'File' --> 'New Project...' from the menu. Typically, a new project is created in a new directory. You can also create a new project by clicking on the ‘Project’ button in the top right of RStudio and selecting ‘New Project…’. Once your new project has been created you will now have a new folder on your computer that contains the basic file structure. You probably want to add folders to better organize all the files and documents, such as a folder for input, output and scripts.

### Install and Load Packages

The base installation of R comes with many useful packages that contains many of the functions you will use on a daily basis, however, you will very quickly feel the urge to extend R's capabilities and this is possible by using R packages that can easily be downloaded and install in R. An R package is a collection of functions, data sets, help files and documentation, developed by the community, that extends the capabilities of base R, by improving existing base R functionalities or by adding new ones. 

There several packages out there, but we listed above some of the packages we will be consistently be using throughout this book.

  - Essential packages (or collections): `tidyverse`, `readxl`

  - Custom Microsoft office document creation: `officer`, `flextable`, `rvg`, `openxlsx`, `extrafont`, `extrafontdb`

  - Sensory specific packages: `sensR` , `SensoMineR`, `FactoMineR`, `factoextra`

There are many more, for statistical tests of all varieties, to multivariate analysis, to machine learning, to text analysis, etc.

You only need to install each package once per R version. To install a package, you can type `install.packages("[package name]")`. R will download the packages from CRAN and install the onto your computer.

```{r}
install.packages("tidyverse")

```

If a script loads package that are not installed, RStudio will prompt you to install the package
Also, note that if you do not have write access on your computer, you might need IT help to install packages. 

Once you have installed a package onto your computer it is not immediately available for you to use until you load it with `library()`. 

```{r}
library(tidyverse)

```

### R Scripts

You can enter and run your code at the R Console and there are certainly many cases where it makes senses, such as open a help menu, take a quick look at your dataset, debug a function or maybe a simple calculation or testing. However, nothing you write will be saved, which means that once you close your project or restart the R session, you will loose all the code stream. And if you make an error, or want to make a change in you code, you will have to re-enter the set of commands, typing it all over again. Because of this and many other reasons, you should write any important code as an R script.

An R script is simply a text file containing a bunch of R code or set of commands (that you would enter on the command line in R) and comments that can be conveniently saved and used later to re-execute the commands. The R script can be edited so you can execute a modified version of the commands. 

You can create a new script in RStudio by clicking the 'New File' icon in the upper left of the main toolbar and then selecting 'RScript' or by clicking 'File' in the main menu and then selecting 'New File' --> 'R Script'. The script will open in the Script Editor panel and is ready for text entry. Once you are done you can save your script by clicking the 'Save' icon at the top of the Script Editor and can open it later to re-run your code and/or continue your work where you have stopped.

Unlike typing in the console, when you type your code in the R script, nothing is going to happen. You need to send it to the console by running it. There are a few ways to do this. If you want to run your code line by line, you just highlight the code you want to run (or place cursor on the single line of the code) and use the shortcut Ctrl-Enter (Windows) or Command-Return (Mac). To run the entire script (all lines of the code) you can click 'Run' in the upper right of the main toolbar or use the shortcut Ctrl-Shift-Enter (Windows) or Command-Shift-Return (Mac). 

### Run Sample Code

Like any language, R is best learned first through example then through study. Lets start with a simple example where we analyze a Tetrad test to illustrate the basic principles. 

Suppose you have 15 out of 44 correct in a Tetrad test. Using the package `sensR`, it’s very easy to analyze these data:

```{r first-example}

install.packages("sensR")

library(sensR)

num_correct <- 15  
num_total <- 44  
  
discrim_res <- discrim(num_correct, num_total, method = "tetrad")  
  
print(discrim_res)  


```

## Introduction to the `{magrittr}` and the notion of *pipes*

R is an *evolving* programming language that evolves and expends very rapidly. 

If most additions/improvements have a fairly limited reach, the introduction of the `{tidyverse}` in 2016 by H. Wickham revolutionized the way of scripting in R for many users. At least for us, it had a large impact as we fully embraced its philosophy, as we see its advantage for Data Science and for analyzing our sensory and consumer data. It is hence no surprise that you'll read and learn a lot about it in this book.

As you may know, the `{tidyverse}` is a grouping of packages dedicated to Data Science, which includes (among others) `{readr}` for data importation, `{tibble}` for the data structure, `{stringr}` and `{forcats}` for handling strings and factors, `{dplyr}` and `{tidyr}` for manipulating and tidying data, `{ggplot2}` for data visualization, and `{purrr}` for functional programming. But more importantly, it also includes `{magrittr}`, the package that arguably impacted the most our way of scripting by introducing the notion of *pipes* (defined as `%>%`) as it provides code that is much easier to read and understand.

To illustrate the advantage of the use of pipes, let's use the example provided by H. Wickham in his book *R for Data Science*.
It is some code that tells a story about a little bunny names Foo Foo:
*Little bunny Foo Foo*
*Went hopping through the forest*
*Scooping up the field mice*
*and bopping them on the head*

If we were meant to tell this story though code, we would start by creating an object name `FooFoo` which is a little bunny:

```{r}
foo_foo <- little_bunny()
```
 
To this object, we then apply different functions (we save each step as a different object):

```{r}
foo_foo_1 <- hop(foo_foo, through=forest)
foo_foo_2 <- scoop(foo_foo_1, up=field_mice)
foo_foo_3 <- bop(foo_foo_2, on=head)
```

One of the main downsides of this approach is that you'll need to create intermediate names for each step. If natural names can be used, this will not be a problem, otherwise it can quickly become a source of error (using the wrong object for instance)! Additionally, such approach may affect your disk memory (your creating a new object in each step), especially if the data set is large.

As an alternative, we could consider running the same code by over-writing the original object:

```{r}
foo_foo <- hop(foo_foo, through=forest)
foo_foo <- scoop(foo_foo, up=field_mice)
foo_foo <- bop(foo_foo, on=head)

```

If this solution looks neater and more efficient (less thinking, less typing, less memory use), it is more painful to debug, as the entire code should be re-run from the beginning (when `foo_foo` was originally created). Moreover, calling the same object in each step obscures the changes performed in each line.

To these two approaches, we prefer a third one that strings all the functions together without intermediate steps of saving the results. This procedure uses the so-called pipes ( defined by `%>%`), which takes automatically as input the output generated by the previous line of code:

```{r}
foo_foo %>% 
  hop(through = forest) %>% 
  scoop(up = field_mice) %>% 
  bop(on = head)
```

This code is easier to read and understand as it focuses more on the verbs (here `hop`, `scoop`, and `bop`) rather than names
(`foo_foo_1`, or `foo_foo`). It can be surprising at first, but no worries, by the time you've read this book, you'll be fully familiar with this concept. 

When lines are piped, R runs the entire block at once. So how can we understand the intermediate steps that were done, or how can we fix the code if an error occur? The answer to these questions is simple: run back the code bits by bits.

For instance, in this previous example, we could start by printing `foo_foo` (in practice, only select `foo_foo` and run this code only) only to ensure that it is the object that we were supposed to have. 
If it is the case, we can then extend the selection to the next line by selecting all the code before the pipe (do not select the pipe, else R is expecting additional code after it and will not show results).
Repeat this until you found your error, or you ensure that all the steps have been performed correctly.

While reading this book, we advise you to apply this trick to each block of code for you to visualize the steps performed. 

Note however that although pipes are very powerful, they are not always the best option:

  - A rule of thumb suggests that if you are piping more than 10 lines of code, you're probably better of splitting it into 2 or more blocks (saving results in intermediate step) as this simplifies debugging. 
  - If some steps require multiple inputs, or provides multiple outputs, pipes should not be used as they usually require a primary object to transform.
  - The system of pipes works linearly: if your code requires a complex dependency structure, the pipes should be avoided.

## Version Control / Git and GitHub {#git-and-github}

Version control is a toll that tracks changes to files, especially source code files. Using version control means that you can not only track the changes, but manage them, record reasons for the changes, revert to previous versions and most important, collaborate with multiple developers. Version control systems are simply software that help users manage changes to source code over time. The reasons why everyone should use version control includes then back up work, restore prior versions, document reasons for changes, quickly determine differences in versions, easily share code and develop in parallel with others.

There are many tools for Version Control out there, but Git/GitHub are by far the most common, so we will quickly discuss them.We highly recommend that you integrate both Git and GitHub into your data scientific workflow.  For a full review of Git and GitHub from an R programming perspective, we recommend [Happy Git with R](https://happygitwithr.com/) by Jenny Bryant.  In what follows, we simply provide the minimum information needed to get you up and running with Git and GitHub.  Also, for an insightful discussion of the need for version control, please see [Cite bryan2018excuse].

### Git

Git is a version control system that runs locally and automatically organizes and saves versions of code on your computer, but does not connect to the internet. Git allows you to revert to earlier versions of your code, if necessary. To set up Git, follow the steps bellow:

1) Download and install the latest version of Git.
Download and install Git with standard options (allow 3rd party software).

For Windows: https://git-scm.com/download/win and the download should automatically start.

For Mac: https://git-scm.com/download/mac and the download should automatically start.

2) Enable Git Bash in RStudio
Got to "Tool" on the top tool bar and select "Global Options..." --> Terminal. In the drop down box for New terminals open with, select Git Bash. 

3) Configure Git from Rstudio
The easiest way is using the package `{usethis}`

```{git}

install.packages("usethis")

library(usethis)

use_git_conf (user.name = "Name Surname", user.email = "your email address")

```

4) Register with RStudio

  
### GitHub


GitHub is service that allows for online backups of your code and which facilitates collaboration between team members.  


  - Create a GitHub account
  - Register with RStudio

## Tips on *how to read this book?*

In this book, we assume that the readers have already some basic knowledge in R.
If you are completely new to R, we recommend you reading "R for Data Science" (REF) or looking at some documentation online to get you started with the basics. 

Just like with any spoken language, the same message can be said in various ways. The same applies with writing scripts in R, each of us having our own styles, or our own preferences towards certain procedures, packages, functions, etc. In other words, writing scripts is personal. Through this book, we are not trying to impose our way of thinking/proceeding/building scripts, instead we aim in sharing our knowledge built through past experiences to help you find your own style.

But to fully decode our message, you'll need some reading keys. These keys will be described in the next sections. 
#### Running code and handling errors

For you to get the most out of this book, you need to understand (and eventually adhere to) our philosophy of scripting, and our way of working. This is why we are providing you with some tips to use, if you're comfortable with them:

  1. Create a folder for this book on your computer, and create a script for each chapter in which you re-write yourself the code. If you work with the online version, you could copy/paste the code to go faster, but you may miss some subtleties.
  2. Do not be discourage when you get some errors: we all get some regularly. At first, this can be very frustrating, especially when you are not able to fix them quickly. If you get stuck on an error and cannot fix it immediately, take a break and come back later with fresh eyes, you may solve it then. And with time and experience, you'll notice that you can reduce the amount of errors, and will also solve them faster.
  3. The more code, the more difficult it is to find errors. This is true whether you use "regular" R-code or pipes. The best way to solve errors in such circumstances is to run the code line by line until you find the error, and understand why the input/output does not match expectations. 
  4. In the particular case of pipes, debugging errors means that you shouldn't run the entire block of code, but select parts of it and run it by adding in each run a new line. This can either be done by stopping your selection just before the adequate `%>%` sign, or by adding after that `%>%` sign the function `identity()`^[`identity()` is a function that returns as output the input as it is. This function is particularly useful in pipes as you can finish your pipes with it, meaning that you can put any line in comments (starting with '#') without worrying about finishing your pipe with a `%>%`].
  
#### Printing vs. Saving results
  
In many examples through this book, we apply changes to certain elements without actually saving them in an R object. This is quite convenient for us as many changes we do are only done for pedagogic reasons, and are not necessarily relevant for our analysis. 
  
Here is an example of such case (REF):

```{r}
sensory %>% 
  rename(Panellist = Judge, Sample = Product)
```

If you run this code, you'll notice that we rename `Judge` to `Panellist`, and `Product` to `Sample`...at least this is what you see on screen. However, if you look at `sensory`, the data set still contains the column `Judge` and `Product` (`Panellist` and `Sample` do not exist!). This is simply because we did not save the changes in any R object.

If we would want to save the element in a new object, we should save the outcome in an element using `<-`:

```{r}
newsensory <- sensory %>% 
  rename(Panellist = Judge, Sample = Product)
```

Here, `newsensory` corresponds to `sensory`, but with the new names. Of course, if you would want to overwrite the previous file with the new names, you simply need to ensure that the name of the output is the same as the name of the input. Concretely, we replace here `newsensory` by `sensory`, meaning that the new names are saved in `sensory` (so the old names `Judge` and `Product` and definitely lost). This procedure saves computer memory and does not require you coming up with new names all the time. However, it also means that some changes that you applied may be lost, and if you have a mistake in your code, it is more complicated to find and ultimately solve it (you may need to re-run your entire script). 

```{r}
sensory <- sensory %>% 
  rename(Panellist = Judge, Sample = Product)
```

To visualize the changes, you would need to type `newsensory` or `sensory` in R.
Another (faster) way to visualize it is to put the entire block of code between brackets: Putting code between brackets is equivalent to asking to print the output. 

```{r}
(sensory <- sensory %>% 
  rename(Panellist = Judge, Sample = Product))
```

Note that if you run all these lines of codes in R, you will get an error stating `Column 'Judge' doesn't exist.` This is a good illustration of a potential error mentioned above: We overwrote the original `sensory` (containing `Judge` and `Product`) with another version in which these columns were already renamed as `Panellist` and `Sample`. So when you re-run this code, you are trying to apply again the same changes to columns that no longer exist, hence the error...
This is something that you need to take into consideration when overwriting elements (in this case, you should initialize `sensory` to its original version before trying).

#### Calling Variables

In R, variables can be called in different ways when programming. If the names of variables should be read from the data (e.g. "Product", "products", "samples", etc.), you will often use strings, meaning that the name used will be defined between quotes (e.g. `"Product"`). 

Within the `{tidyverse}`, the names of variables that are included within a data set are usually called as it is, without quote:

```{r}
sensory %>% 
  dplyr::select(Judge, Product, Shiny)
```

This is true for simple names that do not contain any special characters (e.g. space, `-, etc.`). For names that contain special characters, the use of backticks are required (backticks can also be used with simple names):

```{r}
sensory %>% 
  dplyr::select(`Judge`, Product, `Color evenness`).
```

While going through this book, you'll notice that many functions from the `{tidyverse}` sometimes require quotes, and sometimes doesn't. The simple way to know whether quotes are required or not is based on its existence in the data set or not: If the column exists and should be used, no quotes should be used. On the contrary, if the variable doesn't exist and should be created, then quotes should be used.

Let's illustrate this through a simple example involving `pivot_longer()` and `pivot_wider()` successively. For `pivot_longer()`, we create two new variables,one that contains the column names (informed by `names_to`) and one that contains the values (informed by `values_to`). Since these variables are being created, quotes are required for the new names. For `pivot_wider()`, quotes are not needed since the names of the variables to use (`names_from` and `values_from`) are present in the data:

```{r}
sensory %>% 
  pivot_longer(Shiny:Melting, names_to="Variables", values_to="Scores") %>% 
  pivot_wider(names_from=Variables, values_from=Scores)
```
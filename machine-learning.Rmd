```{r include=FALSE}
knitr::opts_chunk$set(echo = TRUE, eval = FALSE)
```

# Machine Learning {#machine-learning}

## Overview

```{r classification_Aigora_ml_training}

# Install and load libraries ----------------------------------------------

# install.packages(c("tidyverse", "tidymodels", "rattle",
#                    "ggplot2", " factoextra", "ranger",
#                    "ggfortify", "cluster"))
library(tidyverse)
library(rattle) # wine dataset
library(ggplot2)
require(factoextra)
library(tidymodels)
library(ranger)
library(ggfortify) # PCA visualization
library(cluster)

# Data ----------------------------------------------

set.seed(123)
wine_dataset <- tibble(wine) %>% 
  select(-Type) # We drop type, to present possibility of generating the target using unsupervised methods


# PCA without scaling -----------------------------------------------------

pca_results_ws <- wine_dataset %>%
  prcomp()

summary(pca_results_ws)
autoplot(pca_results_ws)

pca_ws_plot <- autoplot(pca_results_ws, data = wine_dataset,,
                   loadings = TRUE, loadings.colour = 'red',
                   loadings.label = TRUE, loadings.label.size = 3) +
  theme_minimal()

pca_ws_plot
# ggsave("output/pca_without_scaling.jpg", pca_ws_plot)

# scaling data + PCA -----------------------------------------------------------

pca_results <- wine_dataset %>%
  prcomp(scale. = TRUE)

summary(pca_results)
plot(pca_results)

pca_plot <- autoplot(pca_results, data = wine_dataset,,
               loadings = TRUE, loadings.colour = 'red',
               loadings.label = TRUE, loadings.label.size = 3) +
  theme_minimal()

pca_plot
# ggsave("output/pca.jpg", pca_plot)

reduced_dataset <- data.frame(pca_results$x[, 1:2]) %>%
  tibble()
# we can see that clustering should be easy

# Clustering  -------------------------------------------------------------

# Finding number of clusters - Elbow method
wcss <- tibble()
for (i in 1:10) {
  
  wcss <- wcss %>% 
    bind_rows(tibble(n_clusters = i,
                     wcss = kmeans(reduced_dataset, i)$tot.withinss))
  
}

ggplot(data=wcss, aes(x=n_clusters, y=wcss, group=1)) +
  geom_line(size = 1.5)+
  geom_point(shape=21, fill="blue", color="darkred", size=5) +
  theme_minimal() +
  xlab("Number of clusters") +
  ylab("Total within-cluster sum of squares")

# ggsave("output/n_clusters_decision_Elbow.jpg")

# Finding number of clusters - silhouette method
fviz_nbclust(reduced_dataset, kmeans, method = "silhouette")
# ggsave("output/n_clusters_decision_silhouette.jpg")

# 3 clusters seems to be good fit

km_dw <- kmeans(reduced_dataset, 3, nstart = 20)

km_dw

fviz_cluster(
  list(data = reduced_dataset, cluster = km_dw$cluster),
  ellipse.type = "norm",
  geom = "point",
  stand = FALSE
)

# ggsave("output/clustered_data.jpg")

# Classification ----------------------------------------------------------

# Dataset preparation
wine_classification_dataset <- reduced_dataset %>% 
  bind_cols(tibble(Wine_type = km_dw$cluster)) %>% # Our classification label is the clustering output
  mutate(Wine_type = as.factor(Wine_type))

initial_split <- initial_split(data = wine_classification_dataset, strata = "Wine_type", prop = 0.7)

wine_train <- training(initial_split)
wine_testing <- testing(initial_split)

wine_cv <- wine_train %>% vfold_cv(5,strata = Wine_type)

# Random forest model definition
model_recipe <- wine_train %>% 
  recipe(Wine_type ~ .)

rf_spec <- rand_forest(
  mtry = tune(),
  trees = tune(),
  min_n = tune()) %>%
  set_mode("classification") %>% 
  set_engine(engine = "ranger")

rf_wf <- workflow() %>%
  add_recipe(model_recipe) %>% 
  add_model(rf_spec)


# Best parameters searching

params_grid <- rf_spec %>%
  parameters() %>%
  update(mtry = mtry(range = c(1, 2)),
         trees = trees(range = c(10, 200))) %>% 
  grid_regular(levels = 5)

tuning <- tune_grid(
  rf_wf,
  resamples = wine_cv,
  grid = params_grid
)

autoplot(tuning)

params_best <- select_best(tuning, "roc_auc")

# Finalize model 

final_model <- rf_wf %>%
  finalize_workflow(params_best) %>%
  fit(wine_train)

validation_data_pred <- wine_testing %>%
  bind_cols(predict(final_model, .))

cm <- conf_mat(validation_data_pred, Wine_type, .pred_class)

autoplot(cm, type = "heatmap")
```

```{r regression_data_generation_Aigora_ml_training}
library(tidyverse)

n_rows <- 100

with(set.seed(1),
     data <- tibble(
       id = sprintf("product_%d", 1:n_rows)
     ) %>%
       mutate(
         sensory_1 = runif(n(), 0, 6),
         sensory_2 = runif(n(), 4, 8),
         sensory_3 = pmax(0, pmin(10, rnorm(n(), 6, 1.5))),
         sensory_4 = runif(n(), 0, 2),
         sensory_5 = runif(n(), 0, 2),
         sensory_6 = pmax(0, pmin(10, rnorm(n(), 3, 1))),
         sensory_7 = runif(n(), 3, 10)
       ) %>%
       mutate(
         liking = 
           - 0.2 * abs(sensory_1-2.5)
         + 0.6 * sensory_2
         + 0.4 * sensory_3
         + 0.2 * abs(sensory_4-1)
         - 0.3 * sensory_5
         + 0.1 * sensory_6
         + 0.2 * sensory_7
       ) %>%
       mutate(liking = pmin(9.74, rnorm(n(), 1, 0.1) * liking))
)

summary(data)

# write_rds(data, "data/regression_data.rds")

```

```{r regression_Aigora_ml_training}
# Tutorial content:
#   1. Split data
#   2. Define model
#   3. Tune hyperparameters
#   4. Visualize results
#   5. Explore model with DALEX and modelStudio


# Install and load libraries ----------------------------------------------

# install.packages(c("tidyverse", "tidymodels", "remotes",
#                    "DALEXtra", " modelStudio", "r2d3"))
# remotes::install_github("aigorahub/aigoraOpen")
library(tidyverse)
library(tidymodels)
library(aigoraOpen)


# Load data ---------------------------------------------------------------

data <- read_rds("data/regression_data.rds")

set.seed(123)

data_split <- initial_split(data)

training_data <- training(data_split)
validation_data <- testing(data_split)

resampling <- vfold_cv(training_data, v = 10)

# Define model ------------------------------------------------------------

model_recipe <- training_data %>%
  select(-id) %>% # id shouldn't be used by the model
  recipe(liking ~ .) %>%
  step_earth(all_predictors(), outcome = "liking")

model_spec <- linear_reg(
  penalty = tune(),
  mixture = tune()
) %>%
  set_mode("regression") %>%
  set_engine("glmnet")

model_workflow <- workflow() %>%
  add_recipe(model_recipe) %>%
  add_model(model_spec)


# Tune model hyperparameters (grid search) ---------------------------------

set.seed(124)

params_grid <- model_spec %>%
  parameters() %>%
  grid_regular(levels = 10)

tuning <- tune_grid(
  model_workflow,
  resamples = resampling,
  grid = params_grid
)

autoplot(tuning)

params_best <- select_best(tuning, "rmse")


# Zoom in grid search -----------------------------------------------------

set.seed(125)

penalty_levels <- sort(unique(params_grid$penalty))
mixture_levels <- sort(unique(params_grid$mixture))

penalty_new_range <- c(
  penalty_levels[lead(penalty_levels, default = 0) == params_best$penalty],
  penalty_levels[lag(penalty_levels, default = 0) == params_best$penalty]
)
mixture_new_range <- c(
  mixture_levels[lead(mixture_levels, default = 0) == params_best$mixture],
  mixture_levels[lag(mixture_levels, default = 0) == params_best$mixture]
)

params_grid_2 <- model_spec %>%
  parameters() %>%
  update(
    penalty = penalty(log10(penalty_new_range)),
    mixture = mixture(mixture_new_range)
  ) %>%
  grid_regular(levels = 10)

tuning_2 <- tune_grid(
  model_workflow,
  resamples = resampling,
  grid = params_grid_2
)

autoplot(tuning_2)

params_best_2 <- select_best(tuning_2, "rmse")


# Finalize model ----------------------------------------------------------

final_model <- model_workflow %>%
  finalize_workflow(params_best_2) %>%
  fit(training_data)

validation_data_pred <- validation_data %>%
  bind_cols(predict(final_model, .))

metric_set(rmse, rsq)(validation_data_pred, liking, .pred)

validation_data_pred %>%
  ggplot(aes(liking, .pred)) +
  geom_point() +
  geom_abline(slope = 1, intercept = 0, linetype = 2)


# Model Studio ------------------------------------------------------------

library(DALEXtra)
library(modelStudio)

explainer <- explain_tidymodels(
  final_model, 
  data = training_data %>% 
    column_to_rownames("id") %>%
    select(-liking),
  y = training_data$liking
)

resid <- model_performance(explainer)
resid
plot(resid)

var_imp <- variable_importance(explainer)
plot(var_imp)

ms <- modelStudio(
  explainer,
  new_observation = validation_data %>%
    column_to_rownames("id") %>%
    select(-liking),
  new_observation_y = round(validation_data$liking, 3)
)

# r2d3::save_d3_html(ms, "output/modelstudio.html")

```




## Key Topics

### Model Validation
### Unsupervised learning
#### Cluster analysis
#### Factor analysis
#### Principle components analysis
#### t-SNE
### Semisupervised learning
#### PLS regression
#### Cluster Characterization
### Supervised learning
#### Regression
#### K-nearest neighbors
#### Decision trees
#### Black boxes
##### Random forests
##### SVMs
##### Neural networks
##### Computer vision
### Interpretability 
#### LIME
#### DALEX
#### IML

## Common Applications
### Predicting sensory profiles from instrumental data
### Predicting consumer response from sensory profiles
### Characterizing consumer clusters

## Code Examples

### Data Prep

```{r data-prep}

data <- readr::read_rds('data/masked_data.rds')
nrows <- max(summary(data$Class)) * 2

data_over <- ROSE::ROSE(Class ~ .,
                        data = data %>% 
                          mutate(across(starts_with('D'), factor, levels = c(0, 1))),
                        N = nrows, seed = 1)$data

readr::write_rds(data_over, 'data/data_classification.rds')

readxl::read_excel('data/data_regression.xlsx') %>%
  select(-`...1`, -judge, -product, -(steak:V64), -`qtt.drink.(%)`) %>%
  rename(socio_professional = `socio-professional`) %>%
  readr::write_rds('data/data_regression.rds')


```


### Classification Code

```{r classification-code}

library(tidyverse)
library(tidymodels)


# Load data ---------------------------------------------------------------

data <- read_rds('data/data_classification.rds')

# Inspect the data --------------------------------------------------------

summary(data)

data <- data %>% select(-ID)

skimr::skim(data)

data %>%
  mutate(across(starts_with('D'), factor, levels = c(0, 1))) %>%
  GGally::ggpairs(aes(fill = Class))



# Split data for models ---------------------------------------------------

# Set test set aside
train_test_split <- initial_split(data)
train_test_split

train_set <- training(train_test_split)
test_set <- testing(train_test_split)

# Split set fot cross-validation
resampling <- vfold_cv(train_set, 10)
resampling


# Fit MARS model ----------------------------------------------------------

usemodels::use_earth(
  Class ~ .,
  data = train_set
  )

earth_recipe <- 
  recipe(formula = Class ~ ., data = train_set) %>% 
  step_novel(all_nominal(), -all_outcomes()) %>% 
  step_dummy(all_nominal(), -all_outcomes()) %>% 
  step_zv(all_predictors()) 

earth_spec <- 
  mars(
    num_terms = tune(),
    prod_degree = tune(),
    prune_method = "none"
    ) %>% 
  set_mode("classification") %>% 
  set_engine("earth") 

earth_workflow <- 
  workflow() %>% 
  add_recipe(earth_recipe) %>% 
  add_model(earth_spec) 

earth_grid <- tidyr::crossing(num_terms = 2 * (1:6), prod_degree = 1:2) 
earth_grid

earth_tune <- 
  tune_grid(
    earth_workflow, 
    resamples = resampling, 
    # Save predictions for further steps
    control = control_grid(save_pred = TRUE, verbose = TRUE),
    # Test parameters on a grid defined above
    grid = earth_grid
  ) 


# Check model performance -------------------------------------------------

earth_tune %>% show_best(n = 10)
earth_tune %>% autoplot()

earth_predictions <- earth_tune %>%
  collect_predictions(parameters = select_best(., 'roc_auc')) %>%
  mutate(model = "MARS")

earth_predictions %>%
  roc_curve(Class, .pred_A) %>%
  autoplot()

earth_predictions %>%
  lift_curve(Class, .pred_A) %>%
  autoplot()

earth_predictions %>%
  pr_curve(Class, .pred_A) %>%
  autoplot()

earth_predictions %>%
  conf_mat(Class, .pred_class) %>%
  autoplot()


# Fit decision tree -------------------------------------------------------

tree_recipe <- 
  recipe(formula = Class ~ ., data = train_set) %>% 
  step_novel(all_nominal(), -all_outcomes()) %>% 
  step_zv(all_predictors()) 

tree_spec <- 
  decision_tree(
    cost_complexity = tune(),
    tree_depth = tune(),
    min_n = tune()
    ) %>% 
  set_mode("classification") %>% 
  set_engine("rpart") 

tree_workflow <- 
  workflow() %>% 
  add_recipe(tree_recipe) %>% 
  add_model(tree_spec) 

tree_tune <- 
  tune_grid(
    tree_workflow, 
    resamples = resampling, 
    # Save predictions for further steps
    control = control_grid(save_pred = TRUE, verbose = TRUE),
    # Test 20 random combinations of parameters
    grid = 20
  ) 

# Check model performance -------------------------------------------------

tree_tune %>% show_best(n = 10)
tree_tune %>% autoplot()

tree_predictions <- tree_tune %>%
  collect_predictions(parameters = select_best(., 'roc_auc')) %>%
  mutate(model = "Decision Tree")

tree_predictions %>%
  bind_rows(earth_predictions) %>%
  group_by(model) %>%
  roc_curve(Class, .pred_A) %>%
  autoplot()

tree_predictions %>%
  bind_rows(earth_predictions) %>%
  group_by(model) %>%
  lift_curve(Class, .pred_A) %>%
  autoplot()

tree_predictions %>%
  bind_rows(earth_predictions) %>%
  group_by(model) %>%  pr_curve(Class, .pred_A) %>%
  autoplot()

tree_predictions %>%
  conf_mat(Class, .pred_class) %>%
  autoplot()


# Let's go with MARS model ------------------------------------------------

final_fit <- earth_workflow %>%
  finalize_workflow(select_best(earth_tune, 'roc_auc')) %>%
  last_fit(train_test_split)

final_fit %>% collect_metrics()

final_fit %>%
  collect_predictions() %>%
  roc_curve(Class, .pred_A) %>%
  autoplot()

final_model <- final_fit %>%
  pluck(".workflow", 1) %>%
  fit(data)

final_model %>%
  pull_workflow_fit() %>% 
  vip::vip()

final_model %>%
  pull_workflow_fit() %>%
  pluck("fit") %>%
  summary

write_rds(final_model, 'classification_model.rds')


# Predict something -------------------------------------------------------

model <- read_rds('classification_model.rds')

new_observation <- tibble(
  N1 = 1.8,
  D1 = factor(0),
  D2 = factor(0),
  D3 = factor(1),
  D4 = factor(0),
  D5 = factor(1),
  D6 = factor(0),
  D7 = factor(1),
  D8 = factor(1),
  D9 = factor(1),
  D10 = factor(1),
  D11 = factor(0)
)

predict(model, new_observation, type = "class")
predict(model, new_observation, type = "prob")





```



### Regression Code

```{r regression-code}

library(tidyverse)
library(tidymodels)


# Load data ---------------------------------------------------------------

data <- read_rds('data/data_regression.rds')
glimpse(data)

# Inspect the data --------------------------------------------------------

summary(data)

skimr::skim(data)

# Split data for models ---------------------------------------------------

# Set test set aside
train_test_split <- initial_split(data)
train_test_split

train_set <- training(train_test_split)
test_set <- testing(train_test_split)

# Split set fot cross-validation
resampling <- vfold_cv(train_set, 10)
resampling


# Fit glmnet model ----------------------------------------------------------

usemodels::use_glmnet(
  Liking ~ .,
  data = train_set
)

glmnet_recipe <- 
  recipe(formula = Liking ~ ., data = train_set) %>% 
  step_novel(all_nominal(), -all_outcomes()) %>% 
  step_dummy(all_nominal(), -all_outcomes()) %>% 
  step_zv(all_predictors()) %>% 
  step_normalize(all_predictors(), -all_nominal())

glmnet_spec <- 
  linear_reg(penalty = tune(), mixture = tune()) %>% 
  set_mode("regression") %>% 
  set_engine("glmnet") 

glmnet_workflow <- 
  workflow() %>% 
  add_recipe(glmnet_recipe) %>% 
  add_model(glmnet_spec) 

glmnet_grid <- tidyr::crossing(penalty = 10^seq(-6, -1, length.out = 20), 
                               mixture = c(0.05, 0.2, 0.4, 0.6, 0.8, 1)) 

glmnet_tune <- 
  tune_grid(
    glmnet_workflow, 
    resamples = resampling, 
    # Save predictions for further steps
    control = control_grid(save_pred = TRUE, verbose = TRUE),
    # Test parameters on a grid defined above
    grid = glmnet_grid
    ) 

# Check model performance -------------------------------------------------

glmnet_tune %>% show_best(n = 10)
glmnet_tune %>% autoplot()

glmnet_predictions <- glmnet_tune %>%
  collect_predictions(parameters = select_best(., 'rmse')) %>%
  mutate(model = "GLMNet",
         .resid = Liking - .pred)

glmnet_predictions %>%
  ggplot(aes(sample = .resid)) +
  geom_qq() +
  geom_qq_line()

glmnet_predictions %>%
  ggplot(aes(.pred, Liking)) +
  geom_point() +
  geom_abline(slope = 1, intercept = 0)

glmnet_predictions %>%
  ggplot(aes(.pred, .resid)) +
  geom_point() +
  geom_hline(yintercept = 0)

ggplot(glmnet_predictions, aes(x = .resid)) + 
  geom_histogram(aes(y =..density..), fill = 'white', color = 'black') +
  stat_function(fun = dnorm,
                args = list(mean = mean(glmnet_predictions$.resid), 
                            sd = sd(glmnet_predictions$.resid)),
                size = 1)

# Fit random forest -------------------------------------------------------

rf_recipe <- 
  recipe(formula = Liking ~ ., data = train_set) %>% 
  step_novel(all_nominal(), -all_outcomes()) %>% 
  step_zv(all_predictors()) 

rf_spec <- 
  rand_forest(
    mtry = tune(), 
    min_n = tune(),
    trees = 50
    ) %>% 
  set_mode("regression") %>% 
  set_engine("ranger", importance = "impurity") 

rf_workflow <- 
  workflow() %>% 
  add_recipe(rf_recipe) %>% 
  add_model(rf_spec) 

rf_tune <- 
  tune_grid(
    rf_workflow, 
    resamples = resampling, 
    # Save predictions for further steps
    control = control_grid(save_pred = TRUE, verbose = TRUE),
    # Test 20 random combinations of parameters
    grid = 20
  ) 

# Check model performance -------------------------------------------------

rf_tune %>% show_best(n = 10)
rf_tune %>% autoplot()

rf_predictions <- rf_tune %>%
  collect_predictions(parameters = select_best(., 'rmse')) %>%
  mutate(model = "Random Forest",
         .resid = Liking - .pred)

rf_predictions %>%
  bind_rows(glmnet_predictions) %>%
  ggplot(aes(sample = .resid)) +
  geom_qq() +
  geom_qq_line() +
  facet_wrap(~model)

rf_predictions %>%
  bind_rows(glmnet_predictions) %>%
  ggplot(aes(.pred, Liking)) +
  geom_point() +
  geom_abline(slope = 1, intercept = 0) +
  facet_wrap(~model)

rf_predictions %>%
  bind_rows(glmnet_predictions) %>%
  ggplot(aes(.pred, .resid)) +
  geom_point() +
  geom_hline(yintercept = 0) +
  facet_wrap(~model)

rf_predictions %>%
  ggplot(aes(x = .resid)) + 
  geom_histogram(aes(y =..density..), fill = 'white', color = 'black') +
  stat_function(fun = dnorm,
                args = list(mean = mean(rf_predictions$.resid), 
                            sd = sd(rf_predictions$.resid)),
                size = 1)

# Let's go with rf model ------------------------------------------------

final_fit <- glmnet_workflow %>%
  finalize_workflow(select_best(glmnet_tune, 'rmse')) %>%
  last_fit(train_test_split)

final_fit <- rf_workflow %>%
  finalize_workflow(select_best(rf_tune, 'rmse')) %>%
  last_fit(train_test_split)

final_fit %>% collect_metrics()

final_fit %>%
  collect_predictions() %>%
  mutate(.resid = Liking - .pred) %>%
  ggplot(aes(sample = .resid)) +
  geom_qq() +
  geom_qq_line()

final_model <-  final_fit %>%
  pluck(".workflow", 1) %>%
  fit(data)

final_model %>%
  pull_workflow_fit() %>%
  vip::vip()

# final_model %>%
#   broom::tidy() %>%
#   filter(estimate != 0)

write_rds(final_model, 'regression_model.rds')

# Predict something -------------------------------------------------------

model <- read_rds('regression_model.rds')

new_observations <- data[1:2,]
new_observations

predict(model, new_observations)




```



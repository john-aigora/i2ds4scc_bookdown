```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, eval = FALSE)
```

# Machine Learning {#machine-learning}

Machine Learning is recently a hot topic in the sensory and consumer science field, proven to be one of the most game-changing technological advancements to support CPG companies in the development of new products, making a considerable role in speeding up and at the same time, reducing the cost or steps involved in the R&D process. In today's fast-moving and increasingly competitive corporate world, companies that are embracing, adopting and opening their minds to digital transformation and artificial intelligence, moving towards the age of automation, are not one but many steps ahead of their competitors.

Machine Learning (ML) is a branch of artificial intelligence based on the idea that systems can learn from data, that has the capability to evolve. Generally speaking, ML refers to various programming techniques that are able to process large amounts of data and extract useful information from it. It refers to a method of data analysis that build intelligent algorithms that can automatically improve through the experience gained from the data and identify patterns or make decisions with minimal human intervention. ML focuses on using data and algorithms to mimic the way humans learn, gradually improving their accuracy.

The definition of the objectives or the situation where ML would bring value refers to the very first step of the process. Once that is clear, the next step is to collect data or dig into the historical data sets to understand what information is available and/or has to be obtained. The data varies according to the situation, but it may refers to product composition or formulation, analytical measurements (E.g., pH, color, rheology, instrumental texture, GCMS, etc), sensory attributes (E.g., creaminess, sweetness, bitterness, texture, consistency, etc), or consumer behavior (E.g., frequency of consumption/use, consumption/use situation), demographics (E.g., age, gender, skin type, etc) and responses (E.g. liking, CATA questions, JAR questions, etc). 

The data set size and quality are very important and will directly impact the model's robustness. There will be specific recommendations on that according to the situation, data type, and objectives. In general, the higher the number of objects, which is usually the number of products or samples, the better, with being 10-14 the minimum recommended. The number of measurements (analytical,  sensory and/or consumer measurements) and the number of consumers evaluating the products are also very relevant to the model's quality. In the Sensory and consumer science field, the number of measurements is usually very high, so not something likely to worry about. Regarding the number of consumers, the minimum number recommended would be 100, but the more the better. Regarding data quality, one of the most important aspects, besides the standardization of data collection, refers to the variability of the products/samples. The higher the variability between samples, the broader the space the model will be covering. Additionally, it is strongly recommended the capture the consumers individual differences, not only demographic information, but also JAR questions and conducting the study in a sequential monadic design.

According to the purposes and goals, there are some variations on how to group or classify ML algorithms which can be divided into three prominent methods: supervised learning, unsupervised learning, and reinforcement learning. In this chapter, we will be focusing on the first two approaches.
 
## Methods Overview

Supervised learning is the most popular type of machine learning that uses labeled data, it is a process that involves providing input data as well as correct output data to the machine learning model. The ultimate goal of the algorithm is to find a mapping function to map input variables with output variables. In supervised learning, models are initially trained using a subset of the data (training data set) and afterwards, the model is tested and validated using the other part of the data (test data set and validation data set). Once this process is done, the model can continuously improve, discovering new patterns and relationships as it trains itself on new data sets.

A very common situation where supervised learning is widely used is to predict consumer responses (E.g., Liking, Perception, Benefit) based on analytical measurements and/or sensory data. In this situation, ML models can provide insights and directions on how to improve product performance and has also the ability to predict consumer response based on analytical and/or sensory data, working as a powerful screening tool where only prototypes or products with the highest potential are moved to the next level, which may be the consumer testing. Another common situation is the use of supervised machine learning to predict product sensory profile or consumer response, based on the formulation or ingredients of a product. In this situation, the ML would be of great support for the developers, who can much easier understand and get clear directions on what has to be changed in the formulation to improve the product sensory profile or consumer performance. 

Unlike supervised learning, unsupervised learning uses unlabeled or untagged data, which means inputs where the output values are not known. In this case, users do not need to supervise the model, instead, the algorithm operates independently to finds patterns and trends, trying to learn from the data distribution the distinguishing features and associations through similarity and dissimilarity measurements. Its ability to discover hidden patterns and get similarities/differences information is what make it the ideal solution for exploratory analysis and consumer segmentation, extracting insights from the data sets. 

Unsupervised machine learning is commonly used to segment consumers into groups based on their similarities related to a variety of factors such as behavior, preferences or habits, so that companies can understand and target specific segments effectively. Similarly, unsupervised models are also very used to classify group of products in homogeneous analytical, sensory and/or consumer attribute in order to identify different segments in the market.

<!--Change order: First Supervised and then Unsupervised? -->

https://www.ibm.com/cloud/learn/supervised-learning

https://www.javatpoint.com/supervised-machine-learning


### Unsupervised learning

Unsupervised learning models can be further categorized into two types: Clustering and Association.

#### Cluster analysis

The aim of cluster analysis is to discover in high-dimensional data groups of observations that are similar to each other in the group and significantly different from the rest of observations. As previously mentioned, a very common application in sensory and consumer science is to cluster consumers and classify groups of products based on their similarities/dissimilarities.

Let's start installing/loading the necessary packages and by preparing the dataset for the cluster analysis. We will be using the wine dataset (rattle package) that consists of the results of a chemical analysis of wines grown in a specific area of Italy. Three types of wine are represented in the 178 samples, with the results of 13 chemical analyses recorded for each sample. 

```{r prepare_data}
library(tidyverse)
library(rattle) # wine dataset
require(factoextra)
library(ranger)
library(ggfortify) # PCA visualization
library(cluster)

# load data

wine.fl <- "http://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data"
wine <- read.csv(wine.fl,header = F)

# Names of the variables

wine.names=c("Alcohol", "Malic acid", "Ash", "Alcalinity of ash", "Magnesium",
             "Total phenols", "Flavanoids", "Nonflavanoid phenols", "Proanthocyanins",
             "Color intensity", "Hue", "OD280/OD315 of diluted wines", "Proline")
colnames(wine)[2:14]=wine.names
colnames(wine)[1]="Wine_type"

set.seed(123)
wine_dataset <- tibble(wine)

```


<!-- cluster analysis in consumer analysis as semisupervised learning -->

<!-- #### Factor analysis -->
<!-- #### Principle components analysis -->

<!-- Tian comments: Why do we need PCA before cluster analysis? Or in what situation -->
<!-- a PCA is beneficial before clustering? -->


comparing PCA with and without scaling

```{r pca_without_scaling}
pca_results_ws <- wine_dataset %>%
  prcomp()

summary(pca_results_ws)
autoplot(pca_results_ws)

pca_ws_plot <- autoplot(pca_results_ws, data = wine_dataset,
                   loadings = TRUE, loadings.colour = 'red',
                   loadings.label = TRUE, loadings.label.size = 3) +
  theme_minimal()

pca_ws_plot

```

```{r pca_with_scaling}
# scaling data + PCA -----------------------------------------------------------

pca_results <- wine_dataset %>%
  prcomp(scale. = TRUE)

summary(pca_results)
plot(pca_results)

pca_plot <- autoplot(pca_results, data = wine_dataset,
               loadings = TRUE, loadings.colour = 'red',
               loadings.label = TRUE, loadings.label.size = 3) +
  theme_minimal()

pca_plot

reduced_dataset <- data.frame(pca_results$x[, 1:2]) %>%
  tibble()
# we can see that clustering should be easy

```

<!-- Clustering  -->
<!-- Using Elbow method to find the optimum number of cluster numbers -->

<!-- kmeans vs hierarchical clustering, is nbclust only valid for kmeans? -->

```{r find_opt_cluster_number}

wcss <- tibble()
for (i in 1:10) {
  
  wcss <- wcss %>% 
    bind_rows(tibble(n_clusters = i,
                     wcss = kmeans(reduced_dataset, i)$tot.withinss))
  
}

ggplot(data=wcss, aes(x=n_clusters, y=wcss, group=1)) +
  geom_line(size = 1.5)+
  geom_point(shape=21, fill="blue", color="darkred", size=5) +
  theme_minimal() +
  xlab("Number of clusters") +
  ylab("Total within-cluster sum of squares")

# Finding number of clusters - silhouette method
fviz_nbclust(reduced_dataset, kmeans, method = "silhouette")

# 3 clusters seems to be good fit

```

<!-- Tian comments:from sensory consumer data analysis point of view, when to  -->
<!-- use kmeans, when to use hierarchical? etc. -->
```{r kmeans_cluster_analysis}

km_dw <- kmeans(reduced_dataset, 3, nstart = 20)

km_dw

fviz_cluster(
  list(data = reduced_dataset, cluster = km_dw$cluster),
  ellipse.type = "norm",
  geom = "point",
  stand = FALSE
)

```


<!-- #### t-SNE -->
<!-- ### Semisupervised learning -->
<!-- #### PLS regression -->
<!-- #### Cluster Characterization -->



### Supervised learning

#### Regression

Regression methods approximate the target variable^[This is a bit of simplification. 
In some cases it is some transformation of combination of predictors that 
approximates target variable. An example of this is logistic regression.]
with (usually linear) combination of predictor variables. 

There are multiple regression algorithms varying by type of data they can handle,
type of target variable and additional aspects like ability to perform 
dimensionality reduction. We will take a walk through the ones most relevant for 
sensory and consumer science.

##### Linear regression

The simplest and most popular variant is linear regression in which continuous 
target variable is approximated as linear combination of predictors in a way that 
minimizes sum of squared estimates of errors (SSE). It can be for example used to 
predict consumer liking of a product based on it's sensory profile, but user has
to keep in mind that linear regression can in some cases return value outside 
reasonable range of target values. This can be addressed by capping predictions 
to desired range. Functions in R to apply linear regression are: `lm()` and `glm()`
or `parsnip::linear_reg() %>% parsnip::set_engine("lm")` when using `tidymodels` workflow.

##### Logistic regression

Logistic regression is an algorithm which by use of logistic transformation allows
to apply the same approach as linear regression to cases with binary target variables.
It can be used in R with `glm(family = "binomial")` or
`parsnip::logistic_reg() %>% parsnip::set_engine("glm")` when using `tidymodels` workflow.

##### Penalized regression 

It is often that the data we want to use for modeling have a lot of predictor 
variables, possibly with lot of high correlations. In such cases linear/logistic
regression may become unstable and produce unreasonable predictions. This can be
addressed by use of so called penalized regression. It is a special case where 
instead of minimizing pure error term, algorithm minimizes both error and regression 
coefficients at the same time. This leads to more stable predictions.

There are three variations of penalized regression and all of them can be accessed
via function `glmnet::glmnet()` ($\beta$ is set of regression coefficients and 
$\lambda$ is a parameter to be set by user or determined from cross-validation):

+ Ridge regression (L2 penalty) minimizes $SSE + \lambda \sum|\beta|^2$ and drives
the coefficients to smaller values
+ Lasso regression (L1 penalty) $SSE + \lambda \sum|\beta|$ and forces some of the
coefficients to vanish what can be used for variable selection
+ Elastic-net regression is a combination of the two previous variants 
$SSE + \lambda_1 \sum|\beta| + \lambda_2 \sum|\beta|^2$.

Penalized regression can be also runned in `tidymodels` workflow with 
or `parsnip::linear_reg() %>% parsnip::set_engine("glmnet")`.

##### MARS

One limitation of all mentioned so far methods is that they assume linear relationship
between predictor and target variables. Multivariate adaptive regression spline (MARS)
addresses this by modeling nonlinearities with piecewise linear function. This
gives a nice balance between simplicity and ability to fit complex data, for example
$\Lambda$-shaped once where there is a maximal point from which function decreases 
in both directions. In R this model can be accesed via `earth::earth()` function.

##### PLS

In case of multiple target variables one can apply partial least squares (PLS) regression
which, similarly to PCA looks for components that maximizes explained variance of
the predictors, but at the same time also maximizes their correlation to target variables.
PLS can be applied with `lm()` specifying multiple targets or in `tidymodels` workflow
with `plsmod::pls() %>% parsnip::set_engine("mixOmics")`.

#### K-nearest neighbors

A very simple, yet useful and robust algorithm that works for both numeric and nominal
target variables is K-nearest neighbors. The idea is that for every new observation
we want to predict the algorithms finds K closest points in training set and use
either their mean value (for numeric targets) or most frequent value (for nominal targets)
as prediction. This algorithm can be used with `kknn::kknn()` function or in `tidymodels` workflow
with `parsnip::nearest_neighbor() %>% parsnip::set_engine("kknn")`.

#### Decision trees

Decision tree models the data by splitting the training set in smaller subsets 
in a way that each split is done by a predictor variable so that it maximizes 
the difference in target variable between the subsets. One important advantage 
of decision trees is that they can model complex relationships and interactions
between predictors. To use decision tree in R one can use `rpart::rpart()` or
in `tidymodels` workflow with `parsnip::decision_tree() %>% parsnip::set_engine("rpart")`.

#### Black boxes

So called black boxes are class of models that have too complex structure to directly
interpret relationship between predictor variables and a value predicted by the model.
Their advantage usually is ability to model more complicated data than in case of
interpretable models, but they have greater risk of overfitting (fitting to
noise in training data). Also, lack of clear interpretation may be not acceptable
in some business specific use cases. The later problem can be addressed by use of 
explanation algorithms that will be discussed in later part of this chapter.

##### Random forests

A random forest is a set of decision trees, each one trained on random subset 
of observations and/or predictors. The final prediction is an average of individual
trees' predictions. This way 





##### SVMs
##### Neural networks
##### Computer vision

## Key Topics

### Model Validation

### Interpretability 
#### LIME
#### DALEX
#### IML

## Common Applications
### Predicting sensory profiles from instrumental data
### Predicting consumer response from sensory profiles
### Characterizing consumer clusters

## Code

<!-- introduce tidymodel -->

tidyverse and tidymodel

The tidymodels framework is a collection of packages for modeling and machine learning using tidyverse principles.

``` {r install_load_tidymodels}

install.packages("tidymodels")
library(tidymodels)

```

here we use the wine dataset to build our model. 


First we prepare our 

```{r classification_Aigora_ml_training}

# Classification ----------------------------------------------------------

# Dataset preparation
wine_classification_dataset <- wine_dataset %>% 
  # bind_cols(tibble(Wine_type = km_dw$cluster)) %>% # Our classification label is the clustering output
  mutate(Wine_type = as.factor(Wine_type))
```

The function rsample::initial_split() takes the original data and saves the information on how to make the partitions.
Here we used the strata argument, which conducts a stratified split. This ensures that, despite the imbalance we noticed in our class variable, our training and test data sets will keep roughly the same proportions of all Wine types as in the original data. After the initial_split, the training() and testing() functions return the actual data sets. (!!!copied from tidymodels documentation)
```{r prep_train_test_data}
initial_split <- initial_split(data = wine_classification_dataset, strata = "Wine_type", prop = 0.7)

wine_train <- training(initial_split)
wine_testing <- testing(initial_split)

```

There is https://www.tidymodels.org/start/resampling/#resampling cool graph and explanation of cross-validation
```{r cv}
wine_cv <- wine_train %>% vfold_cv(5,strata = Wine_type)
```
The recipe package is part of tidymodels. It contains rich set of data manipulation tools which can be used to preprocess data and to define role of each variables (e.g. outcome and predictor)
```{r recipe}
# Random forest model definition
model_recipe <- wine_train %>% 
  recipe(Wine_type ~ .)
```
We decided to use random forest classifier. This method has 3 hyperparameters which can be tuned to achieve best results (mtry, trees, min_n). "Most often you would like to change a parameters from its default but you are not sure what the final value will be. This is the basis for model tuning where we use the tune package. Since the model is not executing when created, these types of parameters can be changed using the tune() function. This provides a simple placeholder for the value" (https://parsnip.tidymodels.org/articles/parsnip.html?q=tune#placeholders-for-parameters).
```{r method_selection_and_placeholder_for_parameters}
rf_spec <- rand_forest(
  mtry = tune(),
  trees = tune(),
  min_n = tune()) %>%
  set_mode("classification") %>% 
  set_engine(engine = "ranger")

```
Let's combine the model and recipe into a single workflow () object to help manage R objects
```{r workflow_def}
rf_wf <- workflow() %>%
  add_recipe(model_recipe) %>% 
  add_model(rf_spec)
```
We created placeholders for hyperparameters 2 steps earlier. Now it's time to define the scope of the search and to choose the method of searching the parameter space (in this example it is grid_regular)
```{r grid_def}
params_grid <- rf_spec %>%
  parameters() %>%
  update(mtry = mtry(range = c(1, 2)),
         trees = trees(range = c(10, 200))) %>% 
  grid_regular(levels = 5)

```
We already have the hyperparameter search range defined. Now let's look for the best combination using tune_grid() function. We will use a cross-validation set for this purpose. We leave the test set aside, so that the model during training certainly does not see the data on which we will be making predictions. Proceeding in this way, we will obtain a reliable estimate of the quality of the model. Finally we select the best combination using select_best() function. The quality of the model can be estimated with a number of metrics. Here we decided to use roc_auc (Area Under the Receiver Operating Characteristic Curve)
```{r tuning_hyperparams}
# Best parameters searching

tuning <- tune_grid(
  rf_wf,
  resamples = wine_cv,
  grid = params_grid
)

autoplot(tuning)
params_best <- select_best(tuning, "roc_auc")
```
The time has come to train the final model on the entire training set. 
```{r fit_best_model}
# Finalize model 

final_model <- rf_wf %>%
  finalize_workflow(params_best) %>%
  fit(wine_train)

```
A very important step in solving the problem with machine learning methods is the assessment of the quality of the model. The first step in this process is to make a prediction on the out of sample set (one that the model has not seen while training). 
```{r prediction}
validation_data_pred <- wine_testing %>%
  bind_cols(predict(final_model, .))

```
Having predicted wine classes and actual labels, we can finally judge the quality of the model by comparing them. A very pleasant method for classification problems is the confusion matrix and the associated statistics (accuracy, sensitivity specificity, precision, F1 score and a lot more: https://en.wikipedia.org/wiki/Confusion_matrix). 
```{r cm}
cm <- conf_mat(validation_data_pred, Wine_type, .pred_class)

autoplot(cm, type = "heatmap")
```

```{r regression_data_generation_Aigora_ml_training}
library(tidyverse)

n_rows <- 100

with(set.seed(1),
     data <- tibble(
       id = sprintf("product_%d", 1:n_rows)
     ) %>%
       mutate(
         sensory_1 = runif(n(), 0, 6),
         sensory_2 = runif(n(), 4, 8),
         sensory_3 = pmax(0, pmin(10, rnorm(n(), 6, 1.5))),
         sensory_4 = runif(n(), 0, 2),
         sensory_5 = runif(n(), 0, 2),
         sensory_6 = pmax(0, pmin(10, rnorm(n(), 3, 1))),
         sensory_7 = runif(n(), 3, 10)
       ) %>%
       mutate(
         liking = 
           - 0.2 * abs(sensory_1-2.5)
         + 0.6 * sensory_2
         + 0.4 * sensory_3
         + 0.2 * abs(sensory_4-1)
         - 0.3 * sensory_5
         + 0.1 * sensory_6
         + 0.2 * sensory_7
       ) %>%
       mutate(liking = pmin(9.74, rnorm(n(), 1, 0.1) * liking))
)

summary(data)

# write_rds(data, "data/regression_data.rds")

```

```{r regression_Aigora_ml_training}
# Tutorial content:
#   1. Split data
#   2. Define model
#   3. Tune hyperparameters
#   4. Visualize results
#   5. Explore model with DALEX and modelStudio


# Install and load libraries ----------------------------------------------

# install.packages(c("tidyverse", "tidymodels", "remotes",
#                    "DALEXtra", " modelStudio", "r2d3"))
# remotes::install_github("aigorahub/aigoraOpen")
library(tidyverse)
library(tidymodels)
library(aigoraOpen)


# Load data ---------------------------------------------------------------

# data <- read_rds("data/regression_data.rds")

set.seed(123)

data_split <- initial_split(data)

training_data <- training(data_split)
validation_data <- testing(data_split)

resampling <- vfold_cv(training_data, v = 10)

# Define model ------------------------------------------------------------

model_recipe <- training_data %>%
  select(-id) %>% # id shouldn't be used by the model
  recipe(liking ~ .) %>%
  step_earth(all_predictors(), outcome = "liking")

model_spec <- linear_reg(
  penalty = tune(),
  mixture = tune()
) %>%
  set_mode("regression") %>%
  set_engine("glmnet")

model_workflow <- workflow() %>%
  add_recipe(model_recipe) %>%
  add_model(model_spec)


# Tune model hyperparameters (grid search) ---------------------------------

set.seed(124)

params_grid <- model_spec %>%
  parameters() %>%
  grid_regular(levels = 10)

tuning <- tune_grid(
  model_workflow,
  resamples = resampling,
  grid = params_grid
)

autoplot(tuning)

params_best <- select_best(tuning, "rmse")


# Zoom in grid search -----------------------------------------------------

set.seed(125)

penalty_levels <- sort(unique(params_grid$penalty))
mixture_levels <- sort(unique(params_grid$mixture))

penalty_new_range <- c(
  penalty_levels[lead(penalty_levels, default = 0) == params_best$penalty],
  penalty_levels[lag(penalty_levels, default = 0) == params_best$penalty]
)
mixture_new_range <- c(
  mixture_levels[lead(mixture_levels, default = 0) == params_best$mixture],
  mixture_levels[lag(mixture_levels, default = 0) == params_best$mixture]
)

params_grid_2 <- model_spec %>%
  parameters() %>%
  update(
    penalty = penalty(log10(penalty_new_range)),
    mixture = mixture(mixture_new_range)
  ) %>%
  grid_regular(levels = 10)

tuning_2 <- tune_grid(
  model_workflow,
  resamples = resampling,
  grid = params_grid_2
)

autoplot(tuning_2)

params_best_2 <- select_best(tuning_2, "rmse")


# Finalize model ----------------------------------------------------------

final_model <- model_workflow %>%
  finalize_workflow(params_best_2) %>%
  fit(training_data)

validation_data_pred <- validation_data %>%
  bind_cols(predict(final_model, .))

metric_set(rmse, rsq)(validation_data_pred, liking, .pred)

validation_data_pred %>%
  ggplot(aes(liking, .pred)) +
  geom_point() +
  geom_abline(slope = 1, intercept = 0, linetype = 2)


# Model Studio ------------------------------------------------------------

library(DALEXtra)
library(modelStudio)

explainer <- explain_tidymodels(
  final_model, 
  data = training_data %>% 
    column_to_rownames("id") %>%
    select(-liking),
  y = training_data$liking
)

resid <- model_performance(explainer)
resid
plot(resid)

var_imp <- variable_importance(explainer)
plot(var_imp)

ms <- modelStudio(
  explainer,
  new_observation = validation_data %>%
    column_to_rownames("id") %>%
    select(-liking),
  new_observation_y = round(validation_data$liking, 3)
)

# r2d3::save_d3_html(ms, "output/modelstudio.html")

```


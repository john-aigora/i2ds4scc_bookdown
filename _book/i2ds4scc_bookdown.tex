% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
%
\documentclass[
]{book}
\usepackage{lmodern}
\usepackage{amsmath}
\usepackage{ifxetex,ifluatex}
\ifnum 0\ifxetex 1\fi\ifluatex 1\fi=0 % if pdftex
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
  \usepackage{amssymb}
\else % if luatex or xetex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\IfFileExists{bookmark.sty}{\usepackage{bookmark}}{\usepackage{hyperref}}
\hypersetup{
  pdftitle={Data Science for Sensory and Consumer Scientists},
  pdfauthor={John Ennis, Julien Delarue, and Thierry Worch},
  hidelinks,
  pdfcreator={LaTeX via pandoc}}
\urlstyle{same} % disable monospaced font for URLs
\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{248,248,248}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.94,0.16,0.16}{#1}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.77,0.63,0.00}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\BuiltInTok}[1]{#1}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.64,0.00,0.00}{\textbf{#1}}}
\newcommand{\ExtensionTok}[1]{#1}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ImportTok}[1]{#1}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\NormalTok}[1]{#1}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.81,0.36,0.00}{\textbf{#1}}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\RegionMarkerTok}[1]{#1}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\usepackage{longtable,booktabs}
\usepackage{calc} % for calculating minipage widths
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\usepackage{graphicx}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother
\setlength{\emergencystretch}{3em} % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{5}
\usepackage{booktabs}
\ifluatex
  \usepackage{selnolig}  % disable illegal ligatures
\fi
\usepackage[]{natbib}
\bibliographystyle{apalike}

\title{Data Science for Sensory and Consumer Scientists}
\author{John Ennis, Julien Delarue, and Thierry Worch}
\date{2021-04-22}

\begin{document}
\maketitle

{
\setcounter{tocdepth}{1}
\tableofcontents
}
\hypertarget{preface}{%
\chapter*{Preface}\label{preface}}
\addcontentsline{toc}{chapter}{Preface}

Welcome to the website for \emph{Data Science for Sensory and Consumer Scientists}, a book in development and under contract for \href{https://www.routledge.com/}{CRC Press}.

\begin{center}\includegraphics[width=13.44in]{images/cover_art} \end{center}

\hypertarget{who-should-read-this-book}{%
\section*{Who Should Read This Book?}\label{who-should-read-this-book}}
\addcontentsline{toc}{section}{Who Should Read This Book?}

\hypertarget{how-to-use-this-book}{%
\section*{How to Use This Book}\label{how-to-use-this-book}}
\addcontentsline{toc}{section}{How to Use This Book}

\hypertarget{cautions-dont-that-everybody-does}{%
\section*{Cautions: Don't that Everybody Does}\label{cautions-dont-that-everybody-does}}
\addcontentsline{toc}{section}{Cautions: Don't that Everybody Does}

\hypertarget{how-to-contact-us}{%
\section*{How to Contact Us}\label{how-to-contact-us}}
\addcontentsline{toc}{section}{How to Contact Us}

\hypertarget{acknowledgements}{%
\section*{Acknowledgements}\label{acknowledgements}}
\addcontentsline{toc}{section}{Acknowledgements}

\hypertarget{bienvenue}{%
\chapter{Bienvenue!}\label{bienvenue}}

\hypertarget{why-data-science-for-sensory-and-consumer-science}{%
\section*{Why Data Science for Sensory and Consumer Science?}\label{why-data-science-for-sensory-and-consumer-science}}
\addcontentsline{toc}{section}{Why Data Science for Sensory and Consumer Science?}

One of the most exciting aspects of being a sensory and consumer scientist is having access to a wide range of data.

\hypertarget{core-principles-in-sensory-and-consumer-science}{%
\subsection*{Core principles in Sensory and Consumer Science}\label{core-principles-in-sensory-and-consumer-science}}
\addcontentsline{toc}{subsection}{Core principles in Sensory and Consumer Science}

Sensory and consumer science (SCS) is consider as a pillar of food science and technology and is useful to product development, quality control and market research. Most scientific and methodological advances in the field are applied to food. This book makes no exception as we chose a cookie formulation dataset as a main thread. However, SCS widely applies to many other consumer goods so are the content of this book and the principles set out below.

\hypertarget{measuring-and-analyzing-human-responses}{%
\subsection*{Measuring and analyzing human responses}\label{measuring-and-analyzing-human-responses}}
\addcontentsline{toc}{subsection}{Measuring and analyzing human responses}

Sensory and consumer science aims at measuring and understanding consumers' sensory perceptions as well as the judgements, emotions and behaviors that may arise from these perceptions. SCS is thus primarily a science of measurement, although a very particular one that uses human beings and their senses as measuring instruments. In other words, sensory and consumer researchers measure and analyze human responses.

To this end, SCS relies essentially on sensory evaluation which comprises a set of techniques that mostly derive from psychophysics and behavioral research. It uses psychological models to help separate signal from noise in collected data {[}ref O'Mahony, D.Ennis, others?{]}. Besides, sensory evaluation has developed its own methodological framework that includes most refined techniques for the accurate measurement of product sensory properties while minimizing the potentially biasing effects of brand identity and the influence of other external information on consumer perception {[}Lawless \& Heymann, 2010{]}.

A detailed description of sensory methods is beyond the scope of this book and many textbooks on sensory evaluation methods are available to readers seeking more information. However, just to give a brief overview, it is worth remembering that sensory methods can be roughly divided into three categories, each of them bearing many variants:

\begin{itemize}
\tightlist
\item
  Discrimination tests that aim at detecting subtle differences between two products.
\item
  Descriptive analysis (DA), also referred to as `sensory profiling', aims at providing both qualitative and quantitative information about product sensory properties.
\item
  Hedonic tests. This category gathers affective tests that aim at measuring consumers' liking for the tested products or their preferences among a product set.
\end{itemize}

Each of these test categories generates its own type of data and related statistical questions in relation to the objectives of the study. Typically, data from difference tests consist in series of correct/failed binary answers depending on whether judges successfully picked the odd sample(s) among a set of three or more samples. These are used to determine whether the number of correct choices is above the level expected by chance.

Conventional descriptive analysis data consist in intensity scores given by each panelist to evaluated samples on a series of sensory attributes, hence resulting in a product x attribute x panelist dataset (Figure 1). Note that depending on the DA method, quantifying means other than intensity ratings can be used (ranks, frequency, etc.). Most frequently, each panelist evaluates all the samples in the product set. However, the use of balanced incomplete design can also be found when the experimenters aim to limit the number of samples evaluated by each subject.

Eventually, hedonic test datasets consist in hedonic scores (ratings for consumers' degree of liking or preference ranks) given by each interviewed consumer to a series of products. As for DA, each consumer usually evaluates all the samples in the product set, but balanced incomplete designs are sometimes used too. In addition, some companies favor pure monadic evaluation of product (i.e.~between-subject design or independent groups design) which obviously result in unrelated sample datasets.

Sensory and consumer researchers also borrow methods from other fields, in particular from sociology and experimental psychology. Definitely a multidisciplinary area, SCS develops in many directions and reaches disciplines that range from genetics and physiology to social marketing, behavioral economics and computational neuroscience. So have diversified the types of data sensory and consumer scientists must deal with.

\hypertarget{computational-sensory-science}{%
\subsection*{Computational Sensory Science}\label{computational-sensory-science}}
\addcontentsline{toc}{subsection}{Computational Sensory Science}

\hypertarget{part-hors-doeuvres}{%
\part*{Hors d'Oeuvres}\label{part-hors-doeuvres}}
\addcontentsline{toc}{part}{Hors d'Oeuvres}

\hypertarget{data_science}{%
\chapter{Why Data Science?}\label{data_science}}

In this chapter we explain what is data science and discuss why data science is valuable to sensory and consumer scientists. While this book focuses on the aspects of data science that are most important to sensory and consumer scientists, we recommend the excellent text \citet{Wickham2016} for a more general introduction to data science.

\hypertarget{history-and-definition}{%
\section{History and Definition}\label{history-and-definition}}

You may have heard that data science was called the ``sexiest job of the 21st century'' by Harvard Business Review (\citet{Davenport2012}). But what is data science? Before we give our definition, we provide some brief history for context. For a comprehensive survey of this topic, we recommend \citet{Cao2017}.

To begin, there was a movement in early computer science to call their field ``data science.'' Chief among the advocates for this viewpoint was Peter Naur, winner of the 2005 Turing award \footnote{A prize roughly equivalent in prestige to a Nobel prize, but for computer science.}. This viewpoint is detailed in the preface to his 1974 book, ``Concise Survey of Computer Methods,'' where he states that data science is ``the science of dealing with data, once they have been established'' (\citet{Naur1974}). According to Naur, this is the purpose of computer science. This viewpoint is echoed in the statement, often attributed to Edsger Dijkstr, that ``Computer science is no more about computers than astronomy is about telescopes.''

Interestingly, a similar viewpoint arose in statistics, as reflected in John Tukey's statements that ``Data analysis, and the parts of statistics which adhere to it, must \ldots{} take on the characteristics of science rather than those of mathematics'' and that ``data analysis is intrinsically an empirical science'' (\citet{Tukey1962}). This movement culminated in 1997 when Jeff Wu proposed during his inaugural lecture upon becoming the chair of the University of Michigan's statistics department, entitled ``Statistics = Data Science?,'' that statistics should be called data science (\citet{Wu1997}).

These two movements\footnote{It is worth noting that these two movements were connected by substantial work in the areas of statistical computing, knowledge discovery, and data mining, with important work contributed by Gregory Piatetsky-Shapiro, Usama Fayyad, and Padhraic Smyth among many others. See \citet{Fayyad1996}, for example.} came together in 2001 in William S. Cleveland's paper ``Data Science: An Action Plan for Expanding the Technical Areas in the Field of Statistics'' (\citet{Cleveland2001}). In this highly influential monograph, Cleveland makes the key assertion that ``The value of technical work is judged by the extent ot which it benefits the data analyst, either directly or indirectly.''

Based on this history, we provide our definition of \textbf{data science}:

\begin{quote}
Data science is the intersection of statistics, computer science, and industrial design.
\end{quote}

Accordingly, we use the following three definitions of these fields:

\begin{itemize}
\tightlist
\item
  \textbf{Statistics}: The branch of mathematics dealing with the collection, analysis, interpretation, and presentation of masses of numerical data.
\item
  \textbf{Computer Science}: Computer science is the study of processes that interact with data and that can be represented as data in the form of programs.
\item
  \textbf{Industrial Design}: The professional service of creating and developing concepts and specifications that optimize the function, value, and appearance of products and systems for the mutual benefit of both user and manufacturer.
\end{itemize}

Hence data science is the delivery of value through the collection, processing, analysis, and interpretation of data.

\hypertarget{benefits-of-data-science}{%
\section{Benefits of Data Science}\label{benefits-of-data-science}}

Now that we have a working definition of data science, we consider some reasons for sensory and consumer scientists to embrace it.

\hypertarget{reproducible-research}{%
\subsection{Reproducible Research}\label{reproducible-research}}

One of the most important ideas in data science is that of reproducible research (cf. \citet{Peng2011}). Importantly, reproducibility in the context of data science does not refer to the repeatability of the experimental results themselves if the experiment were to be conducted again. What is instead meant by reproducible research is the ability to proceed from the input data to the final results in reproducible steps. Ideally, these steps should be well-documented so that any future researcher, including the researcher who originally conducted the work, should be able to determine all choices made in data cleaning, manipulation, and analysis that led to the final results. Since sensory and consumer scientists often work in teams, this clarity ensures that anyone on the team can understand the steps that led to prior results were obtained, and can apply those steps to their own research going forward.

\hypertarget{standardized-reporting}{%
\subsection{Standardized Reporting}\label{standardized-reporting}}

Related to the idea of reproducible research is that of standardized reporting. By following a data-scientific workflow, including automated reporting (see Chapter \ref{auto-report}), we can standardize our reporting across multiple projecsts. This standardization has many benefits:

\begin{itemize}
\tightlist
\item
  \textbf{Consistent Formatting} When standardized reporting is used, outputs created by a team are formatted consistently regardless of who creates them. This consistency helps consumers of the reports - whether those consumers are executives, clients, or other team members - quickly interpret results.
\item
  \textbf{Upstream Data Consistency} Once a standardized workflow is put in place, consistency of data formatting gains a new importance as producers of the report can save significant time by not having to reformat new data. This fact puts pressure on the data collection produce to become more consistent, which ultimately supports knowledge management (see Chapter \ref{graph-db}).
\item
  \textbf{Shared Learning} Once a team combines standardized reporting with tools for online collaboration such as GitHub (see Appendix \ref{git-and-github}), any improvement to reporting (for example, to a table, chart, text output, or even to the reporting format itself) can be leveraged by all members of the team. Thus improvements compound over time, to the benefit of all team members.
\end{itemize}

\hypertarget{data-driven-decision-making}{%
\subsection{Data-Driven Decision Making}\label{data-driven-decision-making}}

\hypertarget{standardized-data-collection}{%
\subsection{Standardized Data Collection}\label{standardized-data-collection}}

\hypertarget{improved-business-impact}{%
\subsection{Improved Business Impact}\label{improved-business-impact}}

\hypertarget{data-scientific-workflow}{%
\section{Data Scientific Workflow}\label{data-scientific-workflow}}

A schematic of a data scientific workflow is shown in Figure \ref{fig:ds-workflow}. Each section is described in greater detail below.

\begin{figure}

{\centering \includegraphics[width=17.38in]{images/data_science_workflow} 

}

\caption{Data scientific workflow.}\label{fig:ds-workflow}
\end{figure}

\hypertarget{data-collection2}{%
\subsection{Data Collection}\label{data-collection2}}

\hypertarget{design}{%
\subsubsection{Design}\label{design}}

\hypertarget{execute}{%
\subsubsection{Execute}\label{execute}}

\hypertarget{import}{%
\subsubsection{Import}\label{import}}

\hypertarget{data-preparation}{%
\subsection{Data Preparation}\label{data-preparation}}

\hypertarget{inspect}{%
\subsubsection{Inspect}\label{inspect}}

Goal:
Gain familiarity with the data
Key Steps:
Learn collection details
Check data imported correctly
Determine data types
Ascertain consistency and validity
Tabulate and compute other basic summary statistics
Create basic plots of key variables of interest

\hypertarget{clean}{%
\subsubsection{Clean}\label{clean}}

Goal:
Prepare data for analysis
Key Steps:
Remove/correct errors
Make data formatting consistent
Organize text data
Create tidy data (one observation per row)
Organize data into related tables
Document all choices

\hypertarget{data-analysis2}{%
\subsection{Data Analysis}\label{data-analysis2}}

\hypertarget{transform}{%
\subsubsection{Transform}\label{transform}}

Goal:
Adjust data as needed for analysis
Key Steps:
Create secondary variables
Decorrelate data
Identify latent factors
Engineer new features

\hypertarget{explore}{%
\subsubsection{Explore}\label{explore}}

Goal:
Allow data to suggest hypotheses
Key Steps:
Graphical visualizations
Exploratory analyses
Note:
Caution must be taken to avoid high false discovery rate when using automated tools

\hypertarget{model}{%
\subsubsection{Model}\label{model}}

Goal:
Conduct formal statistical modeling
Key Steps:
Conduct traditional statistical modeling
Build predictive models
Note:
This step may feed back into transform and explore

\hypertarget{value-delivery2}{%
\subsection{Value Delivery}\label{value-delivery2}}

\hypertarget{communicate}{%
\subsubsection{Communicate}\label{communicate}}

Goal:
Exchange research information
Key Steps:
Automate reporting as much as possible
Share insights
Receive feedback
Note:
Design principles essential to make information accessible

\hypertarget{reformulate}{%
\subsubsection{Reformulate}\label{reformulate}}

Goal:
Incorporate feedback into workflow
Key Steps:
Investigate new questions
Revise communications
Note:
Reformulation make take us back to data cleaning

\hypertarget{reproducible-research-1}{%
\section{Reproducible Research}\label{reproducible-research-1}}

Discuss benefits

\begin{itemize}
\tightlist
\item
  Time savings
\item
  Collaboration
\item
  Continuous improvement
\end{itemize}

\hypertarget{how-to-learn-data-science}{%
\section{How to Learn Data Science}\label{how-to-learn-data-science}}

Learning data science is much like learning a language or learning to play an instrument - you have to practice. Our advice based on mentoring many students and clients is to get started sooner rather than later, and to accept that the code you'll write in the future will always be better than the code you'll write today. Also, many of the small details that separate an proficient data scientist from a novice can only really be learned through practice as there are too many small details to learn them all in advice. So, starting today, do your best to write at least some code for all your projects. If a time deadline prevents you from completing the analysis in R, that's fine, but at least gain the experience of making an RStudio project and loading the data in R. Then, as time allows, try to duplicate your analyses in R, being quick to search for solutions when you run into errors. Often simply copying and pasting your error into a search engine will be enough to find the solution to your problem. Moreover, searching for solutions is its own skill that also requires practice. Finally, if you are really stuck, reach out to a colleague (or even the authors of this book) for help

We recommend following the instructions in Appendix \ref{start-R} to get started.

\hypertarget{tidy-thoughts}{%
\chapter{Tidy Thinking}\label{tidy-thoughts}}

This is a test of the footnotes\footnote{A great footnote}.

\hypertarget{data-manip}{%
\chapter{Data Manipulation}\label{data-manip}}

In sensory science, different data collection tools (whether it is device, software, or methodologies) may provide data in different formats. Also, different statistical analyses may require having the same data structured in a different way.

A simple example to illustrate this later point is the analysis of liking data.
Let C consumers provide their hedonic assessments of P samples. To evaluate if samples have been liked differently, an ANOVA is performed on a long thin table with (PxC) rows x 3 columns (consumer, sample, and the liking scores).

However, to assess whether consumers have the same preference patterns at the individual level, internal preference mapping or cluster analysis would be performed, and both these analyses require as input a short and large table with P rows and C columns.

Another example of data manipulation consists in summarizing data, by for instance computing the mean by product for each sensory attribute (hence creating the so-called sensory profiles), or to generate frequency tables (e.g.~proportions of male/female, distribution of the liking scores by sample, contingency table for CATA data, etc.)

For these reasons, it is hence essential to learn to manipulate data and transition from one structure to another.

For illustration, let's consider the data stored in \emph{Sensory Profile.xlsx}, which consists in 9 panellists evaluating 11 samples on 32 sensory attributes. This dataset will be further analysed in the following sections. The aim here is not to interpret the results, but to show how data is being manipulated.

This data is imported using the \texttt{read\_xlsx()} function from the \texttt{\{readxl\}} package (for more information on how to import data, see Section \ref{data-collection}).

A first analysis that is commonly done on such table consists in computing the mean per sample for each attribute, hence generating the so-called sensory profiles of the samples. Such table (crossing the samples in rows and the sensory attributes in columns) gives a first impression at the differences between samples across attributes.

The principles of data manipulation will be illustrated here by generating the sensory profiles from the raw data using different approaches. This step consists in reducing the 99x35 table into a 11x33 table, i.e.~a table with 11 rows (one per sample) and 32 columns (one per attribute) and one column with the sample information. An important message here is that most data transformation situation can be solved in different ways, so don't be afraid to open your mind and think differently by stimulating your imagination to solve any of your data challenge.

Note that we could consider passing the sample names as row names rather than having it as an extra column. This extra step is required for certain functions from \texttt{\{FactoMineR\}} and \texttt{\{SensoMineR\}} for instance, and will be presented in Section \ref{data-prep}.

\hypertarget{tidying-data}{%
\section{Tidying Data}\label{tidying-data}}

\hypertarget{transformation-without-altering-the-data}{%
\subsection{Transformation without Altering the Data}\label{transformation-without-altering-the-data}}

Transforming a data table without altering the data itself is done through pivoting, hence either creating a shorter and wider table (CREATE FIGURE), or a longer and thinner table (CREATE FIGURE). This is done through the \texttt{pivot\_wider()} and \texttt{pivot\_longer()} functions from the \texttt{\{tidyr\}} package.

\hypertarget{transformation-that-alters-the-data}{%
\subsection{Transformation that Alters the Data}\label{transformation-that-alters-the-data}}

In some cases, the final table to generate requires altering the data, by (say) computing the mean across multiple values, or counting the number of occurrences of factor levels for instance. In other words, we summarize the information, which also tend to reduce the size of the table. It is hence no surprise that the function used for such data reduction is called \texttt{summarise()} from the \texttt{\{dplyr\}} package.

In practice, \texttt{summarise()} applies a function (whether it is the \texttt{mean()}, or a simple count using \texttt{n()}) on a set of values. When this set of values need to be aggregated based on another variable (say we do not want to compute the overall mean for the entire table, but the mean by product), \texttt{summarise()} is then coupled with \texttt{group\_by()}.

\hypertarget{handling-lists-of-tables}{%
\subsection{Handling Lists of Tables}\label{handling-lists-of-tables}}

Create an example with multiple dataset in one excel sheet (could be different countries, or different sessions)
Import the data using \texttt{map()} by reading the different tabs
Use \texttt{enframe()} to combine all the results
(alternative: use \texttt{reduce()} with \texttt{bind\_rows()}, but this version will lose the country names/session info if not already part of the dataset)

\texttt{nest\_by()} and \texttt{unnest\_by()}
\texttt{enframe()} and \texttt{deframe()}

\texttt{reduce()}

\texttt{rowwise()} and \texttt{mutate()}

\texttt{separate\_rows()} to link to \texttt{unnest\_tokens()}

\hypertarget{illustration}{%
\section{Illustration}\label{illustration}}

Although the solutions we just presented are simple and only involve a few lines of code, we propose other solutions using the \textbf{\{tidyverse\}}. This will allow us introducing this philosophy of coding, and will provide you a first contact to some of the functions that we use.

The \textbf{\{tidyverse\}} operates 5 major transformations on a dataset:

\begin{itemize}
\tightlist
\item
  \texttt{select()} allows selecting, renaming, and re-arranging columns of a dataset;
\item
  \texttt{filter()} and \texttt{arrange()} works on the rows of the dataset by filtering data and rearranging the order;
\item
  \texttt{mutate()} adds new columns, which can be the combination of other columns of the dataset;
\item
  \texttt{summarise()} summarises the data by providing the statistics of interest on the variables selected (all the variables that are not specified are then removed).
\end{itemize}

Note that for \texttt{mutate()} and \texttt{summarise()}, different variant such as \texttt{mutate\_all()} or \texttt{mutate\_if()} (resp. \texttt{summarise\_all()} and \texttt{summarise\_if()}) allows applying the same transformation to multiple columns (all the columns for \texttt{mutate\_all()} and \texttt{summarise\_all()}, or the one that meet a pre-defined condition for \texttt{mutate\_if()} and \texttt{summarise\_if()}).

As a first proposition, we use \texttt{summarise\_all}, meaning that we should only keep the variables that are relevant for the analysis. From \texttt{sensory}, we hence select the columns 3 (product), and the block starting from column 4 until the end of the dataset (sensory attributes).
Since the mean needs to be computed for each sample separately, the function \texttt{group\_by()} is used. This function ensures that the results are summarised by product in our case. We then summarise the data by performing the mean on all the variables (product is ignored since it is used to group the results).
Ultimately, we use the product names as row names (using \texttt{column\_to\_rownames()}).

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{senso\_mean2 }\OtherTok{\textless{}{-}}\NormalTok{ sensory }\SpecialCharTok{\%\textgreater{}\%} 
\NormalTok{  dplyr}\SpecialCharTok{::}\FunctionTok{select}\NormalTok{(}\DecValTok{3}\NormalTok{,}\DecValTok{4}\SpecialCharTok{:}\FunctionTok{ncol}\NormalTok{(sensory)) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{group\_by}\NormalTok{(product) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{summarise\_all}\NormalTok{(}\FunctionTok{list}\NormalTok{(}\SpecialCharTok{\textasciitilde{}}\FunctionTok{mean}\NormalTok{(.))) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{column\_to\_rownames}\NormalTok{(}\AttributeTok{var=}\StringTok{"product"}\NormalTok{)}
\FunctionTok{round}\NormalTok{(senso\_mean2, }\DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

The transformation from the original 11x35 table to the 11x33 table is done through the \texttt{group\_by()} followed by \texttt{summarise\_all} functions.

Another way of generating such table consists in not pre-selecting the variables, but in computing the mean only if the variable is numerical. To do so, we use \texttt{summarise\_if()} and we put the condition that the variable should be numerical to compute the mean (otherwise R will return an error). Here again, we group the results by product.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{senso\_mean3 }\OtherTok{\textless{}{-}}\NormalTok{ sensory }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{group\_by}\NormalTok{(product) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{summarise\_if}\NormalTok{(is.numeric, mean) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{column\_to\_rownames}\NormalTok{(}\AttributeTok{var=}\StringTok{"product"}\NormalTok{)}
\FunctionTok{round}\NormalTok{(senso\_mean3, }\DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

This solution fits well if all the variables that are numeric should be summarized in the same way (here using the mean). Otherwise, a good solution is to run the analysis on a pre-defined set of variables. Such set can be created manually (we are taking the first 10 sensory attributes here), or automatically if the names of the attributes follow a certain pattern. In such case, the use of functions such as \texttt{starts\_with()}, \texttt{ends\_with()}, or using regular expression is of great help!

The mean table is then generated using the \texttt{summarise()} function \texttt{across()} \texttt{all\_of()} the variables that were selected.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{senso\_var }\OtherTok{\textless{}{-}} \FunctionTok{colnames}\NormalTok{(sensory)[}\DecValTok{4}\SpecialCharTok{:}\DecValTok{13}\NormalTok{]}
\NormalTok{senso\_mean4 }\OtherTok{\textless{}{-}}\NormalTok{ sensory }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{group\_by}\NormalTok{(product) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{summarise}\NormalTok{(}\FunctionTok{across}\NormalTok{(}\FunctionTok{all\_of}\NormalTok{(senso\_var), mean)) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{as.data.frame}\NormalTok{() }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{column\_to\_rownames}\NormalTok{(}\AttributeTok{var=}\StringTok{"product"}\NormalTok{)}
\FunctionTok{round}\NormalTok{(senso\_mean4, }\DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

At last, we propose a solution which in this case is not optimal, but which can be very useful in some others. This solution consists in working on the dataset by permuting all the variables using \texttt{pivot\_longer()}, hence generating a dataset with 3 relevant columns: one containing the products, one containing all the attributes, and one containing the scores. On this variable, we \texttt{summarise()} the scores by product and by attribute, before re-structuring the data using \texttt{pivot\_wider()}.
Note that the combination \texttt{pivot\_longer()} and \texttt{pivot\_wider()} will re-organize automatically the attributes alphabetically. To avoid that, we can transform the column we name \texttt{attribute} into a factor with as level order the original order. This procedure maintains the original order.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{senso\_mean5 }\OtherTok{\textless{}{-}}\NormalTok{ sensory }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{pivot\_longer}\NormalTok{(}\DecValTok{4}\SpecialCharTok{:}\FunctionTok{ncol}\NormalTok{(.), }\AttributeTok{names\_to=}\StringTok{"attributes"}\NormalTok{, }\AttributeTok{values\_to=}\StringTok{"scores"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{attributes =} \FunctionTok{factor}\NormalTok{(attributes, }\AttributeTok{levels=}\FunctionTok{colnames}\NormalTok{(sensory)[}\DecValTok{4}\SpecialCharTok{:}\FunctionTok{ncol}\NormalTok{(sensory)])) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{group\_by}\NormalTok{(product, attributes) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{summarise}\NormalTok{(}\AttributeTok{scores =} \FunctionTok{mean}\NormalTok{(scores)) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{pivot\_wider}\NormalTok{(}\AttributeTok{names\_from=}\NormalTok{attributes, }\AttributeTok{values\_from=}\NormalTok{scores) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{column\_to\_rownames}\NormalTok{(}\AttributeTok{var=}\StringTok{"product"}\NormalTok{)}
\FunctionTok{round}\NormalTok{(senso\_mean5, }\DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

This procedure uses intermediate steps since the structure of the original table (99x35) is transformed by pivoting the attributes from columns to rows: this means that after \texttt{pivot\_wider()}, the dataset created now contains 99x32=3168 rows and 5 columns (\emph{judge}, \emph{code}, and \emph{product}, one column called \emph{attributes} which contains the attribute names, and one column called \emph{scores} which contain the individual scores). This table is then reduced to a table 11x32=352 rows and 3 columns (\emph{product}, \emph{attributes}, \emph{scores}) through the \texttt{group\_by()} and \texttt{summarise()} process, before being reset as 11x33 table through \texttt{pivot\_wider()}.

This procedure could slightly be simplified: To generate \texttt{senso\_mean5}, we computed the mean by \texttt{product} and \texttt{attributes} across all assessors. If we delete this line of code (i.e.~related to \texttt{summary}), R will generate a table crossing \texttt{product} in rows, \texttt{attributes} in columns, in which each cell contains a list of values (here, we have as many values as we have assessors performing the test in each cell).
When such situation appears, it is possible to apply automatically a function (here we want the \texttt{mean()}) on this sets of values using \texttt{values\_fn} from \texttt{pivot\_wider()}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{senso\_mean6 }\OtherTok{\textless{}{-}}\NormalTok{ sensory }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{pivot\_longer}\NormalTok{(}\DecValTok{4}\SpecialCharTok{:}\FunctionTok{ncol}\NormalTok{(.), }\AttributeTok{names\_to=}\StringTok{"attribute"}\NormalTok{, }\AttributeTok{values\_to=}\StringTok{"scores"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{attribute =} \FunctionTok{factor}\NormalTok{(attribute, }\AttributeTok{levels=}\FunctionTok{colnames}\NormalTok{(sensory)[}\DecValTok{4}\SpecialCharTok{:}\FunctionTok{ncol}\NormalTok{(sensory)])) }\SpecialCharTok{\%\textgreater{}\%} 
\NormalTok{  dplyr}\SpecialCharTok{::}\FunctionTok{select}\NormalTok{(}\SpecialCharTok{{-}}\NormalTok{judge, }\SpecialCharTok{{-}}\NormalTok{code) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{group\_by}\NormalTok{(product, attribute) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{pivot\_wider}\NormalTok{(}\AttributeTok{names\_from=}\NormalTok{attribute, }\AttributeTok{values\_from=}\NormalTok{scores, }\AttributeTok{values\_fn=}\NormalTok{mean) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{column\_to\_rownames}\NormalTok{(}\AttributeTok{var=}\StringTok{"product"}\NormalTok{)}
\FunctionTok{round}\NormalTok{(senso\_mean6, }\DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

In a similar way, missing values can be replaced automatically using \texttt{values\_fill}.

As expected, all these solutions provide the same sensory profiles using different process. Depending on the situations, some of these processes may be better than others.

Note that multiple analysis can be ordered together. Let's take back the example generating \texttt{senso\_mean4}, and let's consider 2 other groups of variables, one in which we ask for the median, and one for which we ask the number of measures. This entire table can be generated as such:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{senso\_var1 }\OtherTok{\textless{}{-}} \FunctionTok{colnames}\NormalTok{(sensory)[}\DecValTok{4}\SpecialCharTok{:}\DecValTok{13}\NormalTok{]}
\NormalTok{senso\_var2 }\OtherTok{\textless{}{-}} \FunctionTok{colnames}\NormalTok{(sensory)[}\DecValTok{14}\SpecialCharTok{:}\DecValTok{20}\NormalTok{]}
\NormalTok{senso\_var3 }\OtherTok{\textless{}{-}} \FunctionTok{colnames}\NormalTok{(sensory)[}\DecValTok{21}\SpecialCharTok{:}\DecValTok{25}\NormalTok{]}

\NormalTok{senso\_multifun }\OtherTok{\textless{}{-}}\NormalTok{ sensory }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{group\_by}\NormalTok{(product) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{summarise}\NormalTok{(}\FunctionTok{across}\NormalTok{(}\FunctionTok{all\_of}\NormalTok{(senso\_var1), mean),}
            \FunctionTok{across}\NormalTok{(}\FunctionTok{all\_of}\NormalTok{(senso\_var2), median),}
            \FunctionTok{across}\NormalTok{(}\FunctionTok{all\_of}\NormalTok{(senso\_var3), length)) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{as.data.frame}\NormalTok{() }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{column\_to\_rownames}\NormalTok{(}\AttributeTok{var=}\StringTok{"product"}\NormalTok{)}
\FunctionTok{round}\NormalTok{(senso\_multifun, }\DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\hypertarget{data-viz}{%
\chapter{Data Visualization}\label{data-viz}}

\hypertarget{design-principles}{%
\section{Design Principles}\label{design-principles}}

\hypertarget{table-making}{%
\section{Table Making}\label{table-making}}

\hypertarget{chart-making}{%
\section{Chart Making}\label{chart-making}}

\hypertarget{philosophy-of-ggplot2}{%
\subsection{Philosophy of ggplot2}\label{philosophy-of-ggplot2}}

Explain the principles of multi-layer graphs through an example.

\texttt{aes()}, \texttt{geom\_()}, \texttt{theme()}

\hypertarget{aesthetics}{%
\subsubsection{aesthetics}\label{aesthetics}}

Provide the most relevant options for \texttt{aes()}

\begin{itemize}
\tightlist
\item
  x, y, z
\item
  group
\item
  color, fill
\item
  text, label
\item
  alpha, size
\end{itemize}

\hypertarget{geom_}{%
\subsubsection{geom\_}\label{geom_}}

Explain the fact that some \texttt{geom\_()} comes with some stats automatically (e.g.~\texttt{geom\_bar} bins the data)

\hypertarget{common-charts}{%
\subsection{Common Charts}\label{common-charts}}

\hypertarget{scatter-points}{%
\subsubsection{Scatter points}\label{scatter-points}}

\texttt{geom\_point()}

\hypertarget{line-charts}{%
\subsubsection{Line charts}\label{line-charts}}

\texttt{geom\_line()}, \texttt{geom\_smooth()}
\texttt{geom\_abline()}
\texttt{geom\_hline()} and \texttt{geom\_vline()}
\texttt{geom\_segment()} and \texttt{geom\_arrow()}

\hypertarget{bar-charts}{%
\subsubsection{Bar charts}\label{bar-charts}}

\texttt{geom\_bar}, \texttt{geom\_polygon}, \texttt{geom\_histogram()}, \texttt{geom\_freqpoly()}
\texttt{position="identity"}, \texttt{position="dodge"} or \texttt{position="fill"}

\hypertarget{distribution}{%
\subsubsection{Distribution}\label{distribution}}

\texttt{geom\_boxplot()} and \texttt{geom\_violin()}

\hypertarget{text}{%
\subsubsection{Text}\label{text}}

\texttt{geom\_text} and \texttt{geom\_label}
presentation of \textbf{\{ggrepel\}}

\hypertarget{rectangles}{%
\subsubsection{Rectangles}\label{rectangles}}

\texttt{geom\_tile()}, \texttt{geom\_rect}, and \texttt{geom\_raster()}

\hypertarget{themes-and-legend}{%
\subsubsection{Themes and legend}\label{themes-and-legend}}

\texttt{theme()}, and pre-defined themes like \texttt{theme\_bw()}, \texttt{theme\_minimal()}, etc.
\texttt{ggtitle()}
\texttt{xlab()}, \texttt{ylab()}, or \texttt{labs()}

\hypertarget{additional-topics}{%
\subsection{Additional Topics}\label{additional-topics}}

\hypertarget{playing-around-with-axes}{%
\subsubsection{Playing around with axes}\label{playing-around-with-axes}}

\texttt{coord\_fixed()}, \texttt{coord\_cartesian()}, \texttt{coord\_trans()}
\texttt{scale\_x\_}, \texttt{scale\_y\_}

\hypertarget{transposing-the-plot}{%
\subsubsection{Transposing the plot}\label{transposing-the-plot}}

\texttt{coord\_flip()} and \texttt{coord\_polar()}

\hypertarget{splitting-plots}{%
\subsubsection{Splitting plots}\label{splitting-plots}}

\texttt{facet\_wrap()}, \texttt{facet\_grid()}

\hypertarget{combining-plots}{%
\subsubsection{Combining plots}\label{combining-plots}}

\textbf{\{patchwork\}}

\hypertarget{auto-report}{%
\chapter{Automated Reporting}\label{auto-report}}

Effective communication of results is among the essential duties of the sensory scientist, but the sometimes tedious mechanics of report production together with the sheer volume of data that many scientists now must process combine to make reporting design an afterthought in too many cases. In this tutorial, we review recent advances in automated report production that liberate resources for scientists to focus on the interpretation and communication of results, while simultaneously reducing errors and increasing the consistency of their analyses. We teach the tutorial through an extended example, cumulatively building an R script that takes participates from receipt of an example dataset to a beautifully-designed and nearly completed PowerPoint presentation automatically and using freely available, open-source packages. Details of how to customize the final presentation to incorporate corporate branding - such as logos, font choices, and color palettes - will also be covered.

\hypertarget{what-is-automated-reporting}{%
\section{What is Automated Reporting?}\label{what-is-automated-reporting}}

Why Script?
Save time
Reduce errors
Collaboration
Share code with others
Read own code later
Explain choices for analysis, table presentation, charts
Save steps for result creation
Main tools
R/RStudio
RMarkdown, HTML output, etc. (mention but don't focus)
Packages for Microsoft office production
Officer suite (PowerPoint, Word)
Charts, especially RVG
Extract from Word/PowerPoint
Index
Flextable
Images?
Packages for formatting
extrafont
extrafontdb
Rcolorbrewer

\hypertarget{excel}{%
\section{Excel}\label{excel}}

Although Excel is not our preferred tool for automated reporting, it is still one of the major ways to access and share data. Most data collection software offers the possibility to export data and/or results in an Excel format, and most data analysis tools accepts Excel format as inputs. With the large use of Excel, it is no surprise that many of our colleagues or clients like to share data and results using such spreadsheets. It is even less a surprise that R provides multiple solutions to import/export results from/to Excel.

For the importation of datasets, we have already presented two packages (\textbf{\{xlsx\}} and \textbf{\{readxl\}}) which provide some interesting options: they will not be detailed any further here.

For exporting results, two complementary packages (amongst others) in terms of ease of use and flexibility in the outcome are considered: \textbf{\{xlsx\}} and \textbf{\{openxlsx\}}.

Besides its option of importing directly Excel files (.xls and .xlsx), the package \textbf{\{xlsx\}} also offers the option to export tables in Excel through the function \texttt{write.xlsx()}. \texttt{write.xlsx()} works in the same way as \texttt{base::write.csv()} (as its name indicates, this function exports tables from R to a .csv file), but since it generates an Excel file (.xls or .xlsx), additional tabs can be added using the \texttt{append} option. The procedure for \texttt{write.xlsx()} is the following:

\begin{itemize}
\tightlist
\item
  First export the table \texttt{x=mydata1} of interest in a new Excel into the tab entitles ``mytab1'' of the file ``myfile.xlsx'' using the options \texttt{file=“myfile.xlsx”} and \texttt{sheetName=\ “mytab1”}, and set the option \texttt{append=FALSE}.
\item
  Then add to \texttt{file=“myfile.xlsx”} any additional table \texttt{x=mydata2} in another tab (e.g.~\texttt{sheet=”mytab2”}) using a similar command, but by setting \texttt{append=TRUE}.
  By doing so, R understands that ``myfile.xlsx'' should be extended with a second tab called ``mytab2'' that contains ``mytable2''. The tables exported may or may not include row names and column namess, and the sheet can automatically be password protected using the \texttt{password} option.
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(xlsx)}

\CommentTok{\# We propose here to export the 5 first tables in 5 different tabs.}
\ControlFlowTok{for}\NormalTok{ (v }\ControlFlowTok{in} \DecValTok{1}\SpecialCharTok{:}\DecValTok{5}\NormalTok{)\{}
  
  \ControlFlowTok{if}\NormalTok{ (v}\SpecialCharTok{==}\DecValTok{1}\NormalTok{)\{}
\NormalTok{    append}\OtherTok{=}\ConstantTok{FALSE}
\NormalTok{  \} }\ControlFlowTok{else}\NormalTok{ \{}
\NormalTok{    append}\OtherTok{=}\ConstantTok{TRUE}
\NormalTok{  \}}
  
\NormalTok{  xlsx}\SpecialCharTok{::}\FunctionTok{write.xlsx}\NormalTok{(}\FunctionTok{as.data.frame}\NormalTok{(demog\_freq[[v]]), }
                   \AttributeTok{file=}\StringTok{"thierry\_code/Output/Tables using xlsx.xlsx"}\NormalTok{, }
                   \AttributeTok{sheetName=}\FunctionTok{names}\NormalTok{(demog\_freq)[v], }
                   \AttributeTok{row.names=}\ConstantTok{FALSE}\NormalTok{, }\AttributeTok{append=}\NormalTok{append)}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

The exportation of tables using the \textbf{\{xlsx\}} package is easy, yet very simplistic as it does not allow formatting the tables, nor does it allow exporting multiple tables in the same tab. For more advanced exporting options, the use of \textbf{\{openxlsx\}} package is preferred as it allows more flexibility in structuring and formatting the Excel output.

With \textbf{\{openxlsx\}}, the procedure starts with creating a workbook \texttt{wb} using the \texttt{createWorkbook()} function, to which we add worksheets through the \texttt{addWorksheet()} function.
On a given worksheet, any table can be exported using \texttt{writeData()} or \texttt{writeDataTable()}, which controls where to write the table through the \texttt{startRow} and \texttt{startCol} options.
Through these different functions, many additional formatting procedure can be applied:

\begin{itemize}
\tightlist
\item
  \texttt{createWorksheet()} allows:

  \begin{itemize}
  \tightlist
  \item
    show/hide grid lines using \texttt{gridLines};
  \item
    colour the specific sheet using \texttt{tabColour};
  \item
    change the zoom on the sheet through \texttt{zoom};
  \item
    show/hide the tab using \texttt{visible};
  \item
    format the worksheet by specifying its size (\texttt{paperSize}) and orientation (\texttt{orientation}).
  \end{itemize}
\item
  \texttt{writeData()} and \texttt{writeDataTable()} allow:

  \begin{itemize}
  \tightlist
  \item
    controlling where to print the data using \texttt{startRow} and \texttt{startCol} (or alternatively \texttt{xy}: \texttt{xy=c(“B”,12)} prints the table in cell B12), hence allowing exporting multiple tables within the same tab;
  \item
    including the row names and column names through \texttt{rowNames} and \texttt{colNames};
  \item
    formatting the header using \texttt{headerStyle} (incl.~colour of the text and/or background, font, font size, etc.) and whether a \texttt{filter} should be applied;
  \item
    shaping the borders using predefined solutions through \texttt{borders}, or customizing them with \texttt{borderStyle} and \texttt{borderColour};
  \item
    adding a filter to the table using \texttt{withFilger};
  \item
    converts missing data to ``\#N/A'' or any other string using \texttt{keepNA} and \texttt{na.string}.
  \end{itemize}
\item
  Additional formatting can be controlled using:

  \begin{itemize}
  \tightlist
  \item
    \texttt{options()} to predefine number formatting, border colours and style that will be applied automatically to each tables;
  \item
    \texttt{modifyBaseFont()} to defined the font and font size;
  \item
    \texttt{freezePane()} to freeze the first row and/or column of the table using \texttt{firstRow=TRUE} and \texttt{firstCol=TRUE};
  \item
    \texttt{createStyle()} to pre-define a style, or \texttt{addStyle()} to apply a later stage some styling to some cells;
  \item
    controls the width of the columns using \texttt{setColWidths};
  \item
    \texttt{conditionalFormatting()} allows coloring cells when they meet pre-defined rules, as for instance to highlight significant p-values.
  \end{itemize}
\end{itemize}

When using \textbf{\{openxlsx\}}, we recommend to use the same procedure as for Word and PowerPoint:

\begin{itemize}
\tightlist
\item
  Start with setting as default the parameters that should be applied to each table;
\item
  Create styles for text or table headers that you save in different elements, and that you apply where needed.
\end{itemize}

In the following example, the sensory profiles are exported in the first tab, and a set of frequency tables are exported in the second tab.
To introduce conditional formatting with \textbf{\{openxlsx\}}, the sensory profiles are color coded as following: For each cell, the value is compared to the overall mean computed for that column and is colored in red (resp. blue) if it's higher (resp. lower) than the mean.
In practice, the color style is pre-defined in two parameters called \texttt{pos\_style} (red) and \texttt{neg\_style} (blue) using \texttt{createStyle()}. The decision whether \texttt{pos\_style} or \texttt{neg\_style} should be used is defined by the \texttt{rule} parameter from the \texttt{conditionalFormatting()}\footnote{In \texttt{conditionalFormatting()}, you can specify to which \texttt{rows} and \texttt{cols} the formatting applies. In this example, \texttt{cols} takes \texttt{v+1} because the first column contains the row names.} function.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(openxlsx)}

\CommentTok{\# Pre{-}define options to control the borders }
\FunctionTok{options}\NormalTok{(}\StringTok{"openxlsx.borderColour"}\OtherTok{=}\StringTok{"\#4F80BD"}\NormalTok{)}
\FunctionTok{options}\NormalTok{(}\StringTok{"openxlsx.borderStyle"}\OtherTok{=}\StringTok{"thin"}\NormalTok{)}

\CommentTok{\# Automatically set Number formats to 3 values after the decimal}
\FunctionTok{options}\NormalTok{(}\StringTok{"openxlsx.numFmt"}\OtherTok{=}\StringTok{"0.000"}\NormalTok{)}

\CommentTok{\# Change the font to Calibri size 10}
\FunctionTok{modifyBaseFont}\NormalTok{(wb, }\AttributeTok{fontSize=}\DecValTok{10}\NormalTok{, }\AttributeTok{fontName=}\StringTok{"Calibri"}\NormalTok{)}

\CommentTok{\# Create a header style in which }
  \CommentTok{\# the text is centered and in bold, }
  \CommentTok{\# borders on top and on the bottom, }
  \CommentTok{\# a blue background is used.}
\NormalTok{headSty }\OtherTok{\textless{}{-}} \FunctionTok{createStyle}\NormalTok{(}\AttributeTok{fgFill=}\StringTok{"\#DCE6F1"}\NormalTok{, }\AttributeTok{border=}\StringTok{"TopBottom"}\NormalTok{,}
                       \AttributeTok{halign=}\StringTok{"center"}\NormalTok{, }\AttributeTok{textDecoration=}\StringTok{"bold"}\NormalTok{)}

\CommentTok{\# Preparing the colouring for the conditional formatting}
\NormalTok{senso\_mean }\OtherTok{\textless{}{-}}\NormalTok{ sensory }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{group\_by}\NormalTok{(product) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{summarise\_if}\NormalTok{(is.numeric, mean) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{column\_to\_rownames}\NormalTok{(}\AttributeTok{var=}\StringTok{"product"}\NormalTok{)}
\NormalTok{overall\_mean }\OtherTok{\textless{}{-}} \FunctionTok{apply}\NormalTok{(senso\_mean, }\DecValTok{2}\NormalTok{, mean)}

\NormalTok{pos\_style }\OtherTok{\textless{}{-}} \FunctionTok{createStyle}\NormalTok{(}\AttributeTok{fontColour=}\StringTok{"firebrick3"}\NormalTok{, }\AttributeTok{bgFill=}\StringTok{"mistyrose1"}\NormalTok{)}
\NormalTok{neg\_style }\OtherTok{\textless{}{-}} \FunctionTok{createStyle}\NormalTok{(}\AttributeTok{fontColour=}\StringTok{"navy"}\NormalTok{, }\AttributeTok{bgFill=}\StringTok{"lightsteelblue"}\NormalTok{)}

\CommentTok{\# Creation of the workbook wb with two tabs called Mean and Frequency}
\NormalTok{wb }\OtherTok{\textless{}{-}}\NormalTok{ openxlsx}\SpecialCharTok{::}\FunctionTok{createWorkbook}\NormalTok{()}
\FunctionTok{addWorksheet}\NormalTok{(wb, }\AttributeTok{sheetName=}\StringTok{"Mean"}\NormalTok{, }\AttributeTok{gridLines=}\ConstantTok{FALSE}\NormalTok{)}
\FunctionTok{addWorksheet}\NormalTok{(wb, }\AttributeTok{sheetName=}\StringTok{"Frequency"}\NormalTok{, }\AttributeTok{gridLines=}\ConstantTok{FALSE}\NormalTok{)}

\CommentTok{\# Exporting senso\_mean to the first tab (first row and first column are frozen)}
\CommentTok{\# A pre{-}defined Excel design called TableStyleLight9 is used for this table}
\FunctionTok{freezePane}\NormalTok{(wb, }\AttributeTok{sheet=}\DecValTok{1}\NormalTok{, }\AttributeTok{firstRow=}\ConstantTok{TRUE}\NormalTok{, }\AttributeTok{firstCol=}\ConstantTok{TRUE}\NormalTok{)}
\FunctionTok{writeDataTable}\NormalTok{(wb, }\AttributeTok{sheet=}\DecValTok{1}\NormalTok{, }\AttributeTok{x=}\NormalTok{senso\_mean, }
               \AttributeTok{colNames=}\ConstantTok{TRUE}\NormalTok{, }\AttributeTok{rowNames=}\ConstantTok{TRUE}\NormalTok{, }
               \AttributeTok{tableStyle=}\StringTok{"TableStyleLight9"}\NormalTok{)}
\ControlFlowTok{for}\NormalTok{ (v }\ControlFlowTok{in} \DecValTok{1}\SpecialCharTok{:}\FunctionTok{ncol}\NormalTok{(senso\_mean1))\{}
  \FunctionTok{conditionalFormatting}\NormalTok{(wb, }\DecValTok{1}\NormalTok{, }\AttributeTok{cols=}\NormalTok{v}\SpecialCharTok{+}\DecValTok{1}\NormalTok{, }\AttributeTok{rows=}\NormalTok{(}\DecValTok{1}\SpecialCharTok{:}\FunctionTok{nrow}\NormalTok{(senso\_mean1)}\SpecialCharTok{+}\DecValTok{1}\NormalTok{), }
                        \AttributeTok{rule =} \FunctionTok{paste0}\NormalTok{(}\StringTok{"\textgreater{}"}\NormalTok{,overall\_mean[[v]]),}
                        \AttributeTok{style =}\NormalTok{ pos\_style)}
  \FunctionTok{conditionalFormatting}\NormalTok{(wb, }\DecValTok{1}\NormalTok{, }\AttributeTok{cols=}\NormalTok{v}\SpecialCharTok{+}\DecValTok{1}\NormalTok{, }\AttributeTok{rows=}\NormalTok{(}\DecValTok{1}\SpecialCharTok{:}\FunctionTok{nrow}\NormalTok{(senso\_mean1)}\SpecialCharTok{+}\DecValTok{1}\NormalTok{), }
                        \AttributeTok{rule =} \FunctionTok{paste0}\NormalTok{(}\StringTok{"\textless{}"}\NormalTok{,overall\_mean[[v]]),}
                        \AttributeTok{style =}\NormalTok{ neg\_style)}
\NormalTok{\}}

\CommentTok{\# Here, we export many different frequency tables in the second tab by:}
\CommentTok{\# 1. adding a title prior to the table}
\CommentTok{\# 2. export the table under its title}
\CommentTok{\# 3. title\_r and next\_r are used to track where the text is being printed}
\FunctionTok{writeData}\NormalTok{(wb, }\DecValTok{2}\NormalTok{, }\AttributeTok{x=}\StringTok{"Frequency Tables"}\NormalTok{, }\AttributeTok{startRow=}\DecValTok{1}\NormalTok{, }\AttributeTok{startCol=}\DecValTok{2}\NormalTok{)}
\NormalTok{title\_r }\OtherTok{\textless{}{-}} \DecValTok{3}
\ControlFlowTok{for}\NormalTok{ (v }\ControlFlowTok{in} \DecValTok{1}\SpecialCharTok{:}\DecValTok{5}\NormalTok{)\{}
  \FunctionTok{writeData}\NormalTok{(wb, }\DecValTok{2}\NormalTok{, }\AttributeTok{x=}\FunctionTok{names}\NormalTok{(demog\_freq)[v], }\AttributeTok{startRow=}\FunctionTok{max}\NormalTok{(title\_r), }\AttributeTok{startCol=}\DecValTok{1}\NormalTok{)}
  \FunctionTok{writeData}\NormalTok{(wb, }\DecValTok{2}\NormalTok{, }\AttributeTok{x=}\NormalTok{demog\_freq[[v]], }\AttributeTok{startRow=}\FunctionTok{max}\NormalTok{(title\_r)}\SpecialCharTok{+}\DecValTok{1}\NormalTok{, }\AttributeTok{startCol=}\DecValTok{1}\NormalTok{, }
            \AttributeTok{rowNames=}\ConstantTok{FALSE}\NormalTok{, }\AttributeTok{borders=}\StringTok{"surrounding"}\NormalTok{, }\AttributeTok{headerStyle=}\NormalTok{headSty)}
\NormalTok{  next\_r }\OtherTok{\textless{}{-}} \FunctionTok{max}\NormalTok{(title\_r) }\SpecialCharTok{+} \DecValTok{1} \SpecialCharTok{+} \DecValTok{1} \SpecialCharTok{+} \FunctionTok{nrow}\NormalTok{(demog\_freq[[v]]) }\SpecialCharTok{+} \DecValTok{1}
\NormalTok{  title\_r }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(title\_r, next\_r)}
\NormalTok{\}}

\CommentTok{\# We apply different style for the main title and for each table\textquotesingle{}s title.}
\FunctionTok{addStyle}\NormalTok{(wb, }\DecValTok{2}\NormalTok{, }\AttributeTok{style=}\FunctionTok{createStyle}\NormalTok{(}\AttributeTok{fontSize=}\DecValTok{14}\NormalTok{, }\AttributeTok{textDecoration=}\StringTok{"bold"}\NormalTok{), }
         \AttributeTok{rows=}\DecValTok{1}\NormalTok{, }\AttributeTok{cols=}\DecValTok{2}\NormalTok{)}
\FunctionTok{addStyle}\NormalTok{(wb, }\DecValTok{2}\NormalTok{, }\AttributeTok{style=}\FunctionTok{createStyle}\NormalTok{(}\AttributeTok{fontSize=}\DecValTok{12}\NormalTok{, }\AttributeTok{textDecoration=}\StringTok{"italic"}\NormalTok{), }
         \AttributeTok{rows=}\NormalTok{title\_r, }\AttributeTok{cols=}\FunctionTok{rep}\NormalTok{(}\DecValTok{1}\NormalTok{,}\FunctionTok{length}\NormalTok{(title\_r)))}

\FunctionTok{setColWidths}\NormalTok{(wb, }\DecValTok{2}\NormalTok{, }\AttributeTok{cols=}\DecValTok{1}\SpecialCharTok{:}\DecValTok{10}\NormalTok{, }\AttributeTok{widths=}\DecValTok{12}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

The file is created using \texttt{saveWorkbook()} by specifying the name of the workbook \texttt{wb} and its path through \texttt{file}. In case such workbook already exists, it can be overwritten using \texttt{overwrite}. Additionally, the user can visualize the file so far created using \texttt{openXL()}.

For more details on using \textbf{\{openxlsx\}} see \url{https://rdrr.io/cran/openxlsx/}.

\hypertarget{powerpoint}{%
\section{PowerPoint}\label{powerpoint}}

Start with template
Explain slide master
How to adjust choices
Internal naming (relevant later)
Example
Title slides
Tables
Charts
Bullet points
Images
Layout discussion

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(tidyverse)}
\FunctionTok{library}\NormalTok{(officer)}
\FunctionTok{library}\NormalTok{(flextable)}
\end{Highlighting}
\end{Shaded}

\hypertarget{powerpoint-formatting}{%
\subsection{PowerPoint Formatting}\label{powerpoint-formatting}}

PowerPoint Slide Master

\hypertarget{importing-the-template}{%
\subsubsection{Importing the Template}\label{importing-the-template}}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{my\_file }\OtherTok{\textless{}{-}} \FunctionTok{file.path}\NormalTok{(}\StringTok{"input"}\NormalTok{,}\StringTok{"templates"}\NormalTok{,}\StringTok{"Tutorial Template.pptx"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%} 
                        \FunctionTok{read\_pptx}\NormalTok{()}

\FunctionTok{class}\NormalTok{(my\_file) }\CommentTok{\# checking if correct class}

\NormalTok{my\_file }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{layout\_summary}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\hypertarget{creating-a-powerpoint-deck}{%
\subsubsection{Creating a PowerPoint Deck}\label{creating-a-powerpoint-deck}}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{pptx\_obj }\OtherTok{\textless{}{-}} \FunctionTok{read\_pptx}\NormalTok{ () }\CommentTok{\# new empty file}
\NormalTok{pptx\_obj }\OtherTok{\textless{}{-}}\NormalTok{ pptx\_obj }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{add\_slide}\NormalTok{(}\AttributeTok{layout  =} \StringTok{\textquotesingle{}Title and Content\textquotesingle{}}\NormalTok{,}\AttributeTok{master =} \StringTok{"Office Theme"}\NormalTok{)}

\NormalTok{pptx\_obj }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{print}\NormalTok{(}\AttributeTok{target =} \StringTok{"output/first\_example.pptx"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

We can not load the themes of Office \emph{ex nihilo} returns error

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{pptx\_obj }\OtherTok{\textless{}{-}} \FunctionTok{read\_pptx}\NormalTok{() }\CommentTok{\# new empty file}
\NormalTok{pptx\_obj }\OtherTok{\textless{}{-}}\NormalTok{ pptx\_obj }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{add\_slide}\NormalTok{(}\AttributeTok{layout =} \StringTok{"Title and Content"}\NormalTok{, }\AttributeTok{master =} \StringTok{"Integral"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

However, we can save an empty pptx with the desired theme and use it as a template

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{pptx\_obj }\OtherTok{\textless{}{-}} \FunctionTok{read\_pptx}\NormalTok{(}\FunctionTok{file.path}\NormalTok{(}\StringTok{"input"}\NormalTok{,}\StringTok{"templates"}\NormalTok{,}\StringTok{"integral.pptx"}\NormalTok{))}
\FunctionTok{layout\_summary}\NormalTok{(pptx\_obj)}
\end{Highlighting}
\end{Shaded}

We can even load a template with more than one theme

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{pptx\_obj }\OtherTok{\textless{}{-}} \FunctionTok{read\_pptx}\NormalTok{(}\FunctionTok{file.path}\NormalTok{(}\StringTok{"input"}\NormalTok{,}\StringTok{"templates"}\NormalTok{,}\StringTok{"multmasters.pptx"}\NormalTok{))}
\FunctionTok{layout\_summary}\NormalTok{(pptx\_obj)}
\end{Highlighting}
\end{Shaded}

\hypertarget{selection-pane}{%
\subsubsection{Selection Pane}\label{selection-pane}}

\hypertarget{key-functions-read_pptxpath-layout_summaryx-layout_propertiesx-add_slidex-layout-master-on_slidex-index-slide_summaryx-index-null}{%
\subsubsection{Key functions: read\_pptx(path), layout\_summary(x), layout\_properties(x), add\_slide(x, layout, master), on\_slide(x, index), slide\_summary(x, index = NULL)}\label{key-functions-read_pptxpath-layout_summaryx-layout_propertiesx-add_slidex-layout-master-on_slidex-index-slide_summaryx-index-null}}

\hypertarget{example-code}{%
\subsubsection{Example Code}\label{example-code}}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{pptx\_obj }\OtherTok{\textless{}{-}} \FunctionTok{read\_pptx}\NormalTok{() }\CommentTok{\# new empty file}

\NormalTok{pptx\_obj }\OtherTok{\textless{}{-}}\NormalTok{ pptx\_obj }\SpecialCharTok{\%\textgreater{}\%} \CommentTok{\# add slide}
  \FunctionTok{add\_slide}\NormalTok{(}\AttributeTok{layout =} \StringTok{"Title and Content"}\NormalTok{, }\AttributeTok{master =} \StringTok{"Office Theme"}\NormalTok{)}

\FunctionTok{layout\_summary}\NormalTok{(pptx\_obj) }\CommentTok{\# contains only basic layouts}
\FunctionTok{layout\_properties}\NormalTok{(pptx\_obj) }\CommentTok{\# additional detail}

\NormalTok{pptx\_obj }\OtherTok{\textless{}{-}}\NormalTok{ pptx\_obj }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{on\_slide}\NormalTok{(}\AttributeTok{index =} \DecValTok{1}\NormalTok{) }\CommentTok{\# set active slide}
\FunctionTok{slide\_summary}\NormalTok{(pptx\_obj) }\CommentTok{\# slide is empty}
\end{Highlighting}
\end{Shaded}

\hypertarget{placeholders}{%
\subsection{Placeholders}\label{placeholders}}

\hypertarget{placeholders-and-shapes}{%
\subsubsection{Placeholders and Shapes}\label{placeholders-and-shapes}}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Example 1}
\NormalTok{my\_data }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\StringTok{"My functions are:"}\NormalTok{,}\StringTok{"ph\_with"}\NormalTok{,}\StringTok{"ph\_location\_type"}\NormalTok{)}
\NormalTok{my\_type }\OtherTok{\textless{}{-}} \StringTok{"body"}

\NormalTok{pptx\_obj }\OtherTok{\textless{}{-}} \FunctionTok{read\_pptx}\NormalTok{() }\CommentTok{\# new empty file}

\NormalTok{pptx\_obj }\OtherTok{\textless{}{-}}\NormalTok{ pptx\_obj }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{add\_slide}\NormalTok{(}\AttributeTok{layout =} \StringTok{"Title and Content"}\NormalTok{, }\AttributeTok{master =} \StringTok{"Office Theme"}\NormalTok{)}

\NormalTok{pptx\_obj }\OtherTok{\textless{}{-}}\NormalTok{ pptx\_obj }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{ph\_with}\NormalTok{(}\AttributeTok{value =}\NormalTok{ my\_data,}\AttributeTok{location =} \FunctionTok{ph\_location\_type}\NormalTok{(}\AttributeTok{type =}\NormalTok{ my\_type))}

\NormalTok{pptx\_obj }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{print}\NormalTok{(}\AttributeTok{target =} \StringTok{"output/test2.1.pptx"}\NormalTok{) }
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Example 2: }
\NormalTok{my\_data }\OtherTok{\textless{}{-}} \FunctionTok{head}\NormalTok{(mtcars)[,}\DecValTok{1}\SpecialCharTok{:}\DecValTok{4}\NormalTok{]}
\NormalTok{my\_type }\OtherTok{\textless{}{-}} \StringTok{"body"}

\NormalTok{pptx\_obj }\OtherTok{\textless{}{-}} \FunctionTok{read\_pptx}\NormalTok{() }\CommentTok{\# new empty file}
\NormalTok{pptx\_obj }\OtherTok{\textless{}{-}}\NormalTok{ pptx\_obj }\SpecialCharTok{\%\textgreater{}\%} 
    \FunctionTok{add\_slide}\NormalTok{(}\AttributeTok{layout =} \StringTok{"Title and Content"}\NormalTok{, }\AttributeTok{master =} \StringTok{"Office Theme"}\NormalTok{)}

\NormalTok{pptx\_obj }\OtherTok{\textless{}{-}}\NormalTok{ pptx\_obj }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{ph\_with}\NormalTok{(}\AttributeTok{value =}\NormalTok{ my\_data, }\AttributeTok{location =} \FunctionTok{ph\_location\_type}\NormalTok{(}\AttributeTok{type =}\NormalTok{ my\_type)) }

\NormalTok{pptx\_obj }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{print}\NormalTok{(}\AttributeTok{target =} \StringTok{"output/test2.2.pptx"}\NormalTok{) }
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Example 3}
\CommentTok{\# We add a text box item in a custom position}
\CommentTok{\# The same can be done for an image, logo, custom objects, etc.}

\NormalTok{my\_data }\OtherTok{\textless{}{-}} \StringTok{"My text"}
\NormalTok{my\_type }\OtherTok{\textless{}{-}} \StringTok{"body"}

\NormalTok{pptx\_obj }\OtherTok{\textless{}{-}} \FunctionTok{read\_pptx}\NormalTok{() }\CommentTok{\# new empty file}
\NormalTok{pptx\_obj }\OtherTok{\textless{}{-}}\NormalTok{ pptx\_obj }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{add\_slide}\NormalTok{(}\AttributeTok{layout =} \StringTok{"Title and Content"}\NormalTok{, }\AttributeTok{master =} \StringTok{"Office Theme"}\NormalTok{)}

\CommentTok{\#ph\_location is a subfunction which takes as argument }
\CommentTok{\#left/top/width/height, units are inches}

\NormalTok{pptx\_obj }\OtherTok{\textless{}{-}}\NormalTok{ pptx\_obj }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{ph\_with}\NormalTok{(}\AttributeTok{value =}\NormalTok{ my\_data, }\AttributeTok{location =} \FunctionTok{ph\_location}\NormalTok{(}\AttributeTok{left =} \DecValTok{2}\NormalTok{, }\AttributeTok{top =} \DecValTok{2}\NormalTok{, }\AttributeTok{width =} \DecValTok{3}\NormalTok{, }\AttributeTok{height =} \DecValTok{1}\NormalTok{))}

\NormalTok{pptx\_obj }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{print}\NormalTok{(}\AttributeTok{target =} \StringTok{"output/test2.3.pptx"}\NormalTok{) }
\end{Highlighting}
\end{Shaded}

\hypertarget{key-functions-ph_with}{%
\subsubsection{Key functions: ph\_with()}\label{key-functions-ph_with}}

\hypertarget{text-1}{%
\subsection{Text}\label{text-1}}

\hypertarget{working-with-text}{%
\subsubsection{Working with Text}\label{working-with-text}}

Each new text item added to a PowerPoint via officer is a paragraph object
fpar() (``formatted paragraph'') creates this object

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{my\_data }\OtherTok{\textless{}{-}} \FunctionTok{fpar}\NormalTok{(}\StringTok{"My text"}\NormalTok{)}
\NormalTok{my\_type }\OtherTok{\textless{}{-}} \StringTok{"body"}

\NormalTok{pptx\_obj }\OtherTok{\textless{}{-}} \FunctionTok{read\_pptx}\NormalTok{() }\CommentTok{\# new empty file}
\NormalTok{pptx\_obj }\OtherTok{\textless{}{-}}\NormalTok{ pptx\_obj }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{add\_slide}\NormalTok{(}\AttributeTok{layout =} \StringTok{"Title and Content"}\NormalTok{, }\AttributeTok{master =} \StringTok{"Office Theme"}\NormalTok{)}

\DocumentationTok{\#\# Add paragraph}
\NormalTok{pptx\_obj }\OtherTok{\textless{}{-}}\NormalTok{ pptx\_obj }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{ph\_with}\NormalTok{(}\AttributeTok{value =}\NormalTok{ my\_data, }\AttributeTok{location =} \FunctionTok{ph\_location\_type}\NormalTok{(}\AttributeTok{type =}\NormalTok{ my\_type))}

\DocumentationTok{\#\# Try to add a second paragraph}
\NormalTok{my\_data2 }\OtherTok{\textless{}{-}} \FunctionTok{fpar}\NormalTok{(}\StringTok{"My other text"}\NormalTok{)}
\NormalTok{my\_type }\OtherTok{\textless{}{-}} \StringTok{"body"}

\NormalTok{pptx\_obj }\OtherTok{\textless{}{-}}\NormalTok{ pptx\_obj }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{ph\_with}\NormalTok{(}\AttributeTok{value =}\NormalTok{ my\_data2, }\AttributeTok{location =} \FunctionTok{ph\_location\_type}\NormalTok{(}\AttributeTok{type =}\NormalTok{ my\_type) )}

\NormalTok{pptx\_obj }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{print}\NormalTok{(}\AttributeTok{target =} \StringTok{"output/test3.1.pptx"}\NormalTok{) }
\DocumentationTok{\#\# As we see, this code doesn’t produce bullet points as we might hope}
\end{Highlighting}
\end{Shaded}

block\_list() allows us to wrap multiple paragraphs together

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{my\_data }\OtherTok{\textless{}{-}} \FunctionTok{fpar}\NormalTok{(}\StringTok{"My text"}\NormalTok{)}
\NormalTok{blank\_line }\OtherTok{\textless{}{-}} \FunctionTok{fpar}\NormalTok{(}\StringTok{""}\NormalTok{)}
\NormalTok{my\_data2 }\OtherTok{\textless{}{-}} \FunctionTok{fpar}\NormalTok{(}\StringTok{"My other text"}\NormalTok{)}

\NormalTok{my\_list }\OtherTok{\textless{}{-}} \FunctionTok{block\_list}\NormalTok{(my\_data, blank\_line, my\_data2)}

\NormalTok{my\_type }\OtherTok{\textless{}{-}} \StringTok{"body"}

\NormalTok{pptx\_obj }\OtherTok{\textless{}{-}} \FunctionTok{read\_pptx}\NormalTok{() }\CommentTok{\# new empty file}
\NormalTok{pptx\_obj }\OtherTok{\textless{}{-}}\NormalTok{ pptx\_obj }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{add\_slide}\NormalTok{(}\AttributeTok{layout =} \StringTok{"Title and Content"}\NormalTok{, }\AttributeTok{master =} \StringTok{"Office Theme"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{ph\_with}\NormalTok{(}\AttributeTok{value =}\NormalTok{ my\_list, }\AttributeTok{location =} \FunctionTok{ph\_location\_type}\NormalTok{(}\AttributeTok{type =}\NormalTok{ my\_type) )}

\NormalTok{pptx\_obj }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{print}\NormalTok{(}\AttributeTok{target =} \StringTok{"output/test3.2.pptx"}\NormalTok{) }
\end{Highlighting}
\end{Shaded}

Use ftext() (``formatted text'') to edit the text before pasting into paragraphs. ftext() requires a second argument called prop which contains the formatting properties.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{my\_prop }\OtherTok{\textless{}{-}} \FunctionTok{fp\_text}\NormalTok{(}\AttributeTok{color =} \StringTok{"red"}\NormalTok{, }\AttributeTok{font.size =} \DecValTok{16}\NormalTok{)}
\NormalTok{my\_text }\OtherTok{\textless{}{-}} \FunctionTok{ftext}\NormalTok{(}\StringTok{"Hello"}\NormalTok{, }\AttributeTok{prop =}\NormalTok{ my\_prop)}

\NormalTok{my\_par }\OtherTok{\textless{}{-}} \FunctionTok{fpar}\NormalTok{(my\_text) }\DocumentationTok{\#\# formatted}
\NormalTok{blank\_line }\OtherTok{\textless{}{-}} \FunctionTok{fpar}\NormalTok{(}\StringTok{""}\NormalTok{)}

\NormalTok{my\_par2 }\OtherTok{\textless{}{-}} \FunctionTok{fpar}\NormalTok{(}\StringTok{"My other text"}\NormalTok{) }\DocumentationTok{\#\# unformatted}
\NormalTok{my\_list }\OtherTok{\textless{}{-}} \FunctionTok{block\_list}\NormalTok{(my\_par,blank\_line, my\_par2)}

\NormalTok{pptx\_obj }\OtherTok{\textless{}{-}} \FunctionTok{read\_pptx}\NormalTok{() }\CommentTok{\# new empty file}

\NormalTok{pptx\_obj }\OtherTok{\textless{}{-}}\NormalTok{ pptx\_obj }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{add\_slide}\NormalTok{(}\AttributeTok{layout =} \StringTok{"Title and Content"}\NormalTok{, }\AttributeTok{master =} \StringTok{"Office Theme"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{ph\_with}\NormalTok{(}\AttributeTok{value =}\NormalTok{ my\_list, }\AttributeTok{location =} \FunctionTok{ph\_location\_type}\NormalTok{(}\AttributeTok{type =}\NormalTok{ my\_type) )}

\NormalTok{pptx\_obj }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{print}\NormalTok{(}\AttributeTok{target =} \StringTok{"output/test3.3.pptx"}\NormalTok{) }
\end{Highlighting}
\end{Shaded}

\hypertarget{key-functions-fpar-ftext-fp_text-block_list}{%
\subsubsection{Key functions: fpar(), ftext(), fp\_text(), block\_list()}\label{key-functions-fpar-ftext-fp_text-block_list}}

\hypertarget{example-code-1}{%
\subsubsection{Example Code}\label{example-code-1}}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{my\_list }\OtherTok{\textless{}{-}} \FunctionTok{block\_list}\NormalTok{(}
  \FunctionTok{fpar}\NormalTok{(}\FunctionTok{ftext}\NormalTok{(}\StringTok{"Hello"}\NormalTok{, }\AttributeTok{prop =} \FunctionTok{fp\_text}\NormalTok{(}\AttributeTok{color =} \StringTok{"red"}\NormalTok{, }\AttributeTok{font.size =} \DecValTok{16}\NormalTok{))) ,}
  \FunctionTok{fpar}\NormalTok{(}\FunctionTok{ftext}\NormalTok{(}\StringTok{"World"}\NormalTok{, }\AttributeTok{prop =} \FunctionTok{fp\_text}\NormalTok{(}\AttributeTok{color =} \StringTok{"blue"}\NormalTok{, }\AttributeTok{font.size =} \DecValTok{14}\NormalTok{))) )}

\CommentTok{\# The hierarchy is:}
\CommentTok{\# block\_list \textgreater{} fpar \textgreater{} ftext \textgreater{} fp\_text}

\NormalTok{pptx\_obj }\OtherTok{\textless{}{-}} \FunctionTok{read\_pptx}\NormalTok{() }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{add\_slide}\NormalTok{(}\AttributeTok{layout =} \StringTok{"Title and Content"}\NormalTok{, }\AttributeTok{master =} \StringTok{"Office Theme"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{ph\_with}\NormalTok{(}\AttributeTok{value =} \FunctionTok{block\_list}\NormalTok{(}
    \FunctionTok{fpar}\NormalTok{(}\FunctionTok{ftext}\NormalTok{(}\StringTok{"Hello"}\NormalTok{, }\AttributeTok{prop =} \FunctionTok{fp\_text}\NormalTok{(}\AttributeTok{color =} \StringTok{"red"}\NormalTok{, }\AttributeTok{font.size =} \DecValTok{16}\NormalTok{))) ,}
    \FunctionTok{fpar}\NormalTok{(}\FunctionTok{ftext}\NormalTok{(}\StringTok{"World"}\NormalTok{, }\AttributeTok{prop =} \FunctionTok{fp\_text}\NormalTok{(}\AttributeTok{color =} \StringTok{"blue"}\NormalTok{, }\AttributeTok{font.size =} \DecValTok{14}\NormalTok{)))),}
    \FunctionTok{ph\_location\_type}\NormalTok{(}\AttributeTok{type =} \StringTok{"body"}\NormalTok{)}
\NormalTok{  ) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{print}\NormalTok{(}\AttributeTok{target =} \StringTok{"output/test3.4.pptx"}\NormalTok{) }
\end{Highlighting}
\end{Shaded}

\hypertarget{tables}{%
\subsection{Tables}\label{tables}}

\hypertarget{basic-code}{%
\subsubsection{Basic Code}\label{basic-code}}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{my\_data }\OtherTok{\textless{}{-}} \FunctionTok{head}\NormalTok{(mtcars)}

\NormalTok{pptx\_obj }\OtherTok{\textless{}{-}} \FunctionTok{read\_pptx}\NormalTok{() }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{add\_slide}\NormalTok{(}\AttributeTok{layout =} \StringTok{"Title and Content"}\NormalTok{, }\AttributeTok{master =} \StringTok{"Office Theme"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{ph\_with}\NormalTok{(}\AttributeTok{value =} \FunctionTok{head}\NormalTok{(mtcars), }\AttributeTok{location =} \FunctionTok{ph\_location\_type}\NormalTok{(}\AttributeTok{type =} \StringTok{"body"}\NormalTok{)) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{print}\NormalTok{(}\AttributeTok{target =} \StringTok{"output/test4.1.pptx"}\NormalTok{) }
\end{Highlighting}
\end{Shaded}

\hypertarget{introduction-to-flextable}{%
\subsubsection{Introduction to flextable}\label{introduction-to-flextable}}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{base\_table }\OtherTok{\textless{}{-}}\NormalTok{ tutorial\_data[[}\StringTok{"Age"}\NormalTok{]] }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{table}\NormalTok{() }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{enframe}\NormalTok{(}\AttributeTok{name =} \StringTok{"Age"}\NormalTok{, }\AttributeTok{value =} \StringTok{"Count"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{Count =} \FunctionTok{as.integer}\NormalTok{(Count)) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{Percent =} \FunctionTok{format\_percent}\NormalTok{(Count }\SpecialCharTok{/} \FunctionTok{sum}\NormalTok{(Count), }\AttributeTok{num\_decimals =} \DecValTok{2}\NormalTok{))}

\NormalTok{base\_table }
\end{Highlighting}
\end{Shaded}

flextable: create attractive tables with predefined formatting. Use of \%\textgreater\% is recommended for readability

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(flextable)}

\NormalTok{ft\_table }\OtherTok{\textless{}{-}}\NormalTok{ base\_table }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{flextable}\NormalTok{()}

\NormalTok{ft\_table }\CommentTok{\# see preliminary result in Viewer tab of RStudio}
\end{Highlighting}
\end{Shaded}

\hypertarget{demonstration}{%
\subsubsection{Demonstration}\label{demonstration}}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{ft\_table }\OtherTok{\textless{}{-}}\NormalTok{ base\_table }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{flextable}\NormalTok{() }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{autofit}\NormalTok{() }\SpecialCharTok{\%\textgreater{}\%} \CommentTok{\# straightforward, column width}
  \CommentTok{\# ALIGNMENT}
  \CommentTok{\# alignment of header: we use part argument}
  \FunctionTok{align}\NormalTok{(}\AttributeTok{align =} \StringTok{"center"}\NormalTok{, }\AttributeTok{part =} \StringTok{"header"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
  \CommentTok{\# alignment of content: we can use part = "body" or specify exact lines }
  \FunctionTok{align}\NormalTok{(}\AttributeTok{i =} \DecValTok{1}\SpecialCharTok{:}\FunctionTok{nrow}\NormalTok{(base\_table), }\AttributeTok{j =} \DecValTok{1}\SpecialCharTok{:}\FunctionTok{ncol}\NormalTok{(base\_table), }\AttributeTok{align =} \StringTok{"center"}\NormalTok{) }

\NormalTok{ft\_table}
\end{Highlighting}
\end{Shaded}

Set font and characters

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{ft\_table }\OtherTok{=}\NormalTok{ ft\_table }\SpecialCharTok{\%\textgreater{}\%} 
\CommentTok{\# FONT AND CHARACTERS}
\CommentTok{\# each command is independent, there are no nested functions as in officer}
\FunctionTok{bold}\NormalTok{(}\AttributeTok{i =} \DecValTok{1}\NormalTok{, }\AttributeTok{j =} \DecValTok{1}\SpecialCharTok{:}\DecValTok{3}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%} \CommentTok{\# first row, all cols}
  \FunctionTok{italic}\NormalTok{(}\AttributeTok{i =} \DecValTok{3}\NormalTok{, }\AttributeTok{j =} \SpecialCharTok{\textasciitilde{}}\NormalTok{Age}\SpecialCharTok{+}\NormalTok{Count}\SpecialCharTok{+}\NormalTok{Percent) }\SpecialCharTok{\%\textgreater{}\%} \CommentTok{\# first row, all cols, using \textasciitilde{} notation}
  
  \FunctionTok{fontsize}\NormalTok{(}\AttributeTok{i =} \DecValTok{2}\NormalTok{, }\AttributeTok{size =} \DecValTok{16}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{font}\NormalTok{(}\AttributeTok{fontname =} \StringTok{"Calibri"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%} \CommentTok{\# since no i or j are input, change is for all data}
  \FunctionTok{font}\NormalTok{(}\AttributeTok{fontname =} \StringTok{"Roboto"}\NormalTok{, }\AttributeTok{part =} \StringTok{"header"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%} \CommentTok{\#different font for header}
  \FunctionTok{color}\NormalTok{(}\AttributeTok{i =} \DecValTok{3}\NormalTok{, }\AttributeTok{j =} \DecValTok{2}\NormalTok{, }\AttributeTok{color =} \StringTok{"red"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
  
  \CommentTok{\# WIDTH AND HEIGHT}
  \CommentTok{\# all measurements are in inches}
  \FunctionTok{width}\NormalTok{(}\AttributeTok{j =} \DecValTok{1}\NormalTok{, }\AttributeTok{width =} \DecValTok{4}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%} \CommentTok{\# column 1 wider}
  \FunctionTok{height}\NormalTok{(}\AttributeTok{i =} \DecValTok{8}\NormalTok{, }\AttributeTok{height =} \FloatTok{0.5}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%} \CommentTok{\# row 8 change}
  \CommentTok{\# CELL COLORS (background) }
  \FunctionTok{bg}\NormalTok{(}\AttributeTok{bg =} \StringTok{"\#0088FF"}\NormalTok{, }\AttributeTok{part =} \StringTok{"header"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%} \CommentTok{\# a custom background for the header}
  \FunctionTok{bg}\NormalTok{(}\AttributeTok{i =} \DecValTok{7}\SpecialCharTok{:}\DecValTok{10}\NormalTok{, }\AttributeTok{bg =} \StringTok{"\#C5C5C5"}\NormalTok{) }\CommentTok{\# a custom background for some cells}

\NormalTok{ft\_table}
\end{Highlighting}
\end{Shaded}

Set borders

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#BORDERS}
\CommentTok{\# For borders we need to use nested functions (similar to fpar\textgreater{}ftext\textgreater{}fp\_text)}
\CommentTok{\#fp\_border() is the second level function we will use to specify border"s characteristics}
\CommentTok{\# as argument it takes color, style, and width}
  
\NormalTok{my\_border }\OtherTok{\textless{}{-}} \FunctionTok{fp\_border}\NormalTok{(}\AttributeTok{color =} \StringTok{"black"}\NormalTok{, }\AttributeTok{style =} \StringTok{"solid"}\NormalTok{, }\AttributeTok{width =} \DecValTok{2}\NormalTok{)}

\CommentTok{\# We use this second level function inside various main border functions}
\CommentTok{\# border\_outer()}
\CommentTok{\# border\_inner()}
\CommentTok{\# border\_inner\_h()}
\CommentTok{\# border\_inner\_v()}
\NormalTok{ft\_table }\OtherTok{\textless{}{-}}\NormalTok{ ft\_table }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{border\_outer}\NormalTok{(}\AttributeTok{part =} \StringTok{"all"}\NormalTok{, }\AttributeTok{border =}\NormalTok{ my\_border) }\SpecialCharTok{\%\textgreater{}\%} \CommentTok{\# using predefined border}
  \FunctionTok{border\_inner}\NormalTok{(}\AttributeTok{part =} \StringTok{"body"}\NormalTok{, }\AttributeTok{border =} \FunctionTok{fp\_border}\NormalTok{(}\AttributeTok{style =} \StringTok{"dashed"}\NormalTok{))}

\NormalTok{ft\_table}
\end{Highlighting}
\end{Shaded}

\hypertarget{demonstration-output}{%
\subsubsection{Demonstration Output}\label{demonstration-output}}

\hypertarget{reformat-original-example}{%
\subsubsection{Reformat original example}\label{reformat-original-example}}

\begin{Shaded}
\begin{Highlighting}[]
\DocumentationTok{\#\# ft parameters}
\NormalTok{header\_background\_color }\OtherTok{=}\NormalTok{ a\_green}
\NormalTok{body\_background\_color }\OtherTok{=}\NormalTok{ a\_cream}
\NormalTok{header\_text\_col }\OtherTok{=}\NormalTok{ a\_cream}
\NormalTok{body\_text\_col }\OtherTok{=}\NormalTok{ a\_dark\_grey}
\NormalTok{total\_text\_col }\OtherTok{=}\NormalTok{ a\_red}

\NormalTok{border\_solid }\OtherTok{\textless{}{-}} \FunctionTok{fp\_border}\NormalTok{(}\AttributeTok{color =}\NormalTok{ a\_dark\_grey, }\AttributeTok{width =} \DecValTok{2}\NormalTok{)}
\NormalTok{border\_dashed }\OtherTok{\textless{}{-}} \FunctionTok{fp\_border}\NormalTok{(}\AttributeTok{color =}\NormalTok{ a\_dark\_grey, }\AttributeTok{width =} \DecValTok{1}\NormalTok{, }\AttributeTok{style =} \StringTok{"dashed"}\NormalTok{)}

\NormalTok{ft }\OtherTok{\textless{}{-}}\NormalTok{ summary\_table }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{flextable}\NormalTok{() }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{font}\NormalTok{(}\AttributeTok{fontname =}\NormalTok{ font\_name, }\AttributeTok{part =} \StringTok{"all"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{fontsize}\NormalTok{(}\AttributeTok{size =}\NormalTok{ font\_size, }\AttributeTok{part =} \StringTok{"all"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{bold}\NormalTok{(}\AttributeTok{part =} \StringTok{"header"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{border\_remove}\NormalTok{() }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{border\_outer}\NormalTok{(}\AttributeTok{border =}\NormalTok{ border\_solid) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{border\_inner\_v}\NormalTok{(}\AttributeTok{border =}\NormalTok{ border\_solid, }\AttributeTok{part =} \StringTok{"header"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{border\_inner\_h}\NormalTok{(}\AttributeTok{border =}\NormalTok{ border\_dashed, }\AttributeTok{part =} \StringTok{"header"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{border\_inner\_v}\NormalTok{(}\AttributeTok{border =}\NormalTok{ border\_solid, }\AttributeTok{part =} \StringTok{"body"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{border\_inner\_h}\NormalTok{(}\AttributeTok{border =}\NormalTok{ border\_dashed, }\AttributeTok{part =} \StringTok{"body"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{bg}\NormalTok{(}\AttributeTok{bg =}\NormalTok{ header\_background\_color, }\AttributeTok{part =} \StringTok{"header"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{bg}\NormalTok{(}\AttributeTok{bg =}\NormalTok{ body\_background\_color, }\AttributeTok{part =} \StringTok{"body"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{align}\NormalTok{(}\AttributeTok{align =} \StringTok{"center"}\NormalTok{, }\AttributeTok{part =} \StringTok{"all"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{color}\NormalTok{(}\AttributeTok{color =}\NormalTok{ header\_text\_col, }\AttributeTok{part =} \StringTok{"header"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{color}\NormalTok{(}\AttributeTok{color =}\NormalTok{ body\_text\_col, }\AttributeTok{part =} \StringTok{"body"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{color}\NormalTok{(}\AttributeTok{color =}\NormalTok{ total\_text\_col, }\AttributeTok{part =} \StringTok{"body"}\NormalTok{, }\AttributeTok{i =} \FunctionTok{nrow}\NormalTok{(summary\_table)) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{italic}\NormalTok{(}\AttributeTok{part =} \StringTok{"body"}\NormalTok{, }\AttributeTok{i =} \FunctionTok{nrow}\NormalTok{(summary\_table)) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{bold}\NormalTok{(}\AttributeTok{part =} \StringTok{"body"}\NormalTok{, }\AttributeTok{i =} \FunctionTok{nrow}\NormalTok{(summary\_table)) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{autofit}\NormalTok{(}\AttributeTok{add\_w =} \DecValTok{1}\NormalTok{)}

\NormalTok{ft}
\CommentTok{\# Add table to slide}
\NormalTok{pptx\_obj }\OtherTok{\textless{}{-}} \FunctionTok{read\_pptx}\NormalTok{() }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{add\_slide}\NormalTok{(}\AttributeTok{layout =} \StringTok{"Title and Content"}\NormalTok{, }\AttributeTok{master =} \StringTok{"Office Theme"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{ph\_with}\NormalTok{(}\AttributeTok{value =}\NormalTok{ ft, }\FunctionTok{ph\_location}\NormalTok{(}\AttributeTok{left =} \DecValTok{2}\NormalTok{, }\AttributeTok{top =} \DecValTok{2}\NormalTok{, }\AttributeTok{width =} \DecValTok{4}\NormalTok{ )) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{print}\NormalTok{(}\AttributeTok{target =} \StringTok{"output/test4.7.pptx"}\NormalTok{) }
\CommentTok{\# positions are fixed. We can find exact positions to center the table}
\end{Highlighting}
\end{Shaded}

\hypertarget{key-functions-flextable-align-bold-font-color-bg-height-width-border_outer-border_inner-border_inner_h-border_inner_v-autofit}{%
\subsubsection{key functions: flextable(), align(), bold(), font(), color(), bg(), height() \& width(), border\_outer() \& border\_inner() \& border\_inner\_h() \& border\_inner\_v(), autofit()}\label{key-functions-flextable-align-bold-font-color-bg-height-width-border_outer-border_inner-border_inner_h-border_inner_v-autofit}}

Additional function to learn: merge(), compose() \& as\_chunk(), style()

fix\_border\_issues()

\hypertarget{charts}{%
\subsection{Charts}\label{charts}}

\hypertarget{adding-charts-as-images}{%
\subsubsection{Adding charts as images}\label{adding-charts-as-images}}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# We have preloaded a function to plot the chart.}
\CommentTok{\# the function is using ggplot2 as plotting library}

\NormalTok{chart\_to\_plot }\OtherTok{\textless{}{-}}\NormalTok{ sample\_data\_list[[}\StringTok{\textquotesingle{}Sample 1\textquotesingle{}}\NormalTok{]] }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{make\_jar\_chart}\NormalTok{() }\CommentTok{\# code to create a ggplot2 item, we will skip the contents}
\FunctionTok{print}\NormalTok{(chart\_to\_plot) }\CommentTok{\# see in Plots Window}
\end{Highlighting}
\end{Shaded}

\hypertarget{rvg-example}{%
\subsubsection{rvg Example}\label{rvg-example}}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# the output is a ggplot2 object}

\CommentTok{\# To add this object as a rvg object on a slide, we will use the ph\_with\_vg}
\CommentTok{\# ph\_with\_vg replaces the ph\_with for a rvg object}
\CommentTok{\# ph\_with\_vg\_at allows to input a precise position for a chart, using the top/left we know already}
\CommentTok{\# all units are in inches}
\CommentTok{\# argument code requires print(chart), argument type is a specific place on slide ("body" or other)}


\DocumentationTok{\#\# IMPORTANT: ph\_with\_vg is is deprecated.}
\CommentTok{\#old syntaxis ph\_with\_vg(code = print(chart\_to\_plot), type = "body") }

\NormalTok{pptx\_obj }\OtherTok{\textless{}{-}} \FunctionTok{read\_pptx}\NormalTok{() }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{add\_slide}\NormalTok{(}\AttributeTok{layout =} \StringTok{"Title and Content"}\NormalTok{, }\AttributeTok{master =} \StringTok{"Office Theme"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{ph\_with}\NormalTok{(}\AttributeTok{value =} \FunctionTok{dml}\NormalTok{(}\AttributeTok{ggobj =}\NormalTok{ chart\_to\_plot), }\AttributeTok{location  =}  \FunctionTok{ph\_location\_type}\NormalTok{(}\AttributeTok{type =} \StringTok{\textquotesingle{}body\textquotesingle{}}\NormalTok{)) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{print}\NormalTok{(}\AttributeTok{target =} \StringTok{"output/5.2.rvg1.pptx"}\NormalTok{) }

\DocumentationTok{\#\# IMPORTANT: ph\_with\_vg\_at is is deprecated.}
\CommentTok{\# old syntaxis ph\_with\_vg\_at(code = print(chart\_to\_plot), left = 1, top = 1, width = 8, height = 6) }

\NormalTok{pptx\_obj }\OtherTok{\textless{}{-}} \FunctionTok{read\_pptx}\NormalTok{() }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{add\_slide}\NormalTok{(}\AttributeTok{layout =} \StringTok{"Title and Content"}\NormalTok{, }\AttributeTok{master =} \StringTok{"Office Theme"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{ph\_with}\NormalTok{(}\AttributeTok{value =} \FunctionTok{dml}\NormalTok{(}\AttributeTok{ggobj =}\NormalTok{ chart\_to\_plot), }\AttributeTok{location =}  \FunctionTok{ph\_location}\NormalTok{(}\AttributeTok{left =} \DecValTok{1}\NormalTok{, }\AttributeTok{top =} \DecValTok{1}\NormalTok{, }\AttributeTok{width =} \DecValTok{8}\NormalTok{, }\AttributeTok{height =} \DecValTok{6}\NormalTok{))  }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{print}\NormalTok{(}\AttributeTok{target =} \StringTok{"output/5.2.rvg2.pptx"}\NormalTok{) }

\CommentTok{\# all items on the chart inside the pptx are now editable, just click on any and see }
\CommentTok{\# the Shape Format tab in PowerPoint}
\end{Highlighting}
\end{Shaded}

\hypertarget{mschart-package}{%
\subsection{mschart Package}\label{mschart-package}}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# sample dataframe}
\NormalTok{mydata }\OtherTok{\textless{}{-}}\NormalTok{ sample\_data\_list[[}\StringTok{\textquotesingle{}Sample 1\textquotesingle{}}\NormalTok{]] }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{group\_by}\NormalTok{(Variable,Response) }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{count}\NormalTok{()}

\CommentTok{\# syntaxis is similar to ggplot2"s aes() with x,y,group}
\NormalTok{my\_barchart }\OtherTok{\textless{}{-}} \FunctionTok{ms\_barchart}\NormalTok{(}\AttributeTok{data =}\NormalTok{ mydata, }\AttributeTok{x =} \StringTok{"Variable"}\NormalTok{, }\AttributeTok{y =} \StringTok{"n"}\NormalTok{, }\AttributeTok{group =} \StringTok{"Response"}\NormalTok{)}

\CommentTok{\# to add the object to a powerpoint slide we can use the officer"s native ph\_with}
\NormalTok{pptx\_obj }\OtherTok{\textless{}{-}} \FunctionTok{read\_pptx}\NormalTok{() }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{add\_slide}\NormalTok{(}\AttributeTok{layout =} \StringTok{"Title and Content"}\NormalTok{, }\AttributeTok{master =} \StringTok{"Office Theme"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{ph\_with}\NormalTok{(}\AttributeTok{value =}\NormalTok{ my\_barchart, }\AttributeTok{location =} \FunctionTok{ph\_location\_type}\NormalTok{(}\AttributeTok{type =} \StringTok{"body"}\NormalTok{)) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{print}\NormalTok{(}\AttributeTok{target =} \StringTok{"output/5.3.msoffice.pptx"}\NormalTok{) }

\CommentTok{\# if we would open a rvg slide and an ms office slide and click on the slide}
\CommentTok{\# for the rvg slide the only menu that appear is shape format}
\CommentTok{\# While for the msoffice chart we have now the chart design option with all msoffice functionalities}
\CommentTok{\# by using chart\_settings() functions one can customise in R the charts}
\end{Highlighting}
\end{Shaded}

\hypertarget{word}{%
\section{Word}\label{word}}

\hypertarget{word-documents}{%
\subsection{Word documents}\label{word-documents}}

Formats share similarities

body\_add\_*()

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{my\_doc }\OtherTok{\textless{}{-}} \FunctionTok{read\_docx}\NormalTok{() }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{body\_add\_par}\NormalTok{(}\AttributeTok{value =} \StringTok{"My Text"}\NormalTok{, }\AttributeTok{style =} \StringTok{"Normal"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{body\_add\_par}\NormalTok{(}\AttributeTok{value =} \StringTok{"Other Text"}\NormalTok{, }\AttributeTok{style =} \StringTok{"Normal"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{body\_add\_par}\NormalTok{(}\AttributeTok{value =} \StringTok{"Conclusion"}\NormalTok{, }\AttributeTok{style =} \StringTok{"Normal"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{print}\NormalTok{(}\AttributeTok{target =} \StringTok{\textquotesingle{}output/6.1.mydoc.docx\textquotesingle{}}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

body\_add\_break()

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{my\_doc }\OtherTok{\textless{}{-}} \FunctionTok{read\_docx}\NormalTok{() }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{body\_add\_par}\NormalTok{(}\AttributeTok{value =} \StringTok{"My Text"}\NormalTok{, }\AttributeTok{style =} \StringTok{"Normal"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{body\_add\_break}\NormalTok{() }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{body\_add\_par}\NormalTok{(}\AttributeTok{value =} \StringTok{"Conclusion"}\NormalTok{, }\AttributeTok{style =} \StringTok{"Normal"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{print}\NormalTok{(}\AttributeTok{target =} \StringTok{\textquotesingle{}output/6.2.mydoc.docx\textquotesingle{}}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{my\_format }\OtherTok{\textless{}{-}} \FunctionTok{fp\_text}\NormalTok{(}\AttributeTok{font.family =} \StringTok{\textquotesingle{}Calibri\textquotesingle{}}\NormalTok{, }\AttributeTok{font.size =} \DecValTok{14}\NormalTok{, }\AttributeTok{bold =} \ConstantTok{TRUE}\NormalTok{, }\AttributeTok{color =} \StringTok{\textquotesingle{}red\textquotesingle{}}\NormalTok{)}
\NormalTok{my\_text }\OtherTok{\textless{}{-}} \FunctionTok{ftext}\NormalTok{(}\StringTok{\textquotesingle{}My dataset is:\textquotesingle{}}\NormalTok{, my\_format)}
\NormalTok{my\_par }\OtherTok{\textless{}{-}} \FunctionTok{fpar}\NormalTok{(my\_text)}

\NormalTok{doc }\OtherTok{\textless{}{-}} \FunctionTok{read\_docx}\NormalTok{() }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{body\_add\_par}\NormalTok{(}\AttributeTok{value =} \StringTok{"Table of content"}\NormalTok{, }\AttributeTok{style =} \StringTok{"heading 1"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{body\_add\_par}\NormalTok{(}\AttributeTok{value =} \StringTok{""}\NormalTok{, }\AttributeTok{style =} \StringTok{"Normal"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{body\_add\_fpar}\NormalTok{(my\_par, }\AttributeTok{style =} \StringTok{"Normal"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%} \CommentTok{\#formatted paragraph function}
  \FunctionTok{body\_add\_par}\NormalTok{(}\AttributeTok{value =} \StringTok{""}\NormalTok{, }\AttributeTok{style =} \StringTok{"Normal"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{body\_add\_table}\NormalTok{(}\AttributeTok{value =} \FunctionTok{head}\NormalTok{(mtcars)[, }\DecValTok{1}\SpecialCharTok{:}\DecValTok{4}\NormalTok{], }\AttributeTok{style =} \StringTok{"table\_template"}\NormalTok{ ) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{print}\NormalTok{(}\AttributeTok{target =} \StringTok{\textquotesingle{}output/6.3.mydoc.docx\textquotesingle{}}\NormalTok{)}

\FunctionTok{read\_docx}\NormalTok{() }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{styles\_info}\NormalTok{() }
\end{Highlighting}
\end{Shaded}

\hypertarget{part-bon-appuxe9tit}{%
\part*{Bon Appétit}\label{part-bon-appuxe9tit}}
\addcontentsline{toc}{part}{Bon Appétit}

\hypertarget{example-projects}{%
\chapter{Example Projects}\label{example-projects}}

\hypertarget{data-collection}{%
\chapter{Data Collection}\label{data-collection}}

\hypertarget{design-1}{%
\section{Design}\label{design-1}}

\hypertarget{execute-1}{%
\section{Execute}\label{execute-1}}

\hypertarget{import-1}{%
\section{Import}\label{import-1}}

To analyze data, we need \emph{data}. If this data is already available in R, then the analysis can be performed directly. However, in much cases, the data is stored outside the R environment, and needs to be imported.

In practice, the data might be stored in as many format as one can imagine, whether it ends up being a fairly common solution (.txt file, .csv file, or .xls/.xlsx file), or software specific (e.g.~Stata, SPSS, etc.).
Since it is very common to store the data in Excel spreadsheets (.xlsx) due to its simplicity, the emphasis is on this solution. Fortunately, most generalities presented for Excel files also apply to other formats through \texttt{base::read.table()} for .txt files, \texttt{base::read.csv()} and \texttt{base::read.csv2()} for .csv files, or through the \texttt{\{read\}} package (which is part of the \texttt{\{tidyverse\}}).

For other (less common) formats, the reader can find packages that would allow importing their files into R. Particular interest can be given to the package \texttt{\{rio\}} (\emph{rio} stands for \emph{R} \emph{I}nput and \emph{O}utput) which provides an easy solution that 1. can handle a large variety of files, 2. can actually guess the type of file it is, and 3. provides tools to import, export, and convert almost any type of data format, including .csv, .xls and .xlsx, or data from other statistical software such as SAS (.sas7bdat and .xpt), SPSS (.sav and .por), or Stata (.dta). As an alternative, the package \texttt{\{foreign\}} provides functions that allow importing data stored from other statistical software (incl.~Minitab, S, SAS, Stata, SPSS, etc.)

Although Excel is most likely one of the most popular way of storing data, there are no \texttt{\{base\}} functions that allow importing such files easily. Fortunately, many packages have been developed in that purpose, including \texttt{\{XLConnect\}}, \texttt{\{xlsx\}}, \texttt{\{gdata\}}, and \texttt{\{readxl\}}. Due to its convenience and speed of execution, we will be using \texttt{\{readxl\}} here.

\hypertarget{importing-structured-excel-file}{%
\subsection{Importing Structured Excel File}\label{importing-structured-excel-file}}

First, let's import the \emph{Sensory Profile.xlsx} workbook using the \texttt{readxl::read\_xlsx()} file, by informing as parameter the location of the file (informed in \texttt{file\_path} using the package \texttt{\{here\}}) and the \texttt{sheet} we want to read from.

This file is called \emph{structured} as all the relevant information is already stored in the same sheet in a structured way. In other words, no decoding is required here, and there are no `unexpected' rows or columns (e.g.~empty lines, or lines with additional information regarding the data but that is not data):

\begin{itemize}
\tightlist
\item
  The first row within the \emph{Data} sheet of \emph{Sensory Profile.xlsx} contains the headers,\\
\item
  From the second row onwards, only data is being stored.
\end{itemize}

Since this data will be used for some analyses, it is assigned data to an R object called \texttt{sensory}.

To ensure that the importation went well, we print \texttt{sensory} to see how it looks like. Since \texttt{\{readxl\}} has been developed by Hadley Wickham and colleagues, its functions follow the \texttt{\{tidyverse\}} principles and the dataset thus imported is a \texttt{tibble}. Let's take advantage of the printing properties of a \texttt{tibble} to evaluate \texttt{sensory}:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{sensory}
\end{Highlighting}
\end{Shaded}

\texttt{sensory} is a tibble with 99 rows and 35 columns that includes the \texttt{Judge} information (first column, defined as character), the \texttt{Product} information (second and third columns, defined as character), and the sensory attributes (fourth column onward, defined as numerical or \texttt{dbl}).

\hypertarget{importing-unstructured-excel-file}{%
\subsection{Importing Unstructured Excel File}\label{importing-unstructured-excel-file}}

In some cases, the dataset is not so well organized/structured, and may need to be \emph{decoded}. This is the case for the workbook entitled \emph{TFEQ.xlsx}. For this file:

\begin{itemize}
\tightlist
\item
  The variables' name have been coded and their corresponding names (together with some other valuable information we will be using in the next chapter) are stored in a different sheet entitled \emph{Variables};
\item
  The different levels of each variable (including their code and corresponding names) are stored in another sheet entitled \emph{Levels}.
\end{itemize}

To import and decode this dataset, multiple steps are required:

\begin{itemize}
\tightlist
\item
  Import the variables' name only;
\item
  Import the information regarding the levels;
\item
  Import the dataset without the first line of header, but by providing the correct names obtained in the first step;
\item
  Decode each question (when needed) by replacing the numerical code by their corresponding labels.
\end{itemize}

Let's start with importing the variables' names from \emph{TFEQ.xlsx} (sheet \emph{Variables})

In a similar way, let's import the information related to the levels of each variable, stored in the \emph{Levels} sheet.
A deeper look at the \emph{Levels} sheet shows that only the coded names of the variables are available. In order to include the final names, \texttt{var\_names} is joined (using \texttt{inner\_join}).

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(tidyverse)}
\NormalTok{var\_labels }\OtherTok{\textless{}{-}} \FunctionTok{read\_xlsx}\NormalTok{(file\_path, }\AttributeTok{sheet=}\StringTok{"Levels"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{inner\_join}\NormalTok{(dplyr}\SpecialCharTok{::}\FunctionTok{select}\NormalTok{(var\_names, Code, Name), }\AttributeTok{by=}\FunctionTok{c}\NormalTok{(}\AttributeTok{Question=}\StringTok{"Code"}\NormalTok{))}

\NormalTok{var\_labels}
\end{Highlighting}
\end{Shaded}

\textbf{Note}: In some cases, this information is directly available in the dataset as sub-header: A solution is then to import the first rows of the dataset that contain this information using the parameter \texttt{n\_max} from `readxl::read\_xlsx``. For each variable (when information is available), store that information as a list of tables that contains the code and their corresponding label.

Finally, the dataset (\emph{Data}) is imported by substituting the coded names with their corresponding names.
This process can be done by skipping reading the first row of the dataset that contains the coded header (\texttt{skip=1}), and by passing \texttt{Var\_names} as header or column names (after ensuring that the names' sequence perfectly match across the two tables!).

The data has now the proper header, however each variable is still coded numerically. The steps to convert the numerical values with their corresponding labels is shown in Section \ref{data-prep}.

\hypertarget{data-prep}{%
\chapter{Data Preparation}\label{data-prep}}

The data we will be using in this chapter is the one that you imported in Section \ref{data-collection}.

\hypertarget{inspect-1}{%
\section{Inspect}\label{inspect-1}}

\hypertarget{data-inspection}{%
\subsection{Data Inspection}\label{data-inspection}}

To inspect the data, different steps can be used.
First, since \texttt{read\_xlsx()} returns a tibble, we can take advantage of its printing properties to get a fill of the data at hand,

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{TFEQ\_data}
\end{Highlighting}
\end{Shaded}

Other informative solutions consists in printing a summary of the data through the \texttt{summary()} function, or looking at its type and first values using \texttt{str()}. However, due to its richness of the outputs, we prefer to use the \texttt{skim()} function from the \texttt{\{skimr\}} package.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(skimr)}
\FunctionTok{skim}\NormalTok{(TFEQ\_data)}
\end{Highlighting}
\end{Shaded}

\hypertarget{design-inspection}{%
\subsection{Design Inspection}\label{design-inspection}}

Evaluate if the design is complete/incomplete
Frequencies and cross-frequencies (simple statistics and simple graphs)

\hypertarget{missing-data-inspection}{%
\subsection{Missing Data Inspection}\label{missing-data-inspection}}

Are there NAs?
If yes, are they structured of random?

\hypertarget{clean-1}{%
\section{Clean}\label{clean-1}}

\hypertarget{renaming-variables}{%
\subsection{Renaming Variables}\label{renaming-variables}}

renaming columns using \texttt{rename()} or \texttt{select()}

\hypertarget{handling-data-type}{%
\subsection{Handling Data Type}\label{handling-data-type}}

In R, the variables can be of different types, going from numerical to nominal to binary etc. This section aims in presenting the most common types (and their properties) used in sensory and consumer studies, and in showing how to transform a variable from one type to another.

Remember that when your dataset is a tibble (as is the case here), the type of each variable is provided as sub-header when printed on screen. This eases the work of the analyst as the variables' type can be assessed at any moment.

In case the dataset is not in a tibble, the use of the \texttt{str()} function used previously becomes handy as it provides this information.

In sensory and consumer research, the four most common types are:

\begin{itemize}
\tightlist
\item
  Numerical (incl.~integer or \texttt{int}, decimal or \texttt{dcl}, and double or \texttt{dbl});
\item
  Logical or \texttt{lgl};
\item
  Character or \texttt{char};
\item
  Factor or \texttt{fct}.
\end{itemize}

R still has plenty of other types, for more information please visit: \url{https://tibble.tidyverse.org/articles/types.html}

\hypertarget{numerical-data}{%
\subsubsection{Numerical Data}\label{numerical-data}}

Since a large proportion of the research done is quantitative, it is no surprise that our dataset are often dominated with numerical variables. In practice, numerical data includes integer (non-fractional number, e.g.~1, 2, -16, etc.), or decimal value (or double, e.g.~1.6, 2.333333, -3.2 etc.).
By default, when reading data from an external file, R converts any numerical variables to integer unless decimal points are detected, in which case it is converted into double.

\textbf{Do we want to show how to format R wrt the number of decimals? (e.g.~options(digits=2))}

\hypertarget{binary-data}{%
\subsubsection{Binary Data}\label{binary-data}}

Another common type that seem to be numerical in appearance, but that has additional properties is the binary type.
Binary data is data that takes two possible values (\texttt{TRUE} or \texttt{FALSE}), and are often the results of a \emph{test} (e.g.~is \texttt{x\textgreater{}3}? Or is \texttt{MyVar} numerical?). A typical example of binary data in sensory and consumer research is data collected through Check-All-That-Apply (CATA) questionnaires.

Note: Intrinsically, binary data is \emph{numerical}, TRUE being assimilated to 1, FALSE to 0. If multiple tests are being performed, it is possible to sum the number of tests that pass using the \texttt{sum()} function, as shown in the simple example below:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{123456}\NormalTok{)}
\CommentTok{\# Generating 10 random values between 1 and 10 using the uniform distribution}
\NormalTok{x }\OtherTok{\textless{}{-}} \FunctionTok{runif}\NormalTok{(}\DecValTok{10}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{10}\NormalTok{)}
\NormalTok{x}

\CommentTok{\# Test whether the values generated are strictly larger than 5}
\NormalTok{test }\OtherTok{\textless{}{-}}\NormalTok{ x}\SpecialCharTok{\textgreater{}}\DecValTok{5}
\NormalTok{test}

\CommentTok{\# Counting the number of values strictly larger than 5}
\FunctionTok{sum}\NormalTok{(test)}
\end{Highlighting}
\end{Shaded}

\hypertarget{nominal-data}{%
\subsubsection{Nominal Data}\label{nominal-data}}

Nominal data is any data that is not numerical. In most cases, nominal data are defined through text, or strings. It can appear in some situations that nominal variables are still defined with numbers although they do not have a numerical meaning. This is for instance the case when the respondents or samples are identified through numerical codes: In that case, it is clear that respondent 2 is not twice larger than respondent 1 for instance. But since the software cannot guess that those numbers are \emph{identifiers} rather than \emph{numbers}, the variables should be declared as nominal. The procedure explaining how to convert the type of the variables will be explained in the next section.

For nominal data, two particular types of data are of interest:

\begin{itemize}
\tightlist
\item
  Character or \texttt{char};
\item
  Factor or \texttt{fct}.
\end{itemize}

Variables defined as character or factor take strings as input. However, these two types differ in terms of structure of their levels:

\begin{itemize}
\tightlist
\item
  For \texttt{character}, there are no particular structure, and the variables can take any values (e.g.~open-ended question);
\item
  For \texttt{factor}, the inputs of the variables are structured into \texttt{levels}.
\end{itemize}

To evaluate the number of levels, different procedure are required:

\begin{itemize}
\tightlist
\item
  For \texttt{character}, one should count the number of unique element using \texttt{length()} and \texttt{unique()};
\item
  For \texttt{factor}, the levels and the number of levels are direcly provided by \texttt{levels()} and \texttt{nlevels()}.
\end{itemize}

Let's compare a variable set as \texttt{factor} and \texttt{character} by using the \texttt{Judge} column from \texttt{TFEQ\_data}:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{example }\OtherTok{\textless{}{-}}\NormalTok{ TFEQ\_data }\SpecialCharTok{\%\textgreater{}\%} 
\NormalTok{  dplyr}\SpecialCharTok{::}\FunctionTok{select}\NormalTok{(Judge) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{Judge\_fct =} \FunctionTok{as.factor}\NormalTok{(Judge))}
\FunctionTok{summary}\NormalTok{(example)}

\FunctionTok{unique}\NormalTok{(example}\SpecialCharTok{$}\NormalTok{Judge)}
\FunctionTok{length}\NormalTok{(}\FunctionTok{unique}\NormalTok{(example}\SpecialCharTok{$}\NormalTok{Judge))}

\FunctionTok{levels}\NormalTok{(example}\SpecialCharTok{$}\NormalTok{Judge\_fct)}
\FunctionTok{nlevels}\NormalTok{(example}\SpecialCharTok{$}\NormalTok{Judge\_fct)}
\end{Highlighting}
\end{Shaded}

Although \texttt{Judge} and \texttt{Judge\_fct} look the same, they are structurally different, and those differences play an important role that one should consider when running certain analyses, or building tables and graphs.

When set as \texttt{character}, the number of levels of a variable is directly read from the data, and its levels' order would either match the way they appear in the data, or are ordered alphabetically. This means that any data collected using a structured scale will lose its natural order.

When set as \texttt{factor}, the number and order of the factor levels are informed, and does not depend on the data itself: If a level has never been selected, or if certain groups have been filtered, this information is still present in the data.

To illustrate this, let's re-arrange the levels from \texttt{Judge\_fct} by ordering them numerically in such a way \texttt{J2} follows \texttt{J1} rather than \texttt{J10}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{judge }\OtherTok{\textless{}{-}} \FunctionTok{str\_sort}\NormalTok{(}\FunctionTok{levels}\NormalTok{(example}\SpecialCharTok{$}\NormalTok{Judge\_fct),}\AttributeTok{numeric=}\ConstantTok{TRUE}\NormalTok{)}
\NormalTok{judge}
\FunctionTok{levels}\NormalTok{(example}\SpecialCharTok{$}\NormalTok{Judge\_fct) }\OtherTok{\textless{}{-}}\NormalTok{ judge}
\end{Highlighting}
\end{Shaded}

Now the levels are sorted, let's `remove' some respondents by only keeping the 20 first ones (J1 to J20, as J18 does not exist), and re-run the previous code:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{example }\OtherTok{\textless{}{-}}\NormalTok{ TFEQ\_data }\SpecialCharTok{\%\textgreater{}\%} 
\NormalTok{  dplyr}\SpecialCharTok{::}\FunctionTok{select}\NormalTok{(Judge) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{Judge\_fct =} \FunctionTok{as.factor}\NormalTok{(Judge)) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{filter}\NormalTok{(Judge }\SpecialCharTok{\%in\%} \FunctionTok{paste0}\NormalTok{(}\StringTok{"J"}\NormalTok{,}\DecValTok{1}\SpecialCharTok{:}\DecValTok{20}\NormalTok{))}
\FunctionTok{dim}\NormalTok{(example)}

\FunctionTok{unique}\NormalTok{(example}\SpecialCharTok{$}\NormalTok{Judge)}
\FunctionTok{length}\NormalTok{(}\FunctionTok{unique}\NormalTok{(example}\SpecialCharTok{$}\NormalTok{Judge))}

\FunctionTok{levels}\NormalTok{(example}\SpecialCharTok{$}\NormalTok{Judge\_fct)}
\FunctionTok{nlevels}\NormalTok{(example}\SpecialCharTok{$}\NormalTok{Judge\_fct)}
\end{Highlighting}
\end{Shaded}

After filtering some respondents, it can be noticed that the variable set as character only contains 19 elements, whereas the column set as factor still contains the 107 respondents (most of them not having any recordings). This property can be seen as an advantage or a disadvantage depending on the situation:

\begin{itemize}
\tightlist
\item
  For frequencies, it may be relevant to remember all the options, including the ones that may never be selected, and to order the results logically (use of \texttt{factor}).
\item
  For hypothesis testing (e.g.~ANOVA) on subset of data (e.g.~the data being split by gender), the \texttt{Judge} variable set as \texttt{character} would have the correct number of degrees of freedom (18 in our example) whereas the variable set as factor would use 106 degrees of freedom in all cases!
\end{itemize}

The latter point is particularly critical since the analysis is incorrect and will either return an error or worse return erroneous results!

Last but not least, variables defined as factor allow having their levels being renamed (and eventually combined) very easily.
Let's consider the \texttt{Living\ area} variable from \texttt{TFEQ\_data} as example. From the original excel file, it can be seen that it has three levels, \texttt{1} corresponding to \emph{urban area}, \texttt{2} to \emph{rurban area}, and \texttt{3} to \emph{rural area}.
Let's start by renaming this variable accordingly:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{example }\OtherTok{=}\NormalTok{ TFEQ\_data }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{Area =} \FunctionTok{factor}\NormalTok{(}\StringTok{\textasciigrave{}}\AttributeTok{Living area}\StringTok{\textasciigrave{}}\NormalTok{, }\AttributeTok{levels=}\FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{,}\DecValTok{3}\NormalTok{), }\AttributeTok{labels=}\FunctionTok{c}\NormalTok{(}\StringTok{"Urban"}\NormalTok{, }\StringTok{"Rurban"}\NormalTok{, }\StringTok{"Rural"}\NormalTok{)))}

\FunctionTok{levels}\NormalTok{(example}\SpecialCharTok{$}\NormalTok{Area)}
\FunctionTok{nlevels}\NormalTok{(example}\SpecialCharTok{$}\NormalTok{Area)}

\FunctionTok{table}\NormalTok{(example}\SpecialCharTok{$}\StringTok{\textasciigrave{}}\AttributeTok{Living area}\StringTok{\textasciigrave{}}\NormalTok{, example}\SpecialCharTok{$}\NormalTok{Area)}
\end{Highlighting}
\end{Shaded}

As can be seen, the variable \texttt{Area} is the factor version (including its labels) of \texttt{Living\ area}.
If we would also consider that \texttt{Rurban} should be combined with \texttt{Rural}, and that \texttt{Rural} should appear before \texttt{Urban}, we can simply modify the code as such:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{example }\OtherTok{=}\NormalTok{ TFEQ\_data }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{Area =} \FunctionTok{factor}\NormalTok{(}\StringTok{\textasciigrave{}}\AttributeTok{Living area}\StringTok{\textasciigrave{}}\NormalTok{, }\AttributeTok{levels=}\FunctionTok{c}\NormalTok{(}\DecValTok{2}\NormalTok{,}\DecValTok{3}\NormalTok{,}\DecValTok{1}\NormalTok{), }\AttributeTok{labels=}\FunctionTok{c}\NormalTok{(}\StringTok{"Rural"}\NormalTok{, }\StringTok{"Rural"}\NormalTok{, }\StringTok{"Urban"}\NormalTok{)))}

\FunctionTok{levels}\NormalTok{(example}\SpecialCharTok{$}\NormalTok{Area)}
\FunctionTok{nlevels}\NormalTok{(example}\SpecialCharTok{$}\NormalTok{Area)}

\FunctionTok{table}\NormalTok{(example}\SpecialCharTok{$}\StringTok{\textasciigrave{}}\AttributeTok{Living area}\StringTok{\textasciigrave{}}\NormalTok{, example}\SpecialCharTok{$}\NormalTok{Area)}
\end{Highlighting}
\end{Shaded}

This approach of renaming and re-ordering factor levels is very important as it simplifies the readability of tables and figures.
Some other transformations can be applied to factors thanks to the \texttt{\{forcats\}} package. Particular attention can be given to the following functions:

\begin{itemize}
\tightlist
\item
  \texttt{fct\_reorder}/\texttt{fct\_reorder2} and \texttt{fct\_relevel} reorder the levels of a factor;
\item
  \texttt{fct\_recode} renames the factor levels (as an alternative to \texttt{factor} used in the previous example);
\item
  \texttt{fct\_collapse} and \texttt{fct\_lump} aggregate different levels together (\texttt{fct\_lump} regroups automatically all the rare levels).
\end{itemize}

Although it hasn't been done here, manipulating strings is also possible through the \texttt{\{stringr\}} package, which provides interesting functions such as:

\begin{itemize}
\tightlist
\item
  \texttt{str\_to\_upper}/\texttt{str\_to\_lower} to convert strings to uppercase or lowercase;
\item
  \texttt{str\_c}, \texttt{str\_sub} combine or subset strings;
\item
  \texttt{str\_trim} and \texttt{str\_squish} remove white spaces;
\item
  \texttt{str\_extract}, \texttt{str\_replace}, \texttt{str\_split} extract, replace, or split strings or part of the strings.
\end{itemize}

\hypertarget{converting-between-types}{%
\subsection{Converting between Types}\label{converting-between-types}}

When importing data, variables may not always be associated to the right type. For instance, when respondents or products are numerically coded, they will be defined as integers rather than strings. Additionally, each variable type has its own property. To take full advantage of the different variable types, and to avoid wrong analyses (e.g considering a variable that is numerically coded as numeric when it is not), we need to convert them to other types.

In the following sections, we will \texttt{mutate()} a variable to create a new variable that corresponds to the original one after being converted to its new type (as in the previous example with \texttt{Area}). In case we want to overwrite a variable by only changing the type, the same name is used within \texttt{mutate()}.

Based on our variable types of interest, there are two main conversions to run:
- From numerical to character/factor;
- From character/factor to numerical.

The conversion from numerical to character or factor is simply done using \texttt{as.character()} and \texttt{as.factor()} respectively. Note however that \texttt{as.factor()} only converts into factors without allowing to chose the order of the levels, nor to rename them. Alternatively, the use of \texttt{factor()} allows specifying the \texttt{levels} (and hence the order of the levels) and their corresponding \texttt{labels}. An example in the use of \texttt{as.character()} and \texttt{as.factor()} was provided in the previous section when we converted the \texttt{Respondent} variables to character and factor. The use of \texttt{factor()} was also used earlier when the variable \texttt{Living\ area} was converted from numerical to factor (called \texttt{Area}) with labels.

To illustrate the following points, let's start with creating a tibble with two variables, one containing strings made of numbers, and one containing strings made of text.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{example }\OtherTok{\textless{}{-}} \FunctionTok{tibble}\NormalTok{(}\AttributeTok{Numbers =} \FunctionTok{c}\NormalTok{(}\StringTok{"2"}\NormalTok{,}\StringTok{"4"}\NormalTok{,}\StringTok{"9"}\NormalTok{,}\StringTok{"6"}\NormalTok{,}\StringTok{"8"}\NormalTok{,}\StringTok{"12"}\NormalTok{,}\StringTok{"10"}\NormalTok{),}
                  \AttributeTok{Text =} \FunctionTok{c}\NormalTok{(}\StringTok{"Data"}\NormalTok{,}\StringTok{"Science"}\NormalTok{,}\StringTok{"4"}\NormalTok{,}\StringTok{"Sensory"}\NormalTok{,}\StringTok{"and"}\NormalTok{,}\StringTok{"Consumer"}\NormalTok{,}\StringTok{"Research"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

The conversion from character to numerical is straight forward and requires the use of the function \texttt{as.numeric()}:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{example }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{NumbersN =} \FunctionTok{as.numeric}\NormalTok{(Numbers), }\AttributeTok{TextN =} \FunctionTok{as.numeric}\NormalTok{(Text))}
\end{Highlighting}
\end{Shaded}

As can be seen, when strings are made of numbers, the conversion works fine. However, the text are not converted properly and returns NAs.

Now let's apply the same principle to a variable of the type factor. To do so, we will take the same example but first convert the variables from character to factor:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{example }\OtherTok{\textless{}{-}}\NormalTok{ example }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{Numbers =} \FunctionTok{as.factor}\NormalTok{(Numbers)) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{Text =} \FunctionTok{factor}\NormalTok{(Text, }\AttributeTok{levels=}\FunctionTok{c}\NormalTok{(}\StringTok{"Data"}\NormalTok{,}\StringTok{"Science"}\NormalTok{,}\StringTok{"4"}\NormalTok{,}\StringTok{"Sensory"}\NormalTok{,}\StringTok{"and"}\NormalTok{,}\StringTok{"Consumer"}\NormalTok{,}\StringTok{"Research"}\NormalTok{)))}
\end{Highlighting}
\end{Shaded}

Let's apply as.numeric() to these variables:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{example }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{NumbersN =} \FunctionTok{as.numeric}\NormalTok{(Numbers), }\AttributeTok{TextN =} \FunctionTok{as.numeric}\NormalTok{(Text))}
\end{Highlighting}
\end{Shaded}

We can notice here that the outcome is not really as expected as the numbers 2-4-9-6-8-12-10 becomes 3-4-7-5-6-2-1, and Data-Science-4-Sensory-and-Consumer-Research becomes 1-2-3-4-5-6-7. The rationale behind this conversion is that the numbers do not reflects the string itself, but the position of that level within the factor level structure.

To convert properly numerical factor levels to number, the variable should first be converted as character:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{example }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{Numbers =} \FunctionTok{as.numeric}\NormalTok{(}\FunctionTok{as.character}\NormalTok{(Numbers)))}
\end{Highlighting}
\end{Shaded}

\hypertarget{conditional-renaming}{%
\subsubsection{Conditional Renaming?}\label{conditional-renaming}}

\texttt{mutate()} and \texttt{ifelse()}

\hypertarget{handling-missing-values}{%
\subsection{Handling Missing Values}\label{handling-missing-values}}

Ignoring, removing, imputing

\hypertarget{restructuring-data}{%
\subsection{Restructuring Data}\label{restructuring-data}}

Presentation of the different shapes of the tables based on objectives

\hypertarget{variables-selection-and-repositioning}{%
\subsubsection{Variables Selection and Repositioning}\label{variables-selection-and-repositioning}}

\texttt{dplyr::select()} and \texttt{dplyr::arrange()}

\hypertarget{data-filtering}{%
\subsubsection{Data Filtering}\label{data-filtering}}

\texttt{dplyr::filter()}

\hypertarget{data-reshaping}{%
\subsubsection{Data (Re)Shaping}\label{data-reshaping}}

\texttt{pivot\_wider()} and \texttt{pivot\_longer()}
\texttt{\_join()}

\hypertarget{preparing-data-for-factominer-and-sensominer}{%
\subsubsection{Preparing Data for FactoMineR and SensoMineR}\label{preparing-data-for-factominer-and-sensominer}}

matrix, data frame, and tibble.

how to check the type? \texttt{class()}
how to test it? \texttt{is.data.frame()}, \texttt{is.matrix()}, \texttt{is\_tibble()}
how to convert it to another format? (see below)

Note on \texttt{\{FactoMineR\}} and \texttt{\{SensoMineR\}} which require data frames or matrix (not tibble) so introduction to \texttt{column\_to\_rownames()} and \texttt{rownames\_to\_columns()} as well as \texttt{as.data.frame()} and \texttt{as\_tibble()}.

\hypertarget{data-analysis}{%
\chapter{Data Analysis}\label{data-analysis}}

\hypertarget{transform-1}{%
\section{Transform}\label{transform-1}}

\hypertarget{explore-1}{%
\section{Explore}\label{explore-1}}

\hypertarget{model-1}{%
\section{Model}\label{model-1}}

\hypertarget{value-delivery}{%
\chapter{Value Delivery}\label{value-delivery}}

\hypertarget{communicate-1}{%
\section{Communicate}\label{communicate-1}}

\hypertarget{know-your-audience}{%
\subsection{Know Your Audience}\label{know-your-audience}}

\hypertarget{pick-the-correct-format}{%
\subsection{Pick the Correct Format}\label{pick-the-correct-format}}

\hypertarget{storytelling}{%
\subsection{Storytelling}\label{storytelling}}

\hypertarget{reformulate-1}{%
\section{Reformulate}\label{reformulate-1}}

\hypertarget{part-haute-cuisine}{%
\part*{Haute Cuisine}\label{part-haute-cuisine}}
\addcontentsline{toc}{part}{Haute Cuisine}

\hypertarget{machine_learning}{%
\chapter{Machine Learning}\label{machine_learning}}

\hypertarget{overview}{%
\section{Overview}\label{overview}}

\hypertarget{key-topics}{%
\section{Key Topics}\label{key-topics}}

\hypertarget{model-validation}{%
\subsection{Model Validation}\label{model-validation}}

\hypertarget{unsupervised-learning}{%
\subsection{Unsupervised learning}\label{unsupervised-learning}}

\hypertarget{cluster-analysis}{%
\subsubsection{Cluster analysis}\label{cluster-analysis}}

\hypertarget{factor-analysis}{%
\subsubsection{Factor analysis}\label{factor-analysis}}

\hypertarget{principle-components-analysis}{%
\subsubsection{Principle components analysis}\label{principle-components-analysis}}

\hypertarget{t-sne}{%
\subsubsection{t-SNE}\label{t-sne}}

\hypertarget{semisupervised-learning}{%
\subsection{Semisupervised learning}\label{semisupervised-learning}}

\hypertarget{pls-regression}{%
\subsubsection{PLS regression}\label{pls-regression}}

\hypertarget{cluster-characterization}{%
\subsubsection{Cluster Characterization}\label{cluster-characterization}}

\hypertarget{supervised-learning}{%
\subsection{Supervised learning}\label{supervised-learning}}

\hypertarget{regression}{%
\subsubsection{Regression}\label{regression}}

\hypertarget{k-nearest-neighbors}{%
\subsubsection{K-nearest neighbors}\label{k-nearest-neighbors}}

\hypertarget{decision-trees}{%
\subsubsection{Decision trees}\label{decision-trees}}

\hypertarget{black-boxes}{%
\subsubsection{Black boxes}\label{black-boxes}}

\hypertarget{random-forests}{%
\paragraph{Random forests}\label{random-forests}}

\hypertarget{svms}{%
\paragraph{SVMs}\label{svms}}

\hypertarget{neural-networks}{%
\paragraph{Neural networks}\label{neural-networks}}

\hypertarget{computer-vision}{%
\paragraph{Computer vision}\label{computer-vision}}

\hypertarget{interpretability}{%
\subsection{Interpretability}\label{interpretability}}

\hypertarget{lime}{%
\subsubsection{LIME}\label{lime}}

\hypertarget{dalex}{%
\subsubsection{DALEX}\label{dalex}}

\hypertarget{iml}{%
\subsubsection{IML}\label{iml}}

\hypertarget{common-applications}{%
\section{Common Applications}\label{common-applications}}

\hypertarget{predicting-sensory-profiles-from-instrumental-data}{%
\subsection{Predicting sensory profiles from instrumental data}\label{predicting-sensory-profiles-from-instrumental-data}}

\hypertarget{predicting-consumer-response-from-sensory-profiles}{%
\subsection{Predicting consumer response from sensory profiles}\label{predicting-consumer-response-from-sensory-profiles}}

\hypertarget{characterizing-consumer-clusters}{%
\subsection{Characterizing consumer clusters}\label{characterizing-consumer-clusters}}

\hypertarget{code-examples}{%
\section{Code Examples}\label{code-examples}}

\hypertarget{data-prep-1}{%
\subsection{Data Prep}\label{data-prep-1}}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{data }\OtherTok{\textless{}{-}}\NormalTok{ readr}\SpecialCharTok{::}\FunctionTok{read\_rds}\NormalTok{(}\StringTok{\textquotesingle{}data/masked\_data.rds\textquotesingle{}}\NormalTok{)}
\NormalTok{nrows }\OtherTok{\textless{}{-}} \FunctionTok{max}\NormalTok{(}\FunctionTok{summary}\NormalTok{(data}\SpecialCharTok{$}\NormalTok{Class)) }\SpecialCharTok{*} \DecValTok{2}

\NormalTok{data\_over }\OtherTok{\textless{}{-}}\NormalTok{ ROSE}\SpecialCharTok{::}\FunctionTok{ROSE}\NormalTok{(Class }\SpecialCharTok{\textasciitilde{}}\NormalTok{ .,}
                        \AttributeTok{data =}\NormalTok{ data }\SpecialCharTok{\%\textgreater{}\%} 
                          \FunctionTok{mutate}\NormalTok{(}\FunctionTok{across}\NormalTok{(}\FunctionTok{starts\_with}\NormalTok{(}\StringTok{\textquotesingle{}D\textquotesingle{}}\NormalTok{), factor, }\AttributeTok{levels =} \FunctionTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{))),}
                        \AttributeTok{N =}\NormalTok{ nrows, }\AttributeTok{seed =} \DecValTok{1}\NormalTok{)}\SpecialCharTok{$}\NormalTok{data}

\NormalTok{readr}\SpecialCharTok{::}\FunctionTok{write\_rds}\NormalTok{(data\_over, }\StringTok{\textquotesingle{}data/data\_classification.rds\textquotesingle{}}\NormalTok{)}

\NormalTok{readxl}\SpecialCharTok{::}\FunctionTok{read\_excel}\NormalTok{(}\StringTok{\textquotesingle{}data/data\_regression.xlsx\textquotesingle{}}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{select}\NormalTok{(}\SpecialCharTok{{-}}\StringTok{\textasciigrave{}}\AttributeTok{...1}\StringTok{\textasciigrave{}}\NormalTok{, }\SpecialCharTok{{-}}\NormalTok{judge, }\SpecialCharTok{{-}}\NormalTok{product, }\SpecialCharTok{{-}}\NormalTok{(steak}\SpecialCharTok{:}\NormalTok{V64), }\SpecialCharTok{{-}}\StringTok{\textasciigrave{}}\AttributeTok{qtt.drink.(\%)}\StringTok{\textasciigrave{}}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{rename}\NormalTok{(}\AttributeTok{socio\_professional =} \StringTok{\textasciigrave{}}\AttributeTok{socio{-}professional}\StringTok{\textasciigrave{}}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
\NormalTok{  readr}\SpecialCharTok{::}\FunctionTok{write\_rds}\NormalTok{(}\StringTok{\textquotesingle{}data/data\_regression.rds\textquotesingle{}}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\hypertarget{classification-code}{%
\subsection{Classification Code}\label{classification-code}}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(tidyverse)}
\FunctionTok{library}\NormalTok{(tidymodels)}


\CommentTok{\# Load data {-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}}

\NormalTok{data }\OtherTok{\textless{}{-}} \FunctionTok{read\_rds}\NormalTok{(}\StringTok{\textquotesingle{}data/data\_classification.rds\textquotesingle{}}\NormalTok{)}

\CommentTok{\# Inspect the data {-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}}

\FunctionTok{summary}\NormalTok{(data)}

\NormalTok{data }\OtherTok{\textless{}{-}}\NormalTok{ data }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{select}\NormalTok{(}\SpecialCharTok{{-}}\NormalTok{ID)}

\NormalTok{skimr}\SpecialCharTok{::}\FunctionTok{skim}\NormalTok{(data)}

\NormalTok{data }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}\FunctionTok{across}\NormalTok{(}\FunctionTok{starts\_with}\NormalTok{(}\StringTok{\textquotesingle{}D\textquotesingle{}}\NormalTok{), factor, }\AttributeTok{levels =} \FunctionTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{))) }\SpecialCharTok{\%\textgreater{}\%}
\NormalTok{  GGally}\SpecialCharTok{::}\FunctionTok{ggpairs}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{fill =}\NormalTok{ Class))}



\CommentTok{\# Split data for models {-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}}

\CommentTok{\# Set test set aside}
\NormalTok{train\_test\_split }\OtherTok{\textless{}{-}} \FunctionTok{initial\_split}\NormalTok{(data)}
\NormalTok{train\_test\_split}

\NormalTok{train\_set }\OtherTok{\textless{}{-}} \FunctionTok{training}\NormalTok{(train\_test\_split)}
\NormalTok{test\_set }\OtherTok{\textless{}{-}} \FunctionTok{testing}\NormalTok{(train\_test\_split)}

\CommentTok{\# Split set fot cross{-}validation}
\NormalTok{resampling }\OtherTok{\textless{}{-}} \FunctionTok{vfold\_cv}\NormalTok{(train\_set, }\DecValTok{10}\NormalTok{)}
\NormalTok{resampling}


\CommentTok{\# Fit MARS model {-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}}

\NormalTok{usemodels}\SpecialCharTok{::}\FunctionTok{use\_earth}\NormalTok{(}
\NormalTok{  Class }\SpecialCharTok{\textasciitilde{}}\NormalTok{ .,}
  \AttributeTok{data =}\NormalTok{ train\_set}
\NormalTok{  )}

\NormalTok{earth\_recipe }\OtherTok{\textless{}{-}} 
  \FunctionTok{recipe}\NormalTok{(}\AttributeTok{formula =}\NormalTok{ Class }\SpecialCharTok{\textasciitilde{}}\NormalTok{ ., }\AttributeTok{data =}\NormalTok{ train\_set) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{step\_novel}\NormalTok{(}\FunctionTok{all\_nominal}\NormalTok{(), }\SpecialCharTok{{-}}\FunctionTok{all\_outcomes}\NormalTok{()) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{step\_dummy}\NormalTok{(}\FunctionTok{all\_nominal}\NormalTok{(), }\SpecialCharTok{{-}}\FunctionTok{all\_outcomes}\NormalTok{()) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{step\_zv}\NormalTok{(}\FunctionTok{all\_predictors}\NormalTok{()) }

\NormalTok{earth\_spec }\OtherTok{\textless{}{-}} 
  \FunctionTok{mars}\NormalTok{(}
    \AttributeTok{num\_terms =} \FunctionTok{tune}\NormalTok{(),}
    \AttributeTok{prod\_degree =} \FunctionTok{tune}\NormalTok{(),}
    \AttributeTok{prune\_method =} \StringTok{"none"}
\NormalTok{    ) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{set\_mode}\NormalTok{(}\StringTok{"classification"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{set\_engine}\NormalTok{(}\StringTok{"earth"}\NormalTok{) }

\NormalTok{earth\_workflow }\OtherTok{\textless{}{-}} 
  \FunctionTok{workflow}\NormalTok{() }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{add\_recipe}\NormalTok{(earth\_recipe) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{add\_model}\NormalTok{(earth\_spec) }

\NormalTok{earth\_grid }\OtherTok{\textless{}{-}}\NormalTok{ tidyr}\SpecialCharTok{::}\FunctionTok{crossing}\NormalTok{(}\AttributeTok{num\_terms =} \DecValTok{2} \SpecialCharTok{*}\NormalTok{ (}\DecValTok{1}\SpecialCharTok{:}\DecValTok{6}\NormalTok{), }\AttributeTok{prod\_degree =} \DecValTok{1}\SpecialCharTok{:}\DecValTok{2}\NormalTok{) }
\NormalTok{earth\_grid}

\NormalTok{earth\_tune }\OtherTok{\textless{}{-}} 
  \FunctionTok{tune\_grid}\NormalTok{(}
\NormalTok{    earth\_workflow, }
    \AttributeTok{resamples =}\NormalTok{ resampling, }
    \CommentTok{\# Save predictions for further steps}
    \AttributeTok{control =} \FunctionTok{control\_grid}\NormalTok{(}\AttributeTok{save\_pred =} \ConstantTok{TRUE}\NormalTok{, }\AttributeTok{verbose =} \ConstantTok{TRUE}\NormalTok{),}
    \CommentTok{\# Test parameters on a grid defined above}
    \AttributeTok{grid =}\NormalTok{ earth\_grid}
\NormalTok{  ) }


\CommentTok{\# Check model performance {-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}}

\NormalTok{earth\_tune }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{show\_best}\NormalTok{(}\AttributeTok{n =} \DecValTok{10}\NormalTok{)}
\NormalTok{earth\_tune }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{autoplot}\NormalTok{()}

\NormalTok{earth\_predictions }\OtherTok{\textless{}{-}}\NormalTok{ earth\_tune }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{collect\_predictions}\NormalTok{(}\AttributeTok{parameters =} \FunctionTok{select\_best}\NormalTok{(., }\StringTok{\textquotesingle{}roc\_auc\textquotesingle{}}\NormalTok{)) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{model =} \StringTok{"MARS"}\NormalTok{)}

\NormalTok{earth\_predictions }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{roc\_curve}\NormalTok{(Class, .pred\_A) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{autoplot}\NormalTok{()}

\NormalTok{earth\_predictions }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{lift\_curve}\NormalTok{(Class, .pred\_A) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{autoplot}\NormalTok{()}

\NormalTok{earth\_predictions }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{pr\_curve}\NormalTok{(Class, .pred\_A) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{autoplot}\NormalTok{()}

\NormalTok{earth\_predictions }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{conf\_mat}\NormalTok{(Class, .pred\_class) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{autoplot}\NormalTok{()}


\CommentTok{\# Fit decision tree {-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}}

\NormalTok{tree\_recipe }\OtherTok{\textless{}{-}} 
  \FunctionTok{recipe}\NormalTok{(}\AttributeTok{formula =}\NormalTok{ Class }\SpecialCharTok{\textasciitilde{}}\NormalTok{ ., }\AttributeTok{data =}\NormalTok{ train\_set) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{step\_novel}\NormalTok{(}\FunctionTok{all\_nominal}\NormalTok{(), }\SpecialCharTok{{-}}\FunctionTok{all\_outcomes}\NormalTok{()) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{step\_zv}\NormalTok{(}\FunctionTok{all\_predictors}\NormalTok{()) }

\NormalTok{tree\_spec }\OtherTok{\textless{}{-}} 
  \FunctionTok{decision\_tree}\NormalTok{(}
    \AttributeTok{cost\_complexity =} \FunctionTok{tune}\NormalTok{(),}
    \AttributeTok{tree\_depth =} \FunctionTok{tune}\NormalTok{(),}
    \AttributeTok{min\_n =} \FunctionTok{tune}\NormalTok{()}
\NormalTok{    ) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{set\_mode}\NormalTok{(}\StringTok{"classification"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{set\_engine}\NormalTok{(}\StringTok{"rpart"}\NormalTok{) }

\NormalTok{tree\_workflow }\OtherTok{\textless{}{-}} 
  \FunctionTok{workflow}\NormalTok{() }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{add\_recipe}\NormalTok{(tree\_recipe) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{add\_model}\NormalTok{(tree\_spec) }

\NormalTok{tree\_tune }\OtherTok{\textless{}{-}} 
  \FunctionTok{tune\_grid}\NormalTok{(}
\NormalTok{    tree\_workflow, }
    \AttributeTok{resamples =}\NormalTok{ resampling, }
    \CommentTok{\# Save predictions for further steps}
    \AttributeTok{control =} \FunctionTok{control\_grid}\NormalTok{(}\AttributeTok{save\_pred =} \ConstantTok{TRUE}\NormalTok{, }\AttributeTok{verbose =} \ConstantTok{TRUE}\NormalTok{),}
    \CommentTok{\# Test 20 random combinations of parameters}
    \AttributeTok{grid =} \DecValTok{20}
\NormalTok{  ) }

\CommentTok{\# Check model performance {-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}}

\NormalTok{tree\_tune }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{show\_best}\NormalTok{(}\AttributeTok{n =} \DecValTok{10}\NormalTok{)}
\NormalTok{tree\_tune }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{autoplot}\NormalTok{()}

\NormalTok{tree\_predictions }\OtherTok{\textless{}{-}}\NormalTok{ tree\_tune }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{collect\_predictions}\NormalTok{(}\AttributeTok{parameters =} \FunctionTok{select\_best}\NormalTok{(., }\StringTok{\textquotesingle{}roc\_auc\textquotesingle{}}\NormalTok{)) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{model =} \StringTok{"Decision Tree"}\NormalTok{)}

\NormalTok{tree\_predictions }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{bind\_rows}\NormalTok{(earth\_predictions) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{group\_by}\NormalTok{(model) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{roc\_curve}\NormalTok{(Class, .pred\_A) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{autoplot}\NormalTok{()}

\NormalTok{tree\_predictions }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{bind\_rows}\NormalTok{(earth\_predictions) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{group\_by}\NormalTok{(model) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{lift\_curve}\NormalTok{(Class, .pred\_A) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{autoplot}\NormalTok{()}

\NormalTok{tree\_predictions }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{bind\_rows}\NormalTok{(earth\_predictions) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{group\_by}\NormalTok{(model) }\SpecialCharTok{\%\textgreater{}\%}  \FunctionTok{pr\_curve}\NormalTok{(Class, .pred\_A) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{autoplot}\NormalTok{()}

\NormalTok{tree\_predictions }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{conf\_mat}\NormalTok{(Class, .pred\_class) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{autoplot}\NormalTok{()}


\CommentTok{\# Let\textquotesingle{}s go with MARS model {-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}}

\NormalTok{final\_fit }\OtherTok{\textless{}{-}}\NormalTok{ earth\_workflow }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{finalize\_workflow}\NormalTok{(}\FunctionTok{select\_best}\NormalTok{(earth\_tune, }\StringTok{\textquotesingle{}roc\_auc\textquotesingle{}}\NormalTok{)) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{last\_fit}\NormalTok{(train\_test\_split)}

\NormalTok{final\_fit }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{collect\_metrics}\NormalTok{()}

\NormalTok{final\_fit }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{collect\_predictions}\NormalTok{() }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{roc\_curve}\NormalTok{(Class, .pred\_A) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{autoplot}\NormalTok{()}

\NormalTok{final\_model }\OtherTok{\textless{}{-}}\NormalTok{ final\_fit }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{pluck}\NormalTok{(}\StringTok{".workflow"}\NormalTok{, }\DecValTok{1}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{fit}\NormalTok{(data)}

\NormalTok{final\_model }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{pull\_workflow\_fit}\NormalTok{() }\SpecialCharTok{\%\textgreater{}\%} 
\NormalTok{  vip}\SpecialCharTok{::}\FunctionTok{vip}\NormalTok{()}

\NormalTok{final\_model }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{pull\_workflow\_fit}\NormalTok{() }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{pluck}\NormalTok{(}\StringTok{"fit"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
\NormalTok{  summary}

\FunctionTok{write\_rds}\NormalTok{(final\_model, }\StringTok{\textquotesingle{}classification\_model.rds\textquotesingle{}}\NormalTok{)}


\CommentTok{\# Predict something {-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}}

\NormalTok{model }\OtherTok{\textless{}{-}} \FunctionTok{read\_rds}\NormalTok{(}\StringTok{\textquotesingle{}classification\_model.rds\textquotesingle{}}\NormalTok{)}

\NormalTok{new\_observation }\OtherTok{\textless{}{-}} \FunctionTok{tibble}\NormalTok{(}
  \AttributeTok{N1 =} \FloatTok{1.8}\NormalTok{,}
  \AttributeTok{D1 =} \FunctionTok{factor}\NormalTok{(}\DecValTok{0}\NormalTok{),}
  \AttributeTok{D2 =} \FunctionTok{factor}\NormalTok{(}\DecValTok{0}\NormalTok{),}
  \AttributeTok{D3 =} \FunctionTok{factor}\NormalTok{(}\DecValTok{1}\NormalTok{),}
  \AttributeTok{D4 =} \FunctionTok{factor}\NormalTok{(}\DecValTok{0}\NormalTok{),}
  \AttributeTok{D5 =} \FunctionTok{factor}\NormalTok{(}\DecValTok{1}\NormalTok{),}
  \AttributeTok{D6 =} \FunctionTok{factor}\NormalTok{(}\DecValTok{0}\NormalTok{),}
  \AttributeTok{D7 =} \FunctionTok{factor}\NormalTok{(}\DecValTok{1}\NormalTok{),}
  \AttributeTok{D8 =} \FunctionTok{factor}\NormalTok{(}\DecValTok{1}\NormalTok{),}
  \AttributeTok{D9 =} \FunctionTok{factor}\NormalTok{(}\DecValTok{1}\NormalTok{),}
  \AttributeTok{D10 =} \FunctionTok{factor}\NormalTok{(}\DecValTok{1}\NormalTok{),}
  \AttributeTok{D11 =} \FunctionTok{factor}\NormalTok{(}\DecValTok{0}\NormalTok{)}
\NormalTok{)}

\FunctionTok{predict}\NormalTok{(model, new\_observation, }\AttributeTok{type =} \StringTok{"class"}\NormalTok{)}
\FunctionTok{predict}\NormalTok{(model, new\_observation, }\AttributeTok{type =} \StringTok{"prob"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\hypertarget{regression-code}{%
\subsection{Regression Code}\label{regression-code}}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(tidyverse)}
\FunctionTok{library}\NormalTok{(tidymodels)}


\CommentTok{\# Load data {-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}}

\NormalTok{data }\OtherTok{\textless{}{-}} \FunctionTok{read\_rds}\NormalTok{(}\StringTok{\textquotesingle{}data/data\_regression.rds\textquotesingle{}}\NormalTok{)}
\FunctionTok{glimpse}\NormalTok{(data)}

\CommentTok{\# Inspect the data {-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}}

\FunctionTok{summary}\NormalTok{(data)}

\NormalTok{skimr}\SpecialCharTok{::}\FunctionTok{skim}\NormalTok{(data)}

\CommentTok{\# Split data for models {-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}}

\CommentTok{\# Set test set aside}
\NormalTok{train\_test\_split }\OtherTok{\textless{}{-}} \FunctionTok{initial\_split}\NormalTok{(data)}
\NormalTok{train\_test\_split}

\NormalTok{train\_set }\OtherTok{\textless{}{-}} \FunctionTok{training}\NormalTok{(train\_test\_split)}
\NormalTok{test\_set }\OtherTok{\textless{}{-}} \FunctionTok{testing}\NormalTok{(train\_test\_split)}

\CommentTok{\# Split set fot cross{-}validation}
\NormalTok{resampling }\OtherTok{\textless{}{-}} \FunctionTok{vfold\_cv}\NormalTok{(train\_set, }\DecValTok{10}\NormalTok{)}
\NormalTok{resampling}


\CommentTok{\# Fit glmnet model {-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}}

\NormalTok{usemodels}\SpecialCharTok{::}\FunctionTok{use\_glmnet}\NormalTok{(}
\NormalTok{  Liking }\SpecialCharTok{\textasciitilde{}}\NormalTok{ .,}
  \AttributeTok{data =}\NormalTok{ train\_set}
\NormalTok{)}

\NormalTok{glmnet\_recipe }\OtherTok{\textless{}{-}} 
  \FunctionTok{recipe}\NormalTok{(}\AttributeTok{formula =}\NormalTok{ Liking }\SpecialCharTok{\textasciitilde{}}\NormalTok{ ., }\AttributeTok{data =}\NormalTok{ train\_set) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{step\_novel}\NormalTok{(}\FunctionTok{all\_nominal}\NormalTok{(), }\SpecialCharTok{{-}}\FunctionTok{all\_outcomes}\NormalTok{()) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{step\_dummy}\NormalTok{(}\FunctionTok{all\_nominal}\NormalTok{(), }\SpecialCharTok{{-}}\FunctionTok{all\_outcomes}\NormalTok{()) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{step\_zv}\NormalTok{(}\FunctionTok{all\_predictors}\NormalTok{()) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{step\_normalize}\NormalTok{(}\FunctionTok{all\_predictors}\NormalTok{(), }\SpecialCharTok{{-}}\FunctionTok{all\_nominal}\NormalTok{())}

\NormalTok{glmnet\_spec }\OtherTok{\textless{}{-}} 
  \FunctionTok{linear\_reg}\NormalTok{(}\AttributeTok{penalty =} \FunctionTok{tune}\NormalTok{(), }\AttributeTok{mixture =} \FunctionTok{tune}\NormalTok{()) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{set\_mode}\NormalTok{(}\StringTok{"regression"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{set\_engine}\NormalTok{(}\StringTok{"glmnet"}\NormalTok{) }

\NormalTok{glmnet\_workflow }\OtherTok{\textless{}{-}} 
  \FunctionTok{workflow}\NormalTok{() }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{add\_recipe}\NormalTok{(glmnet\_recipe) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{add\_model}\NormalTok{(glmnet\_spec) }

\NormalTok{glmnet\_grid }\OtherTok{\textless{}{-}}\NormalTok{ tidyr}\SpecialCharTok{::}\FunctionTok{crossing}\NormalTok{(}\AttributeTok{penalty =} \DecValTok{10}\SpecialCharTok{\^{}}\FunctionTok{seq}\NormalTok{(}\SpecialCharTok{{-}}\DecValTok{6}\NormalTok{, }\SpecialCharTok{{-}}\DecValTok{1}\NormalTok{, }\AttributeTok{length.out =} \DecValTok{20}\NormalTok{), }
                               \AttributeTok{mixture =} \FunctionTok{c}\NormalTok{(}\FloatTok{0.05}\NormalTok{, }\FloatTok{0.2}\NormalTok{, }\FloatTok{0.4}\NormalTok{, }\FloatTok{0.6}\NormalTok{, }\FloatTok{0.8}\NormalTok{, }\DecValTok{1}\NormalTok{)) }

\NormalTok{glmnet\_tune }\OtherTok{\textless{}{-}} 
  \FunctionTok{tune\_grid}\NormalTok{(}
\NormalTok{    glmnet\_workflow, }
    \AttributeTok{resamples =}\NormalTok{ resampling, }
    \CommentTok{\# Save predictions for further steps}
    \AttributeTok{control =} \FunctionTok{control\_grid}\NormalTok{(}\AttributeTok{save\_pred =} \ConstantTok{TRUE}\NormalTok{, }\AttributeTok{verbose =} \ConstantTok{TRUE}\NormalTok{),}
    \CommentTok{\# Test parameters on a grid defined above}
    \AttributeTok{grid =}\NormalTok{ glmnet\_grid}
\NormalTok{    ) }

\CommentTok{\# Check model performance {-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}}

\NormalTok{glmnet\_tune }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{show\_best}\NormalTok{(}\AttributeTok{n =} \DecValTok{10}\NormalTok{)}
\NormalTok{glmnet\_tune }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{autoplot}\NormalTok{()}

\NormalTok{glmnet\_predictions }\OtherTok{\textless{}{-}}\NormalTok{ glmnet\_tune }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{collect\_predictions}\NormalTok{(}\AttributeTok{parameters =} \FunctionTok{select\_best}\NormalTok{(., }\StringTok{\textquotesingle{}rmse\textquotesingle{}}\NormalTok{)) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{model =} \StringTok{"GLMNet"}\NormalTok{,}
         \AttributeTok{.resid =}\NormalTok{ Liking }\SpecialCharTok{{-}}\NormalTok{ .pred)}

\NormalTok{glmnet\_predictions }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{sample =}\NormalTok{ .resid)) }\SpecialCharTok{+}
  \FunctionTok{geom\_qq}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{geom\_qq\_line}\NormalTok{()}

\NormalTok{glmnet\_predictions }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(.pred, Liking)) }\SpecialCharTok{+}
  \FunctionTok{geom\_point}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{geom\_abline}\NormalTok{(}\AttributeTok{slope =} \DecValTok{1}\NormalTok{, }\AttributeTok{intercept =} \DecValTok{0}\NormalTok{)}

\NormalTok{glmnet\_predictions }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(.pred, .resid)) }\SpecialCharTok{+}
  \FunctionTok{geom\_point}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{geom\_hline}\NormalTok{(}\AttributeTok{yintercept =} \DecValTok{0}\NormalTok{)}

\FunctionTok{ggplot}\NormalTok{(glmnet\_predictions, }\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ .resid)) }\SpecialCharTok{+} 
  \FunctionTok{geom\_histogram}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{y =}\NormalTok{..density..), }\AttributeTok{fill =} \StringTok{\textquotesingle{}white\textquotesingle{}}\NormalTok{, }\AttributeTok{color =} \StringTok{\textquotesingle{}black\textquotesingle{}}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{stat\_function}\NormalTok{(}\AttributeTok{fun =}\NormalTok{ dnorm,}
                \AttributeTok{args =} \FunctionTok{list}\NormalTok{(}\AttributeTok{mean =} \FunctionTok{mean}\NormalTok{(glmnet\_predictions}\SpecialCharTok{$}\NormalTok{.resid), }
                            \AttributeTok{sd =} \FunctionTok{sd}\NormalTok{(glmnet\_predictions}\SpecialCharTok{$}\NormalTok{.resid)),}
                \AttributeTok{size =} \DecValTok{1}\NormalTok{)}

\CommentTok{\# Fit random forest {-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}}

\NormalTok{rf\_recipe }\OtherTok{\textless{}{-}} 
  \FunctionTok{recipe}\NormalTok{(}\AttributeTok{formula =}\NormalTok{ Liking }\SpecialCharTok{\textasciitilde{}}\NormalTok{ ., }\AttributeTok{data =}\NormalTok{ train\_set) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{step\_novel}\NormalTok{(}\FunctionTok{all\_nominal}\NormalTok{(), }\SpecialCharTok{{-}}\FunctionTok{all\_outcomes}\NormalTok{()) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{step\_zv}\NormalTok{(}\FunctionTok{all\_predictors}\NormalTok{()) }

\NormalTok{rf\_spec }\OtherTok{\textless{}{-}} 
  \FunctionTok{rand\_forest}\NormalTok{(}
    \AttributeTok{mtry =} \FunctionTok{tune}\NormalTok{(), }
    \AttributeTok{min\_n =} \FunctionTok{tune}\NormalTok{(),}
    \AttributeTok{trees =} \DecValTok{50}
\NormalTok{    ) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{set\_mode}\NormalTok{(}\StringTok{"regression"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{set\_engine}\NormalTok{(}\StringTok{"ranger"}\NormalTok{, }\AttributeTok{importance =} \StringTok{"impurity"}\NormalTok{) }

\NormalTok{rf\_workflow }\OtherTok{\textless{}{-}} 
  \FunctionTok{workflow}\NormalTok{() }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{add\_recipe}\NormalTok{(rf\_recipe) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{add\_model}\NormalTok{(rf\_spec) }

\NormalTok{rf\_tune }\OtherTok{\textless{}{-}} 
  \FunctionTok{tune\_grid}\NormalTok{(}
\NormalTok{    rf\_workflow, }
    \AttributeTok{resamples =}\NormalTok{ resampling, }
    \CommentTok{\# Save predictions for further steps}
    \AttributeTok{control =} \FunctionTok{control\_grid}\NormalTok{(}\AttributeTok{save\_pred =} \ConstantTok{TRUE}\NormalTok{, }\AttributeTok{verbose =} \ConstantTok{TRUE}\NormalTok{),}
    \CommentTok{\# Test 20 random combinations of parameters}
    \AttributeTok{grid =} \DecValTok{20}
\NormalTok{  ) }

\CommentTok{\# Check model performance {-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}}

\NormalTok{rf\_tune }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{show\_best}\NormalTok{(}\AttributeTok{n =} \DecValTok{10}\NormalTok{)}
\NormalTok{rf\_tune }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{autoplot}\NormalTok{()}

\NormalTok{rf\_predictions }\OtherTok{\textless{}{-}}\NormalTok{ rf\_tune }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{collect\_predictions}\NormalTok{(}\AttributeTok{parameters =} \FunctionTok{select\_best}\NormalTok{(., }\StringTok{\textquotesingle{}rmse\textquotesingle{}}\NormalTok{)) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{model =} \StringTok{"Random Forest"}\NormalTok{,}
         \AttributeTok{.resid =}\NormalTok{ Liking }\SpecialCharTok{{-}}\NormalTok{ .pred)}

\NormalTok{rf\_predictions }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{bind\_rows}\NormalTok{(glmnet\_predictions) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{sample =}\NormalTok{ .resid)) }\SpecialCharTok{+}
  \FunctionTok{geom\_qq}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{geom\_qq\_line}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{facet\_wrap}\NormalTok{(}\SpecialCharTok{\textasciitilde{}}\NormalTok{model)}

\NormalTok{rf\_predictions }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{bind\_rows}\NormalTok{(glmnet\_predictions) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(.pred, Liking)) }\SpecialCharTok{+}
  \FunctionTok{geom\_point}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{geom\_abline}\NormalTok{(}\AttributeTok{slope =} \DecValTok{1}\NormalTok{, }\AttributeTok{intercept =} \DecValTok{0}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{facet\_wrap}\NormalTok{(}\SpecialCharTok{\textasciitilde{}}\NormalTok{model)}

\NormalTok{rf\_predictions }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{bind\_rows}\NormalTok{(glmnet\_predictions) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(.pred, .resid)) }\SpecialCharTok{+}
  \FunctionTok{geom\_point}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{geom\_hline}\NormalTok{(}\AttributeTok{yintercept =} \DecValTok{0}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{facet\_wrap}\NormalTok{(}\SpecialCharTok{\textasciitilde{}}\NormalTok{model)}

\NormalTok{rf\_predictions }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ .resid)) }\SpecialCharTok{+} 
  \FunctionTok{geom\_histogram}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{y =}\NormalTok{..density..), }\AttributeTok{fill =} \StringTok{\textquotesingle{}white\textquotesingle{}}\NormalTok{, }\AttributeTok{color =} \StringTok{\textquotesingle{}black\textquotesingle{}}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{stat\_function}\NormalTok{(}\AttributeTok{fun =}\NormalTok{ dnorm,}
                \AttributeTok{args =} \FunctionTok{list}\NormalTok{(}\AttributeTok{mean =} \FunctionTok{mean}\NormalTok{(rf\_predictions}\SpecialCharTok{$}\NormalTok{.resid), }
                            \AttributeTok{sd =} \FunctionTok{sd}\NormalTok{(rf\_predictions}\SpecialCharTok{$}\NormalTok{.resid)),}
                \AttributeTok{size =} \DecValTok{1}\NormalTok{)}

\CommentTok{\# Let\textquotesingle{}s go with rf model {-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}}

\NormalTok{final\_fit }\OtherTok{\textless{}{-}}\NormalTok{ glmnet\_workflow }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{finalize\_workflow}\NormalTok{(}\FunctionTok{select\_best}\NormalTok{(glmnet\_tune, }\StringTok{\textquotesingle{}rmse\textquotesingle{}}\NormalTok{)) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{last\_fit}\NormalTok{(train\_test\_split)}

\NormalTok{final\_fit }\OtherTok{\textless{}{-}}\NormalTok{ rf\_workflow }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{finalize\_workflow}\NormalTok{(}\FunctionTok{select\_best}\NormalTok{(rf\_tune, }\StringTok{\textquotesingle{}rmse\textquotesingle{}}\NormalTok{)) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{last\_fit}\NormalTok{(train\_test\_split)}

\NormalTok{final\_fit }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{collect\_metrics}\NormalTok{()}

\NormalTok{final\_fit }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{collect\_predictions}\NormalTok{() }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{.resid =}\NormalTok{ Liking }\SpecialCharTok{{-}}\NormalTok{ .pred) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{sample =}\NormalTok{ .resid)) }\SpecialCharTok{+}
  \FunctionTok{geom\_qq}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{geom\_qq\_line}\NormalTok{()}

\NormalTok{final\_model }\OtherTok{\textless{}{-}}\NormalTok{  final\_fit }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{pluck}\NormalTok{(}\StringTok{".workflow"}\NormalTok{, }\DecValTok{1}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{fit}\NormalTok{(data)}

\NormalTok{final\_model }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{pull\_workflow\_fit}\NormalTok{() }\SpecialCharTok{\%\textgreater{}\%}
\NormalTok{  vip}\SpecialCharTok{::}\FunctionTok{vip}\NormalTok{()}

\CommentTok{\# final\_model \%\textgreater{}\%}
\CommentTok{\#   broom::tidy() \%\textgreater{}\%}
\CommentTok{\#   filter(estimate != 0)}

\FunctionTok{write\_rds}\NormalTok{(final\_model, }\StringTok{\textquotesingle{}regression\_model.rds\textquotesingle{}}\NormalTok{)}

\CommentTok{\# Predict something {-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}}

\NormalTok{model }\OtherTok{\textless{}{-}} \FunctionTok{read\_rds}\NormalTok{(}\StringTok{\textquotesingle{}regression\_model.rds\textquotesingle{}}\NormalTok{)}

\NormalTok{new\_observations }\OtherTok{\textless{}{-}}\NormalTok{ data[}\DecValTok{1}\SpecialCharTok{:}\DecValTok{2}\NormalTok{,]}
\NormalTok{new\_observations}

\FunctionTok{predict}\NormalTok{(model, new\_observations)}
\end{Highlighting}
\end{Shaded}

\hypertarget{text-analysis}{%
\chapter{Text Analysis}\label{text-analysis}}

\hypertarget{overview-1}{%
\section{Overview}\label{overview-1}}

\hypertarget{key-topics-1}{%
\section{Key Topics}\label{key-topics-1}}

\hypertarget{data-sources}{%
\subsection{Data Sources}\label{data-sources}}

\hypertarget{working-with-strings}{%
\subsection{Working with Strings}\label{working-with-strings}}

\hypertarget{tokenizing}{%
\subsection{Tokenizing}\label{tokenizing}}

\hypertarget{lemmatization-stemming-and-stop-word-removal}{%
\subsection{Lemmatization, stemming, and stop word removal}\label{lemmatization-stemming-and-stop-word-removal}}

\hypertarget{part-of-speech-tagging}{%
\subsection{Part of Speech Tagging}\label{part-of-speech-tagging}}

\hypertarget{common-applications-1}{%
\section{Common Applications}\label{common-applications-1}}

\hypertarget{frequency-counts-and-summary-statistics}{%
\subsection{Frequency counts and summary statistics}\label{frequency-counts-and-summary-statistics}}

\hypertarget{word-clouds}{%
\subsection{Word clouds}\label{word-clouds}}

\hypertarget{contrast-plots}{%
\subsection{Contrast plots}\label{contrast-plots}}

\hypertarget{sentiment-analysis}{%
\subsection{Sentiment analysis}\label{sentiment-analysis}}

\hypertarget{topic-modeling}{%
\subsection{Topic Modeling}\label{topic-modeling}}

\hypertarget{bigrams-and-word-graphs}{%
\subsection{Bigrams and word graphs}\label{bigrams-and-word-graphs}}

\hypertarget{code-examples-1}{%
\section{Code Examples}\label{code-examples-1}}

Introduction to \textbf{\{tidytext\}} and \textbf{\{Xplortext\}}

\hypertarget{statistical-entities}{%
\subsection{Statistical entities}\label{statistical-entities}}

What are we considering as statistical entities?

\begin{itemize}
\tightlist
\item
  documents
\item
  sentences
\item
  words
\item
  cleaned words
\end{itemize}

Depends on objectives of study and how data are being collected:

\begin{itemize}
\tightlist
\item
  directly from consumers in a CLT (directed questions)
\item
  analysis of social media (e.g.~twitter)
\item
  web-scrapping from website
\end{itemize}

Discussion around CATA as a simplified version of text analysis\ldots{}

\hypertarget{notion-of-tokenization}{%
\subsubsection{Notion of tokenization}\label{notion-of-tokenization}}

\hypertarget{cleaning-the-data}{%
\subsubsection{Cleaning the data}\label{cleaning-the-data}}

Notions of lemmatization, stemming, and stopwords removal

\begin{itemize}
\tightlist
\item
  grouping words
\item
  removing stopwords
\item
  tf-idf
\end{itemize}

\hypertarget{analysis-of-frequencies-and-term-frequency-document}{%
\subsection{Analysis of Frequencies and term-frequency document}\label{analysis-of-frequencies-and-term-frequency-document}}

\hypertarget{contingency-table}{%
\subsubsection{Contingency table}\label{contingency-table}}

Presentation of the tf/contingency table

\hypertarget{wordclouds}{%
\subsubsection{wordclouds}\label{wordclouds}}

\textbf{\{ggwordclouds\}}

\hypertarget{correspondence-analysis}{%
\subsubsection{Correspondence Analysis}\label{correspondence-analysis}}

\textbf{\{FactoMineR\}} and \textbf{\{Xplortext\}}

\hypertarget{futher-analysis-of-the-words}{%
\subsection{Futher Analysis of the words}\label{futher-analysis-of-the-words}}

\hypertarget{sentiment-analysis-1}{%
\subsubsection{Sentiment Analysis}\label{sentiment-analysis-1}}

Sentiment analysis and its relationship to hedonic statement
Introduction to free-JAR?

\hypertarget{bi-grams-and-n-grams}{%
\subsubsection{Bi-grams and N-grams}\label{bi-grams-and-n-grams}}

Presentation of graph-theory applied to text mining

\hypertarget{machine-learning}{%
\subsubsection{Machine learning}\label{machine-learning}}

Introduction to machine learning associated to text mining

\hypertarget{linear-programming}{%
\chapter{Linear Programming}\label{linear-programming}}

\hypertarget{overview-2}{%
\section{Overview}\label{overview-2}}

\hypertarget{common-applications-2}{%
\section{Common Applications}\label{common-applications-2}}

\hypertarget{experimental-design}{%
\subsection{Experimental Design}\label{experimental-design}}

\hypertarget{sample-selection}{%
\subsection{Sample Selection}\label{sample-selection}}

\hypertarget{compact-letter-displays}{%
\subsection{Compact Letter Displays}\label{compact-letter-displays}}

\hypertarget{turf-analysis}{%
\subsection{TURF Analysis}\label{turf-analysis}}

\hypertarget{bundle-optimization}{%
\subsection{Bundle Optimization}\label{bundle-optimization}}

\hypertarget{code-examples-2}{%
\section{Code Examples}\label{code-examples-2}}

\hypertarget{pipelines}{%
\chapter{Pipelines}\label{pipelines}}

\hypertarget{dashboards}{%
\chapter{Dashboards}\label{dashboards}}

\hypertarget{graph-db}{%
\chapter{Graph Databases}\label{graph-db}}

\hypertarget{appendix-uxe0-la-carte}{%
\appendix}


\hypertarget{start-R}{%
\chapter{Apéritifs (Getting Started)}\label{start-R}}

\hypertarget{r}{%
\section{R}\label{r}}

R is an open-source programming language and software environment
First released in 1995, R is an open-source implementation of S
R was developed by Ross Ihaka and Robert Gentleman
The name ``R'' is partly a play on Ihaka's and Gentleman's first names
R is a scripting language (not a compiled language)
Lines of R code run (mostly) in order
R is currently the 7th most popular programming language in the world

\hypertarget{why-learn-a-programming-language}{%
\subsection{Why Learn a Programming Language?}\label{why-learn-a-programming-language}}

Control
Speed
Reduced errors
Increased capability
Continuous improvement
Improved collaboration
Reproducible results

\hypertarget{why-r}{%
\subsection{Why R?}\label{why-r}}

R originated as a statistical computing language
It has a culture germane to sensory science
R is well-supported with an active community
Extensive online help is available
Many books, courses, and other educational material exist
The universe of available packages is vast
R excels at data manipulation and results reporting
R has more specialized tools for sensory analysis than other programming language

\hypertarget{why-r-1}{%
\section{Why R?}\label{why-r-1}}

For sensory and consumer scientists, we recommend the R ecosystem of tools for three main reasons. The first reason is cultural - R has from its inception been oriented more towards statistics than to computer science, making the feeling of programming in R more natural (in our experience) for sensory and consumer scientists than programming in Python. This opinion of experience is not to say that a sensory and consumer scientist shouldn't learn Python if they are so inclined, or even that Python tools aren't sometimes superior to R tools (in fact, they sometimes are). This latter point leads to our second reason, which is that R tools are typically better suited to sensory and consumer science than are Python tools. Even when Python tools are superior, the R tools are still sufficient for sensory and consumer science purposes, plus there are many custom packages such as SensR, SensoMineR, and FactorMineR that have been specifically developed for sensory and consumer science. Finally, the recent work by the RStudio company, and especially the exceptional work of Hadley Wickham, has lead to a very low barrier to entry for programming within R together with exceptional tools for data manipulation.

\hypertarget{steps-to-install-r}{%
\subsection{Steps to Install R}\label{steps-to-install-r}}

The first step in this journey is to install R. For this, visit \href{https://www.r-project.org/}{The R Project for Statistical Computing}. From there, follow the download instructions to install R for your particular platform.

\url{https://cran.r-project.org/bin/windows/base/}
Download the latest version of R
Install R with default options
You will almost certainly be running 64-bit R
Note: If you are running R 4.0 or higher, you might need to install Rtools:
\url{https://cran.r-project.org/bin/windows/Rtools/}

\hypertarget{rstudio}{%
\section{RStudio}\label{rstudio}}

\hypertarget{steps-to-install-rstudio}{%
\subsection{Steps to Install RStudio}\label{steps-to-install-rstudio}}

Next you need to install RStudio, which is our recommended integrated development environment (IDE) for developing R code. To do so, visit the \href{https://rstudio.com/products/rstudio/download/}{RStudio desktop download page} and follow the installation instructions.

Once you have installed R and RStudio, you should be able to open RStudio and enter the following into the Console to receive the number ``3'' as your output:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{x }\OtherTok{\textless{}{-}} \DecValTok{1}
\NormalTok{y }\OtherTok{\textless{}{-}} \DecValTok{2}

\NormalTok{x }\SpecialCharTok{+}\NormalTok{ y}
\end{Highlighting}
\end{Shaded}

Some recommendations upon installing RStudio:

\begin{itemize}
\tightlist
\item
  Change the color scheme to dark.
\item
  Put the console on the right.
\end{itemize}

\url{https://www.rstudio.com/products/rstudio/download/\#download}
Download and install the latest (almost certainly 64-bit) version of RStudio with default options
Adjustments:
Uncheck ``Restore .RData into workspace at startup
Select ``Never'' for ``Save workspace to .RData on exit''
Change color scheme to dark (e.g.~``Idle Fingers'')
Put console on right

\hypertarget{create-a-local-project}{%
\subsection{Create a Local Project}\label{create-a-local-project}}

Always work in an RStudio project
Projects keep your files (and activity) organized
Projects help manage your file path (so your computer can find things)
Projects allow for more advanced capabilities later (like GitHub or renv)
We cover the use of GitHub in a future webinar
For now we create projects locally

\hypertarget{install-and-load-packages}{%
\subsection{Install and Load Packages}\label{install-and-load-packages}}

As you use R, you will want to make use of the many packages others (and perhaps you) have written
Essential packages (or collections):
tidyverse, readxl
Custom Microsoft office document creation
officer, flextable, rvg, openxlsx, extrafont, extrafontdb
Sensory specific packages
sensR , SensoMineR, FactoMineR, factoextra
There are many more, for statistical tests of all varieties, to multivariate analysis, to machine learning, to text analysis, etc.

You only need to install each package once per R version
To install a package, you can:
Type install.packages(``{[}package name{]}'')
Use the RStudio dropdown
In addition, if a script loads package that are not installed, RStudio will prompt you to install the package
Notes:
If you do not have write access on your computer, you might need IT help to install packages
You might need to safelist various R related tools and sites

\hypertarget{run-sample-code}{%
\subsection{Run Sample Code}\label{run-sample-code}}

Like any language, R is best learned first through example then through study
We start with a series of examples to illustrate basic principles
For this example, we analyze a series of Tetrad tests

Suppose you have 15 out of 44 correct in a Tetrad test
Using sensR, it's easy to analyze these data:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(sensR)}

\NormalTok{num\_correct }\OtherTok{\textless{}{-}} \DecValTok{15}  
\NormalTok{num\_total }\OtherTok{\textless{}{-}} \DecValTok{44}  
  
\NormalTok{discrim\_res }\OtherTok{\textless{}{-}} \FunctionTok{discrim}\NormalTok{(num\_correct, num\_total, }\AttributeTok{method =} \StringTok{"tetrad"}\NormalTok{)  }
  
\FunctionTok{print}\NormalTok{(discrim\_res)  }
\end{Highlighting}
\end{Shaded}

\hypertarget{git-and-github}{%
\section{Git and GitHub}\label{git-and-github}}

Git is a version control system that allows you to revert to earlier versions of your code, if necessary. GitHub is service that allows for online backups of your code and which facilitates collaboration between team members. We highly recommend that you integrate both Git and GitHub into your data scientific workflow. For a full review of Git and GitHub from an R programming perspective, we recommend \href{https://happygitwithr.com/}{Happy Git with R} by Jenny Bryant. In what follows, we simply provide the minimum information needed to get you up and running with Git and GitHub. Also, for an insightful discussion of the need for version control, please see {[}Cite bryan2018excuse{]}.

\hypertarget{git}{%
\subsection{Git}\label{git}}

\begin{itemize}
\tightlist
\item
  Install Git

  \begin{itemize}
  \tightlist
  \item
    Windows
  \item
    macOS
  \end{itemize}
\item
  Register with RStudio
\end{itemize}

\hypertarget{github}{%
\subsection{GitHub}\label{github}}

\begin{itemize}
\tightlist
\item
  Create a GitHub account
\item
  Register with RStudio
\end{itemize}

\hypertarget{raw-material}{%
\section{RAW MATERIAL}\label{raw-material}}

\hypertarget{principles}{%
\subsection{Principles}\label{principles}}

\hypertarget{tools}{%
\subsection{Tools}\label{tools}}

\hypertarget{github-1}{%
\subsubsection{GitHub}\label{github-1}}

\hypertarget{r-scripts}{%
\subsubsection{R scripts}\label{r-scripts}}

\hypertarget{rmarkdown}{%
\subsubsection{RMarkdown}\label{rmarkdown}}

\hypertarget{shiny}{%
\subsubsection{Shiny}\label{shiny}}

\hypertarget{documentation}{%
\subsection{Documentation}\label{documentation}}

\hypertarget{version-control}{%
\subsection{Version control}\label{version-control}}

\hypertarget{online-repositories-for-team-collaboration}{%
\subsection{Online repositories for team collaboration}\label{online-repositories-for-team-collaboration}}

\hypertarget{building-a-code-base}{%
\subsection{Building a code base}\label{building-a-code-base}}

\hypertarget{internal-functions}{%
\subsubsection{Internal functions}\label{internal-functions}}

\hypertarget{packages}{%
\subsubsection{Packages}\label{packages}}

\hypertarget{next-steps}{%
\chapter{Digestifs (Next Steps)}\label{next-steps}}

\hypertarget{sensory-analysis-in-r}{%
\section{Sensory Analysis in R}\label{sensory-analysis-in-r}}

\hypertarget{other-recommended-resources}{%
\section{Other Recommended Resources}\label{other-recommended-resources}}

\hypertarget{r-for-data-science}{%
\subsection{R for Data Science}\label{r-for-data-science}}

\hypertarget{hands-on-machine-learning-with-r}{%
\subsection{Hands-On Machine Learning with R}\label{hands-on-machine-learning-with-r}}

\hypertarget{factoextra}{%
\subsection{FactoExtra}\label{factoextra}}

\hypertarget{r-graphics-cookbook}{%
\subsection{R Graphics Cookbook}\label{r-graphics-cookbook}}

\hypertarget{storytelling-with-data}{%
\subsection{Storytelling with Data}\label{storytelling-with-data}}

\hypertarget{text-mining-wtih-r}{%
\subsection{Text Mining wtih R}\label{text-mining-wtih-r}}

\hypertarget{python-and-other-languages}{%
\section{Python and Other Languages}\label{python-and-other-languages}}

\hypertarget{bibliography}{%
\chapter*{Bibliography}\label{bibliography}}
\addcontentsline{toc}{chapter}{Bibliography}

  \bibliography{references.bib}

\end{document}

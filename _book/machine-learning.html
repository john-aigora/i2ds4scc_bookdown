<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 12 Machine Learning | Data Science for Sensory and Consumer Scientists</title>
  <meta name="description" content="Open development of data science book for sensory and consumer scientists." />
  <meta name="generator" content="bookdown 0.27 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 12 Machine Learning | Data Science for Sensory and Consumer Scientists" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="Open development of data science book for sensory and consumer scientists." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 12 Machine Learning | Data Science for Sensory and Consumer Scientists" />
  
  <meta name="twitter:description" content="Open development of data science book for sensory and consumer scientists." />
  

<meta name="author" content="Thierry Worch, Julien Delarue, Vanessa Rios de Souza, and John Ennis" />


<meta name="date" content="2022-11-09" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="value-delivery.html"/>
<link rel="next" href="text-analysis.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>
<link href="libs/tabwid-1.0.0/tabwid.css" rel="stylesheet" />
<link href="libs/tabwid-1.0.0/scrool.css" rel="stylesheet" />


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  background-color: #f8f8f8; }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ef2929; } /* Alert */
code span.an { color: #8f5902; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #c4a000; } /* Attribute */
code span.bn { color: #0000cf; } /* BaseN */
code span.cf { color: #204a87; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4e9a06; } /* Char */
code span.cn { color: #000000; } /* Constant */
code span.co { color: #8f5902; font-style: italic; } /* Comment */
code span.cv { color: #8f5902; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #8f5902; font-weight: bold; font-style: italic; } /* Documentation */
code span.dt { color: #204a87; } /* DataType */
code span.dv { color: #0000cf; } /* DecVal */
code span.er { color: #a40000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #0000cf; } /* Float */
code span.fu { color: #000000; } /* Function */
code span.im { } /* Import */
code span.in { color: #8f5902; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #204a87; font-weight: bold; } /* Keyword */
code span.op { color: #ce5c00; font-weight: bold; } /* Operator */
code span.ot { color: #8f5902; } /* Other */
code span.pp { color: #8f5902; font-style: italic; } /* Preprocessor */
code span.sc { color: #000000; } /* SpecialChar */
code span.ss { color: #4e9a06; } /* SpecialString */
code span.st { color: #4e9a06; } /* String */
code span.va { color: #000000; } /* Variable */
code span.vs { color: #4e9a06; } /* VerbatimString */
code span.wa { color: #8f5902; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Data Science for Sensory and Consumer Scientists</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a>
<ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#who-should-read-this-book"><i class="fa fa-check"></i>Who Should Read This Book?</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#how-is-this-book-structured"><i class="fa fa-check"></i>How Is This Book Structured</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#how-to-use-this-book"><i class="fa fa-check"></i>How To Use This Book</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#acknowledgements"><i class="fa fa-check"></i>Acknowledgements</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="preface-1.html"><a href="preface-1.html"><i class="fa fa-check"></i>Preface</a></li>
<li class="chapter" data-level="1" data-path="bienvenue.html"><a href="bienvenue.html"><i class="fa fa-check"></i><b>1</b> Bienvenue!</a>
<ul>
<li class="chapter" data-level="" data-path="bienvenue.html"><a href="bienvenue.html#why-data-science-for-sensory-and-consumer-science"><i class="fa fa-check"></i>Why Data Science for Sensory and Consumer Science?</a>
<ul>
<li class="chapter" data-level="" data-path="bienvenue.html"><a href="bienvenue.html#core-principles-in-sensory-and-consumer-science"><i class="fa fa-check"></i>Core principles in Sensory and Consumer Science</a></li>
<li class="chapter" data-level="" data-path="bienvenue.html"><a href="bienvenue.html#computational-sensory-science"><i class="fa fa-check"></i>Computational Sensory Science</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>Ap√©ritifs</b></span></li>
<li class="chapter" data-level="2" data-path="start-R.html"><a href="start-R.html"><i class="fa fa-check"></i><b>2</b> Getting Started</a>
<ul>
<li class="chapter" data-level="2.1" data-path="start-R.html"><a href="start-R.html#introduction-to-r"><i class="fa fa-check"></i><b>2.1</b> Introduction to R</a>
<ul>
<li class="chapter" data-level="2.1.1" data-path="start-R.html"><a href="start-R.html#what-is-r"><i class="fa fa-check"></i><b>2.1.1</b> What is R?</a></li>
<li class="chapter" data-level="2.1.2" data-path="start-R.html"><a href="start-R.html#why-learning-r-or-any-programming-language"><i class="fa fa-check"></i><b>2.1.2</b> Why Learning R (or any Programming Language)?</a></li>
<li class="chapter" data-level="2.1.3" data-path="start-R.html"><a href="start-R.html#why-r"><i class="fa fa-check"></i><b>2.1.3</b> Why R?</a></li>
<li class="chapter" data-level="2.1.4" data-path="start-R.html"><a href="start-R.html#rstudio"><i class="fa fa-check"></i><b>2.1.4</b> Why RStudio/Posit?</a></li>
<li class="chapter" data-level="2.1.5" data-path="start-R.html"><a href="start-R.html#installing-r-and-rstudio"><i class="fa fa-check"></i><b>2.1.5</b> Installing R and RStudio</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="start-R.html"><a href="start-R.html#getting-started-in-r"><i class="fa fa-check"></i><b>2.2</b> Getting Started in R</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="start-R.html"><a href="start-R.html#packages"><i class="fa fa-check"></i><b>2.2.1</b> Conventions</a></li>
<li class="chapter" data-level="2.2.2" data-path="start-R.html"><a href="start-R.html#install-and-load-packages"><i class="fa fa-check"></i><b>2.2.2</b> Install and Load Packages</a></li>
<li class="chapter" data-level="2.2.3" data-path="start-R.html"><a href="start-R.html#first-analysis-in-r"><i class="fa fa-check"></i><b>2.2.3</b> First Analysis in R</a></li>
<li class="chapter" data-level="2.2.4" data-path="start-R.html"><a href="start-R.html#scripts"><i class="fa fa-check"></i><b>2.2.4</b> R Scripts</a></li>
<li class="chapter" data-level="2.2.5" data-path="start-R.html"><a href="start-R.html#rprojects"><i class="fa fa-check"></i><b>2.2.5</b> Create a Local Project</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="start-R.html"><a href="start-R.html#further-tips-on-how-to-read-this-book"><i class="fa fa-check"></i><b>2.3</b> Further tips on <em>how to read this book?</em></a>
<ul>
<li class="chapter" data-level="2.3.1" data-path="start-R.html"><a href="start-R.html#pipes"><i class="fa fa-check"></i><b>2.3.1</b> Introduction to the <code>{magrittr}</code> and the notion of <em>pipes</em></a></li>
<li class="chapter" data-level="2.3.2" data-path="start-R.html"><a href="start-R.html#calling-variables"><i class="fa fa-check"></i><b>2.3.2</b> Calling Variables</a></li>
<li class="chapter" data-level="2.3.3" data-path="start-R.html"><a href="start-R.html#print-save"><i class="fa fa-check"></i><b>2.3.3</b> Printing vs.¬†Saving results</a></li>
<li class="chapter" data-level="2.3.4" data-path="start-R.html"><a href="start-R.html#running-code-and-handling-errors"><i class="fa fa-check"></i><b>2.3.4</b> Running code and handling errors</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="start-R.html"><a href="start-R.html#git-and-github"><i class="fa fa-check"></i><b>2.4</b> Version Control / Git and GitHub</a>
<ul>
<li class="chapter" data-level="2.4.1" data-path="start-R.html"><a href="start-R.html#git"><i class="fa fa-check"></i><b>2.4.1</b> Git</a></li>
<li class="chapter" data-level="2.4.2" data-path="start-R.html"><a href="start-R.html#github"><i class="fa fa-check"></i><b>2.4.2</b> GitHub</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>Hors d‚ÄôOeuvres</b></span></li>
<li class="chapter" data-level="3" data-path="data_science.html"><a href="data_science.html"><i class="fa fa-check"></i><b>3</b> Why Data Science?</a>
<ul>
<li class="chapter" data-level="3.1" data-path="data_science.html"><a href="data_science.html#history-and-definition"><i class="fa fa-check"></i><b>3.1</b> History and Definition</a></li>
<li class="chapter" data-level="3.2" data-path="data_science.html"><a href="data_science.html#benefits-of-data-science"><i class="fa fa-check"></i><b>3.2</b> Benefits of Data Science</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="data_science.html"><a href="data_science.html#reproducible-research"><i class="fa fa-check"></i><b>3.2.1</b> Reproducible Research</a></li>
<li class="chapter" data-level="3.2.2" data-path="data_science.html"><a href="data_science.html#standardized-reporting"><i class="fa fa-check"></i><b>3.2.2</b> Standardized Reporting</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="data_science.html"><a href="data_science.html#data-scientific-workflow"><i class="fa fa-check"></i><b>3.3</b> Data Scientific Workflow</a>
<ul>
<li class="chapter" data-level="3.3.1" data-path="data_science.html"><a href="data_science.html#data-collection2"><i class="fa fa-check"></i><b>3.3.1</b> Data Collection</a></li>
<li class="chapter" data-level="3.3.2" data-path="data_science.html"><a href="data_science.html#data-preparation"><i class="fa fa-check"></i><b>3.3.2</b> Data Preparation</a></li>
<li class="chapter" data-level="3.3.3" data-path="data_science.html"><a href="data_science.html#data-analysis2"><i class="fa fa-check"></i><b>3.3.3</b> Data Analysis</a></li>
<li class="chapter" data-level="3.3.4" data-path="data_science.html"><a href="data_science.html#value-delivery2"><i class="fa fa-check"></i><b>3.3.4</b> Value Delivery</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="data_science.html"><a href="data_science.html#how-to-learn-data-science"><i class="fa fa-check"></i><b>3.4</b> How to Learn Data Science</a></li>
<li class="chapter" data-level="3.5" data-path="data_science.html"><a href="data_science.html#cautions-dont-that-everybody-does"><i class="fa fa-check"></i><b>3.5</b> Cautions: Don‚Äôt that Everybody Does</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="data-manip.html"><a href="data-manip.html"><i class="fa fa-check"></i><b>4</b> Data Manipulation</a>
<ul>
<li class="chapter" data-level="4.1" data-path="data-manip.html"><a href="data-manip.html#why-manipulating-data"><i class="fa fa-check"></i><b>4.1</b> Why Manipulating Data?</a></li>
<li class="chapter" data-level="4.2" data-path="data-manip.html"><a href="data-manip.html#tidy-data"><i class="fa fa-check"></i><b>4.2</b> Tidying Data</a>
<ul>
<li class="chapter" data-level="4.2.1" data-path="data-manip.html"><a href="data-manip.html#simple-manipulations"><i class="fa fa-check"></i><b>4.2.1</b> Simple Manipulations</a></li>
<li class="chapter" data-level="4.2.2" data-path="data-manip.html"><a href="data-manip.html#pivots"><i class="fa fa-check"></i><b>4.2.2</b> Reshaping Data</a></li>
<li class="chapter" data-level="4.2.3" data-path="data-manip.html"><a href="data-manip.html#transformation-that-alters-the-data"><i class="fa fa-check"></i><b>4.2.3</b> Transformation that Alters the Data</a></li>
<li class="chapter" data-level="4.2.4" data-path="data-manip.html"><a href="data-manip.html#combining-data-from-different-sources"><i class="fa fa-check"></i><b>4.2.4</b> Combining Data from Different Sources</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="data-viz.html"><a href="data-viz.html"><i class="fa fa-check"></i><b>5</b> Data Visualization</a>
<ul>
<li class="chapter" data-level="5.1" data-path="data-viz.html"><a href="data-viz.html#introduction"><i class="fa fa-check"></i><b>5.1</b> Introduction</a></li>
<li class="chapter" data-level="5.2" data-path="data-viz.html"><a href="data-viz.html#design-principles"><i class="fa fa-check"></i><b>5.2</b> Design Principles</a></li>
<li class="chapter" data-level="5.3" data-path="data-viz.html"><a href="data-viz.html#table_making"><i class="fa fa-check"></i><b>5.3</b> Table Making</a>
<ul>
<li class="chapter" data-level="5.3.1" data-path="data-viz.html"><a href="data-viz.html#flextable"><i class="fa fa-check"></i><b>5.3.1</b> Introduction to <code>{flextable}</code></a></li>
<li class="chapter" data-level="5.3.2" data-path="data-viz.html"><a href="data-viz.html#introdution-to-gt"><i class="fa fa-check"></i><b>5.3.2</b> Introdution to <code>{gt}</code></a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="data-viz.html"><a href="data-viz.html#chart-making"><i class="fa fa-check"></i><b>5.4</b> Chart Making</a>
<ul>
<li class="chapter" data-level="5.4.1" data-path="data-viz.html"><a href="data-viz.html#philosophy-of-ggplot2"><i class="fa fa-check"></i><b>5.4.1</b> Philosophy of <code>{ggplot2}</code></a></li>
<li class="chapter" data-level="5.4.2" data-path="data-viz.html"><a href="data-viz.html#getting-started-with-ggplot2"><i class="fa fa-check"></i><b>5.4.2</b> Getting started with <code>{ggplot2}</code></a></li>
<li class="chapter" data-level="5.4.3" data-path="data-viz.html"><a href="data-viz.html#common-charts"><i class="fa fa-check"></i><b>5.4.3</b> Common Charts</a></li>
<li class="chapter" data-level="5.4.4" data-path="data-viz.html"><a href="data-viz.html#miscealleneous"><i class="fa fa-check"></i><b>5.4.4</b> Miscealleneous</a></li>
<li class="chapter" data-level="5.4.5" data-path="data-viz.html"><a href="data-viz.html#few-additional-tips-and-tricks"><i class="fa fa-check"></i><b>5.4.5</b> Few Additional Tips and Tricks</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="auto-report.html"><a href="auto-report.html"><i class="fa fa-check"></i><b>6</b> Automated Reporting</a>
<ul>
<li class="chapter" data-level="6.1" data-path="auto-report.html"><a href="auto-report.html#what-and-why-automated-reporting"><i class="fa fa-check"></i><b>6.1</b> What and why Automated Reporting?</a></li>
<li class="chapter" data-level="6.2" data-path="auto-report.html"><a href="auto-report.html#integrating-reports-within-analyses-scripts"><i class="fa fa-check"></i><b>6.2</b> Integrating reports within analyses scripts</a>
<ul>
<li class="chapter" data-level="6.2.1" data-path="auto-report.html"><a href="auto-report.html#excel"><i class="fa fa-check"></i><b>6.2.1</b> Excel</a></li>
<li class="chapter" data-level="6.2.2" data-path="auto-report.html"><a href="auto-report.html#powerpoint"><i class="fa fa-check"></i><b>6.2.2</b> PowerPoint</a></li>
<li class="chapter" data-level="6.2.3" data-path="auto-report.html"><a href="auto-report.html#word"><i class="fa fa-check"></i><b>6.2.3</b> Word</a></li>
<li class="chapter" data-level="6.2.4" data-path="auto-report.html"><a href="auto-report.html#notes-on-applying-corporate-branding"><i class="fa fa-check"></i><b>6.2.4</b> Notes on applying corporate branding</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="auto-report.html"><a href="auto-report.html#integrating-analyses-scripts-within-your-reporting-tool"><i class="fa fa-check"></i><b>6.3</b> Integrating analyses scripts within your reporting tool</a>
<ul>
<li class="chapter" data-level="6.3.1" data-path="auto-report.html"><a href="auto-report.html#what-is-rmarkdown"><i class="fa fa-check"></i><b>6.3.1</b> What is <code>{rmarkdown}</code></a></li>
<li class="chapter" data-level="6.3.2" data-path="auto-report.html"><a href="auto-report.html#starting-with-rmarkdown"><i class="fa fa-check"></i><b>6.3.2</b> Starting with {rmarkdown}</a></li>
<li class="chapter" data-level="6.3.3" data-path="auto-report.html"><a href="auto-report.html#rmarkdown-through-a-simple-example"><i class="fa fa-check"></i><b>6.3.3</b> <code>{rmarkdown}</code> through a Simple Example</a></li>
<li class="chapter" data-level="6.3.4" data-path="auto-report.html"><a href="auto-report.html#creating-a-document-using-knitr"><i class="fa fa-check"></i><b>6.3.4</b> Creating a document using <code>{knitr}</code></a></li>
<li class="chapter" data-level="6.3.5" data-path="auto-report.html"><a href="auto-report.html#example-of-applications"><i class="fa fa-check"></i><b>6.3.5</b> Example of applications</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="auto-report.html"><a href="auto-report.html#to-go-further"><i class="fa fa-check"></i><b>6.4</b> To go further‚Ä¶</a></li>
</ul></li>
<li class="part"><span><b>Bon App√©tit</b></span></li>
<li class="chapter" data-level="7" data-path="example-projects.html"><a href="example-projects.html"><i class="fa fa-check"></i><b>7</b> Example Project: The Biscuit Study</a>
<ul>
<li class="chapter" data-level="7.1" data-path="example-projects.html"><a href="example-projects.html#objective-of-the-test"><i class="fa fa-check"></i><b>7.1</b> Objective of the Test</a></li>
<li class="chapter" data-level="7.2" data-path="example-projects.html"><a href="example-projects.html#products"><i class="fa fa-check"></i><b>7.2</b> Products</a></li>
<li class="chapter" data-level="7.3" data-path="example-projects.html"><a href="example-projects.html#consumer-test"><i class="fa fa-check"></i><b>7.3</b> Consumer test</a>
<ul>
<li class="chapter" data-level="7.3.1" data-path="example-projects.html"><a href="example-projects.html#participants"><i class="fa fa-check"></i><b>7.3.1</b> Participants</a></li>
<li class="chapter" data-level="7.3.2" data-path="example-projects.html"><a href="example-projects.html#test-design"><i class="fa fa-check"></i><b>7.3.2</b> Test design</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="example-projects.html"><a href="example-projects.html#sensory-descriptive-analysis-data"><i class="fa fa-check"></i><b>7.4</b> Sensory descriptive analysis data</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="data-collection.html"><a href="data-collection.html"><i class="fa fa-check"></i><b>8</b> Data Collection</a>
<ul>
<li class="chapter" data-level="8.1" data-path="data-collection.html"><a href="data-collection.html#designs-of-sensory-doe-experiments"><i class="fa fa-check"></i><b>8.1</b> Designs of sensory (DoE) experiments</a>
<ul>
<li class="chapter" data-level="8.1.1" data-path="data-collection.html"><a href="data-collection.html#general-approach"><i class="fa fa-check"></i><b>8.1.1</b> General approach</a></li>
<li class="chapter" data-level="8.1.2" data-path="data-collection.html"><a href="data-collection.html#Crossover"><i class="fa fa-check"></i><b>8.1.2</b> Crossover designs</a></li>
<li class="chapter" data-level="8.1.3" data-path="data-collection.html"><a href="data-collection.html#BIBD"><i class="fa fa-check"></i><b>8.1.3</b> Balanced incomplete block designs (BIBD)</a></li>
<li class="chapter" data-level="8.1.4" data-path="data-collection.html"><a href="data-collection.html#incomplete-designs-for-hedonic-tests-sensory-informed-designs"><i class="fa fa-check"></i><b>8.1.4</b> Incomplete designs for hedonic tests: Sensory informed designs</a></li>
</ul></li>
<li class="chapter" data-level="8.2" data-path="data-collection.html"><a href="data-collection.html#product-related-designs"><i class="fa fa-check"></i><b>8.2</b> Product-related designs</a>
<ul>
<li class="chapter" data-level="8.2.1" data-path="data-collection.html"><a href="data-collection.html#factorial-designs"><i class="fa fa-check"></i><b>8.2.1</b> Factorial designs</a></li>
<li class="chapter" data-level="8.2.2" data-path="data-collection.html"><a href="data-collection.html#mixture-designs"><i class="fa fa-check"></i><b>8.2.2</b> Mixture designs</a></li>
<li class="chapter" data-level="8.2.3" data-path="data-collection.html"><a href="data-collection.html#screening-designs"><i class="fa fa-check"></i><b>8.2.3</b> Screening designs</a></li>
<li class="chapter" data-level="8.2.4" data-path="data-collection.html"><a href="data-collection.html#sensory-informed-designs"><i class="fa fa-check"></i><b>8.2.4</b> Sensory informed designs</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="data-collection.html"><a href="data-collection.html#execute-1"><i class="fa fa-check"></i><b>8.3</b> Execute</a></li>
<li class="chapter" data-level="8.4" data-path="data-collection.html"><a href="data-collection.html#data-import"><i class="fa fa-check"></i><b>8.4</b> Import</a>
<ul>
<li class="chapter" data-level="8.4.1" data-path="data-collection.html"><a href="data-collection.html#importing-structured-excel-file"><i class="fa fa-check"></i><b>8.4.1</b> Importing Structured Excel File</a></li>
<li class="chapter" data-level="8.4.2" data-path="data-collection.html"><a href="data-collection.html#importing-unstructured-excel-file"><i class="fa fa-check"></i><b>8.4.2</b> Importing Unstructured Excel File</a></li>
<li class="chapter" data-level="8.4.3" data-path="data-collection.html"><a href="data-collection.html#import-mult-sheet"><i class="fa fa-check"></i><b>8.4.3</b> Importing Data Stored in Multiple Sheets</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="9" data-path="data-prep.html"><a href="data-prep.html"><i class="fa fa-check"></i><b>9</b> Data Preparation</a>
<ul>
<li class="chapter" data-level="9.1" data-path="data-prep.html"><a href="data-prep.html#introduction-1"><i class="fa fa-check"></i><b>9.1</b> Introduction</a></li>
<li class="chapter" data-level="9.2" data-path="data-prep.html"><a href="data-prep.html#inspect"><i class="fa fa-check"></i><b>9.2</b> Inspect</a>
<ul>
<li class="chapter" data-level="9.2.1" data-path="data-prep.html"><a href="data-prep.html#data-inspection"><i class="fa fa-check"></i><b>9.2.1</b> Data Inspection</a></li>
<li class="chapter" data-level="9.2.2" data-path="data-prep.html"><a href="data-prep.html#missing-data"><i class="fa fa-check"></i><b>9.2.2</b> Missing Data</a></li>
<li class="chapter" data-level="9.2.3" data-path="data-prep.html"><a href="data-prep.html#design-inspection"><i class="fa fa-check"></i><b>9.2.3</b> Design Inspection</a></li>
</ul></li>
<li class="chapter" data-level="9.3" data-path="data-prep.html"><a href="data-prep.html#clean"><i class="fa fa-check"></i><b>9.3</b> Clean</a>
<ul>
<li class="chapter" data-level="9.3.1" data-path="data-prep.html"><a href="data-prep.html#handling-data-type"><i class="fa fa-check"></i><b>9.3.1</b> Handling Data Type</a></li>
<li class="chapter" data-level="9.3.2" data-path="data-prep.html"><a href="data-prep.html#converting-between-types"><i class="fa fa-check"></i><b>9.3.2</b> Converting between Types</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="10" data-path="data-analysis.html"><a href="data-analysis.html"><i class="fa fa-check"></i><b>10</b> Data Analysis</a>
<ul>
<li class="chapter" data-level="10.1" data-path="data-analysis.html"><a href="data-analysis.html#sensory-data"><i class="fa fa-check"></i><b>10.1</b> Sensory Data</a></li>
<li class="chapter" data-level="10.2" data-path="data-analysis.html"><a href="data-analysis.html#demographic-and-questionnaire-data"><i class="fa fa-check"></i><b>10.2</b> Demographic and Questionnaire Data</a>
<ul>
<li class="chapter" data-level="10.2.1" data-path="data-analysis.html"><a href="data-analysis.html#demographic-data-frequency-and-proportion"><i class="fa fa-check"></i><b>10.2.1</b> Demographic Data: Frequency and Proportion</a></li>
<li class="chapter" data-level="10.2.2" data-path="data-analysis.html"><a href="data-analysis.html#eating-behavior-traits-tfeq-data"><i class="fa fa-check"></i><b>10.2.2</b> Eating behavior traits: TFEQ data</a></li>
</ul></li>
<li class="chapter" data-level="10.3" data-path="data-analysis.html"><a href="data-analysis.html#consumer-data"><i class="fa fa-check"></i><b>10.3</b> Consumer Data</a></li>
<li class="chapter" data-level="10.4" data-path="data-analysis.html"><a href="data-analysis.html#combining-sensory-and-consumer-data"><i class="fa fa-check"></i><b>10.4</b> Combining Sensory and Consumer Data</a>
<ul>
<li class="chapter" data-level="10.4.1" data-path="data-analysis.html"><a href="data-analysis.html#internal-preference-mapping"><i class="fa fa-check"></i><b>10.4.1</b> Internal Preference Mapping</a></li>
<li class="chapter" data-level="10.4.2" data-path="data-analysis.html"><a href="data-analysis.html#consumers-clustering"><i class="fa fa-check"></i><b>10.4.2</b> Consumers Clustering</a></li>
<li class="chapter" data-level="10.4.3" data-path="data-analysis.html"><a href="data-analysis.html#drivers-of-liking"><i class="fa fa-check"></i><b>10.4.3</b> Drivers of Liking</a></li>
<li class="chapter" data-level="10.4.4" data-path="data-analysis.html"><a href="data-analysis.html#external-preference-mapping"><i class="fa fa-check"></i><b>10.4.4</b> External Preference Mapping</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="11" data-path="value-delivery.html"><a href="value-delivery.html"><i class="fa fa-check"></i><b>11</b> Value Delivery</a>
<ul>
<li class="chapter" data-level="11.1" data-path="value-delivery.html"><a href="value-delivery.html#how-to-communicate"><i class="fa fa-check"></i><b>11.1</b> How to Communicate?</a></li>
<li class="chapter" data-level="11.2" data-path="value-delivery.html"><a href="value-delivery.html#exploratory-explanatory-and-predictive-analysis"><i class="fa fa-check"></i><b>11.2</b> Exploratory, Explanatory and Predictive Analysis</a></li>
<li class="chapter" data-level="11.3" data-path="value-delivery.html"><a href="value-delivery.html#audience-awareness"><i class="fa fa-check"></i><b>11.3</b> Audience Awareness</a>
<ul>
<li class="chapter" data-level="11.3.1" data-path="value-delivery.html"><a href="value-delivery.html#technical-audience"><i class="fa fa-check"></i><b>11.3.1</b> Technical Audience</a></li>
<li class="chapter" data-level="11.3.2" data-path="value-delivery.html"><a href="value-delivery.html#management"><i class="fa fa-check"></i><b>11.3.2</b> Management</a></li>
<li class="chapter" data-level="11.3.3" data-path="value-delivery.html"><a href="value-delivery.html#general-interest"><i class="fa fa-check"></i><b>11.3.3</b> General Interest</a></li>
</ul></li>
<li class="chapter" data-level="11.4" data-path="value-delivery.html"><a href="value-delivery.html#methods-to-communicate"><i class="fa fa-check"></i><b>11.4</b> Methods to Communicate</a>
<ul>
<li class="chapter" data-level="11.4.1" data-path="value-delivery.html"><a href="value-delivery.html#consider-the-mechanism"><i class="fa fa-check"></i><b>11.4.1</b> Consider the Mechanism</a></li>
<li class="chapter" data-level="11.4.2" data-path="value-delivery.html"><a href="value-delivery.html#pick-the-correct-format"><i class="fa fa-check"></i><b>11.4.2</b> Pick the Correct Format</a></li>
</ul></li>
<li class="chapter" data-level="11.5" data-path="value-delivery.html"><a href="value-delivery.html#storytelling"><i class="fa fa-check"></i><b>11.5</b> Storytelling</a></li>
<li class="chapter" data-level="11.6" data-path="value-delivery.html"><a href="value-delivery.html#reformulate2"><i class="fa fa-check"></i><b>11.6</b> Reformulate</a></li>
</ul></li>
<li class="part"><span><b>Haute Cuisine</b></span></li>
<li class="chapter" data-level="12" data-path="machine-learning.html"><a href="machine-learning.html"><i class="fa fa-check"></i><b>12</b> Machine Learning</a>
<ul>
<li class="chapter" data-level="12.1" data-path="machine-learning.html"><a href="machine-learning.html#introduction-2"><i class="fa fa-check"></i><b>12.1</b> Introduction</a></li>
<li class="chapter" data-level="12.2" data-path="machine-learning.html"><a href="machine-learning.html#machine-learning-methods"><i class="fa fa-check"></i><b>12.2</b> Machine Learning Methods</a>
<ul>
<li class="chapter" data-level="12.2.1" data-path="machine-learning.html"><a href="machine-learning.html#unsupervised-learning"><i class="fa fa-check"></i><b>12.2.1</b> Unsupervised learning</a></li>
<li class="chapter" data-level="12.2.2" data-path="machine-learning.html"><a href="machine-learning.html#supervised-learning"><i class="fa fa-check"></i><b>12.2.2</b> Supervised learning</a></li>
<li class="chapter" data-level="12.2.3" data-path="machine-learning.html"><a href="machine-learning.html#practical-guide-to-machine-learning"><i class="fa fa-check"></i><b>12.2.3</b> Practical Guide to Machine Learning</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="13" data-path="text-analysis.html"><a href="text-analysis.html"><i class="fa fa-check"></i><b>13</b> Text Analysis</a>
<ul>
<li class="chapter" data-level="13.1" data-path="text-analysis.html"><a href="text-analysis.html#introduction-to-natural-language-processing"><i class="fa fa-check"></i><b>13.1</b> Introduction to Natural Language Processing</a></li>
<li class="chapter" data-level="13.2" data-path="text-analysis.html"><a href="text-analysis.html#application-of-text-analysis-in-sensory-and-consumer-science"><i class="fa fa-check"></i><b>13.2</b> Application of Text Analysis in Sensory and Consumer Science</a>
<ul>
<li class="chapter" data-level="13.2.1" data-path="text-analysis.html"><a href="text-analysis.html#text-analysis-as-way-to-describe-products"><i class="fa fa-check"></i><b>13.2.1</b> Text analysis as way to describe products</a></li>
<li class="chapter" data-level="13.2.2" data-path="text-analysis.html"><a href="text-analysis.html#objectives-of-text-analysis"><i class="fa fa-check"></i><b>13.2.2</b> Objectives of Text Analysis</a></li>
<li class="chapter" data-level="13.2.3" data-path="text-analysis.html"><a href="text-analysis.html#classical-text-analysis-workflow"><i class="fa fa-check"></i><b>13.2.3</b> Classical <em>text analysis</em> workflow</a></li>
<li class="chapter" data-level="13.2.4" data-path="text-analysis.html"><a href="text-analysis.html#warnings"><i class="fa fa-check"></i><b>13.2.4</b> Warnings</a></li>
</ul></li>
<li class="chapter" data-level="13.3" data-path="text-analysis.html"><a href="text-analysis.html#illustration-using-sorting-task-data"><i class="fa fa-check"></i><b>13.3</b> Illustration using Sorting Task Data</a>
<ul>
<li class="chapter" data-level="13.3.1" data-path="text-analysis.html"><a href="text-analysis.html#data-pre-processing"><i class="fa fa-check"></i><b>13.3.1</b> Data Pre-processing</a></li>
<li class="chapter" data-level="13.3.2" data-path="text-analysis.html"><a href="text-analysis.html#introduction-to-working-with-strings-stringr"><i class="fa fa-check"></i><b>13.3.2</b> Introduction to working with strings (<code>{stringr}</code>)</a></li>
<li class="chapter" data-level="13.3.3" data-path="text-analysis.html"><a href="text-analysis.html#tokenization"><i class="fa fa-check"></i><b>13.3.3</b> Tokenization</a></li>
<li class="chapter" data-level="13.3.4" data-path="text-analysis.html"><a href="text-analysis.html#simple-transformations"><i class="fa fa-check"></i><b>13.3.4</b> Simple Transformations</a></li>
<li class="chapter" data-level="13.3.5" data-path="text-analysis.html"><a href="text-analysis.html#splitting-further-the-tokens"><i class="fa fa-check"></i><b>13.3.5</b> Splitting further the tokens</a></li>
<li class="chapter" data-level="13.3.6" data-path="text-analysis.html"><a href="text-analysis.html#stopwords"><i class="fa fa-check"></i><b>13.3.6</b> Stopwords</a></li>
<li class="chapter" data-level="13.3.7" data-path="text-analysis.html"><a href="text-analysis.html#stemming-and-lemmatization"><i class="fa fa-check"></i><b>13.3.7</b> Stemming and Lemmatization</a></li>
</ul></li>
<li class="chapter" data-level="13.4" data-path="text-analysis.html"><a href="text-analysis.html#text-analysis-1"><i class="fa fa-check"></i><b>13.4</b> Text Analysis</a>
<ul>
<li class="chapter" data-level="13.4.1" data-path="text-analysis.html"><a href="text-analysis.html#raw-frequencies-and-visualization"><i class="fa fa-check"></i><b>13.4.1</b> Raw Frequencies and Visualization</a></li>
<li class="chapter" data-level="13.4.2" data-path="text-analysis.html"><a href="text-analysis.html#bigrams-n-grams"><i class="fa fa-check"></i><b>13.4.2</b> Bigrams, <em>n</em>-grams</a></li>
<li class="chapter" data-level="13.4.3" data-path="text-analysis.html"><a href="text-analysis.html#word-embedding"><i class="fa fa-check"></i><b>13.4.3</b> Word Embedding</a></li>
<li class="chapter" data-level="13.4.4" data-path="text-analysis.html"><a href="text-analysis.html#sentiment-analysis"><i class="fa fa-check"></i><b>13.4.4</b> Sentiment Analysis</a></li>
</ul></li>
<li class="chapter" data-level="13.5" data-path="text-analysis.html"><a href="text-analysis.html#to-go-further-1"><i class="fa fa-check"></i><b>13.5</b> To go further‚Ä¶</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="dashboards.html"><a href="dashboards.html"><i class="fa fa-check"></i><b>14</b> Dashboards</a>
<ul>
<li class="chapter" data-level="14.1" data-path="dashboards.html"><a href="dashboards.html#objectives"><i class="fa fa-check"></i><b>14.1</b> Objectives</a></li>
<li class="chapter" data-level="14.2" data-path="dashboards.html"><a href="dashboards.html#introduction-to-shiny-through-an-example"><i class="fa fa-check"></i><b>14.2</b> Introduction to Shiny through an Example</a>
<ul>
<li class="chapter" data-level="14.2.1" data-path="dashboards.html"><a href="dashboards.html#what-is-a-shiny-application"><i class="fa fa-check"></i><b>14.2.1</b> What is a Shiny application?</a></li>
<li class="chapter" data-level="14.2.2" data-path="dashboards.html"><a href="dashboards.html#starting-with-shiny"><i class="fa fa-check"></i><b>14.2.2</b> Starting with Shiny</a></li>
<li class="chapter" data-level="14.2.3" data-path="dashboards.html"><a href="dashboards.html#illustration"><i class="fa fa-check"></i><b>14.2.3</b> Illustration</a></li>
<li class="chapter" data-level="14.2.4" data-path="dashboards.html"><a href="dashboards.html#deploying-the-application"><i class="fa fa-check"></i><b>14.2.4</b> Deploying the Application</a></li>
</ul></li>
<li class="chapter" data-level="14.3" data-path="dashboards.html"><a href="dashboards.html#to-go-further-2"><i class="fa fa-check"></i><b>14.3</b> To go further‚Ä¶</a>
<ul>
<li class="chapter" data-level="14.3.1" data-path="dashboards.html"><a href="dashboards.html#personalizing-and-tuning-your-application"><i class="fa fa-check"></i><b>14.3.1</b> Personalizing and Tuning your application</a></li>
<li class="chapter" data-level="14.3.2" data-path="dashboards.html"><a href="dashboards.html#upgrading-tables"><i class="fa fa-check"></i><b>14.3.2</b> Upgrading Tables</a></li>
<li class="chapter" data-level="14.3.3" data-path="dashboards.html"><a href="dashboards.html#building-dashboard"><i class="fa fa-check"></i><b>14.3.3</b> Building Dashboard</a></li>
<li class="chapter" data-level="14.3.4" data-path="dashboards.html"><a href="dashboards.html#interactive-graphics"><i class="fa fa-check"></i><b>14.3.4</b> Interactive Graphics</a></li>
<li class="chapter" data-level="14.3.5" data-path="dashboards.html"><a href="dashboards.html#interactive-documents"><i class="fa fa-check"></i><b>14.3.5</b> Interactive Documents</a></li>
<li class="chapter" data-level="14.3.6" data-path="dashboards.html"><a href="dashboards.html#documentation-and-books"><i class="fa fa-check"></i><b>14.3.6</b> Documentation and Books</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>Digestifs</b></span></li>
<li class="chapter" data-level="15" data-path="next-steps.html"><a href="next-steps.html"><i class="fa fa-check"></i><b>15</b> Conclusion and Next Steps</a>
<ul>
<li class="chapter" data-level="15.1" data-path="next-steps.html"><a href="next-steps.html#other-recommended-resources"><i class="fa fa-check"></i><b>15.1</b> Other Recommended Resources</a></li>
<li class="chapter" data-level="15.2" data-path="next-steps.html"><a href="next-steps.html#useful-r-packages"><i class="fa fa-check"></i><b>15.2</b> Useful R Packages</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="bibliography.html"><a href="bibliography.html"><i class="fa fa-check"></i>Bibliography</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Data Science for Sensory and Consumer Scientists</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="machine-learning" class="section level1 hasAnchor" number="12">
<h1><span class="header-section-number">Chapter 12</span> Machine Learning<a href="machine-learning.html#machine-learning" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<blockquote>
<p>Artificial Intelligence (AI) and Machine Learning (ML) in particular have gained a lot of attention in recent years. With the increase of data availability, data storage, and computing power, many techniques that were just <em>dreams</em> back then are now easily accessible, and used. And of course, the sensory and consumer science field is not an exception to this rule as we start seeing more and more ML applications‚Ä¶although in our case, we do not have <em>Big Data</em>, instead we do have <em>diverse data</em>!
For many of us, AI and ML seems to be a broad and complex topic. This assertion is true, and in fact it would deserve a whole book dedicated just to it. However, our intention in this chapter is to introduce and demistify the concept of ML, by:</p>
</blockquote>
<blockquote>
<ol style="list-style-type: decimal">
<li>explaining the differences between supervised and unsupervised ML models,</li>
<li>proving that we were already doing it long ago,</li>
<li>extending it to more advanced techniques,</li>
<li>highlighting its main applications in the field.</li>
</ol>
</blockquote>
<blockquote>
<p>To do so, some basic code and steps will be provided to the reader to get familiar with such approach. Throughout this chapter, some more specialized resources is provided for those who have the courage and motivation to dig deeper into this topic.</p>
</blockquote>
<div id="introduction-2" class="section level2 hasAnchor" number="12.1">
<h2><span class="header-section-number">12.1</span> Introduction<a href="machine-learning.html#introduction-2" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Machine Learning is currently a hot topic in the sensory and consumer science field. It is one of the most game-changing technological advancements to support CPG companies in the development of new products, playing a considerable role in speeding up (and at the same time reducing the costs) the steps involved in the R&amp;D process. In today‚Äôs fast-moving and increasingly competitive corporate world, companies that are embracing, adopting and opening their minds to digital transformation and artificial intelligence (AI), moving towards the age of automation, are not one but many steps ahead of their competitors.</p>
<p>Machine Learning (ML) is a branch of AI, which is based on the idea that systems can learn from data, and that has the capability to evolve. Generally speaking, ML refers to various programming techniques that are able to process large amounts of data and extract useful information from it. It refers to a method of data analysis that build intelligent algorithms that can automatically improve through the experience gained from the data and identify patterns or make decisions with minimal human intervention, without being explicitly programmed. ML focuses on using data and algorithms to mimic the way humans learn, gradually improving their accuracy.</p>
<p>The definition of the objectives or the situation where ML would bring value refers to the very first step of the process. Once that is clear, the next step is to collect data or dig into the historical data sets to understand what information is available and/or has to be obtained. The data varies according to the situation, but it may refer to product composition or formulation, instrumental measurements (e.g., pH, color, rheology, GCMS, etc.), sensory attributes (e.g., creaminess, sweetness, bitterness, texture, consistency, etc.), or consumer behavior (e.g., frequency of consumption/use, consumption/use situation, etc.), demographics (e.g., age, gender, skin type, etc.) and consumer responses (e.g.¬†liking, CATA questions, JAR questions, etc.).</p>
<p>The data set size and quality are very important as they impact directly the model‚Äôs robustness. Specific recommendations on that according to the situation, data type, and objectives are as following: In general, the higher the number of objects (usually the number of samples) the better, 12-15 being the minimum recommended. The number of measurements (instrumental, sensory and/or consumer measurements) and the number of consumers evaluating the products are also very relevant to the model‚Äôs quality. In sensory and consumer science studies, the number of measurements is usually sufficient, so nothing to worry about here. In practice, it is recommended to have a minimum of 100 consumers, although the more the better. Regarding data quality, one of the most important aspects (besides the standardization of data collection) corresponds to the variability of the samples. The larger the variability between samples, the broader the space the model will cover. Additionally, it is strongly recommended to capture the consumers‚Äô individual differences, not only through demographic information, but also through Just About Right (JAR) or Ideal Profile Method (IPM) questions. Ultimately, within-subject design (sequential monadic design) provide better quality models.</p>
<p>Depending on the aims of the analysis, there are some variations on how to group or classify ML algorithms. They can be divided into three prominent methods: supervised learning, unsupervised learning, and reinforcement learning. In this section, we mainly focus on the first two approaches.</p>
</div>
<div id="machine-learning-methods" class="section level2 hasAnchor" number="12.2">
<h2><span class="header-section-number">12.2</span> Machine Learning Methods<a href="machine-learning.html#machine-learning-methods" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Supervised learning is the most popular type of machine learning that uses labeled data, it is a process that involves providing input data as well as correct output data to the machine learning model. The ultimate goal of the algorithm is to find a mapping function to map input variables with output variables. In supervised learning, models are initially trained using a subset of the data (training data set) and afterwards, the model is tested and validated using the other part of the data (test data set and validation data set). Once this process is done, the model can continuously improve, discovering new patterns and relationships as it trains itself on new data sets.</p>
<p>A very common situation where supervised learning is widely used is to predict consumer responses (E.g., Liking, Perception, Benefit) based on analytical measurements and/or sensory data. In this situation, ML models can provide insights and directions on how to improve product performance and has also the ability to predict consumer response based on analytical and/or sensory data, working as a powerful screening tool where only prototypes or products with the highest potential are moved to the next level, which may be the consumer testing. Another common situation is the use of supervised machine learning to predict product sensory profile or consumer response, based on the formulation or ingredients of a product. In this situation, the ML would be of great support for the developers, who can much easier understand and get clear directions on what has to be changed in the formulation to improve the product sensory profile or consumer performance.</p>
<p>Unlike supervised learning, unsupervised learning uses unlabeled or untagged data, which means inputs where the output values are not known. In this case, users do not need to supervise the model, instead, the algorithm operates independently to finds patterns and trends, trying to learn from the data distribution the distinguishing features and associations through similarity and dissimilarity measurements. Its ability to discover hidden patterns and get similarities/differences information is what make it the ideal solution for exploratory analysis and consumer segmentation, extracting insights from the data sets.</p>
<p>Unsupervised machine learning is commonly used to segment consumers into groups based on their similarities related to a variety of factors such as shopping or usage behavior, attitudes, interests, liking or preferences. As consumers in the same market segment tend to respond similarly, the segmentation process is a key strategy for companies to understand and tailor effectively their products or marketing approaches for different target groups. Similarly, unsupervised models are also very used to classify group of products in homogeneous analytical, sensory and/or consumer attributes in order to identify different segments in the market.</p>
<p>Let‚Äôs get started by Unsupervised learning first.</p>
<div id="unsupervised-learning" class="section level3 hasAnchor" number="12.2.1">
<h3><span class="header-section-number">12.2.1</span> Unsupervised learning<a href="machine-learning.html#unsupervised-learning" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>In the sensory and consumer science field, unsupervised learning models are usually used for Clustering and Dimensionality Reduction.</p>
<p>Clustering is a technique used to discover in a high-dimensional data, groups of observations that are similar to each other and significantly different from the rest. In other words, it is a method that groups unlabeled data based on their similarities and differences in the way that objects with most similarities remains into a group and has less or no similarities with the objects of another group. As previously mentioned, a very common application is to cluster consumers and classify groups of products based on their similarities/dissimilarities. Clustering algorithms can be categorized into a few types, which are Exclusive (E.g. k-means), Hierarchical and Probabilistic clustering (E.g. Gaussian Mixture Model). The first two are the ones most used and well known in the sensory field.</p>
<p>Dimensionality reduction is a technique used to transform a high dimensional space into a low-dimensional space that retains some meaningful properties of the original data. It refers to the process of reducing the number of features/attributes in a data set while maintaining as much of the variation as possible. This method is a important not only as a technique for data visualization, but also as a pre processing step to reduce training time and computational resources, improve ML algorithms performance/accuracy due to less misleading data, avoid problems of overfitting, find latent variables, remove redundant features and noise, among others. There are numerous dimensionality reduction methods that can be used according to the data type and different requirements. The most common and well known dimensionality reduction methods used in the sensory and consumer science field are the ones that apply linear transformations, including Principal Components Analysis (PCA) and Factor Analysis (FA).</p>
<div id="clustering-and-dimensionality-reduction" class="section level4 hasAnchor" number="12.2.1.1">
<h4><span class="header-section-number">12.2.1.1</span> Clustering and Dimensionality Reduction<a href="machine-learning.html#clustering-and-dimensionality-reduction" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Let‚Äôs start installing/loading the necessary packages and by preparing the dataset for the cluster analysis, with PCA being used as a pre processing method. We will be using a wine dataset, from <code>rattle</code> package, that consists of the results of a chemical analysis of wines grown in a specific area of Italy. Three types of wine are represented in the 178 samples, with the results of 13 chemical analyses recorded for each sample.</p>
<div class="sourceCode" id="cb395"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb395-1"><a href="machine-learning.html#cb395-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span>
<span id="cb395-2"><a href="machine-learning.html#cb395-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(rattle)</span>
<span id="cb395-3"><a href="machine-learning.html#cb395-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb395-4"><a href="machine-learning.html#cb395-4" aria-hidden="true" tabindex="-1"></a><span class="co"># load data</span></span>
<span id="cb395-5"><a href="machine-learning.html#cb395-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb395-6"><a href="machine-learning.html#cb395-6" aria-hidden="true" tabindex="-1"></a>wine.fl <span class="ot">&lt;-</span> <span class="st">&quot;http://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data&quot;</span></span>
<span id="cb395-7"><a href="machine-learning.html#cb395-7" aria-hidden="true" tabindex="-1"></a>wine <span class="ot">&lt;-</span> <span class="fu">read.csv</span>(wine.fl,<span class="at">header =</span> F)</span>
<span id="cb395-8"><a href="machine-learning.html#cb395-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb395-9"><a href="machine-learning.html#cb395-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Names of the variables</span></span>
<span id="cb395-10"><a href="machine-learning.html#cb395-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb395-11"><a href="machine-learning.html#cb395-11" aria-hidden="true" tabindex="-1"></a>wine.names<span class="ot">=</span><span class="fu">c</span>(<span class="st">&quot;Alcohol&quot;</span>, <span class="st">&quot;Malic acid&quot;</span>, <span class="st">&quot;Ash&quot;</span>, <span class="st">&quot;Alcalinity of ash&quot;</span>, <span class="st">&quot;Magnesium&quot;</span>,</span>
<span id="cb395-12"><a href="machine-learning.html#cb395-12" aria-hidden="true" tabindex="-1"></a>             <span class="st">&quot;Total phenols&quot;</span>, <span class="st">&quot;Flavanoids&quot;</span>, <span class="st">&quot;Nonflavanoid phenols&quot;</span>, <span class="st">&quot;Proanthocyanins&quot;</span>,</span>
<span id="cb395-13"><a href="machine-learning.html#cb395-13" aria-hidden="true" tabindex="-1"></a>             <span class="st">&quot;Color intensity&quot;</span>, <span class="st">&quot;Hue&quot;</span>, <span class="st">&quot;OD280/OD315 of diluted wines&quot;</span>, <span class="st">&quot;Proline&quot;</span>)</span>
<span id="cb395-14"><a href="machine-learning.html#cb395-14" aria-hidden="true" tabindex="-1"></a><span class="fu">colnames</span>(wine)[<span class="dv">2</span><span class="sc">:</span><span class="dv">14</span>]<span class="ot">=</span>wine.names</span>
<span id="cb395-15"><a href="machine-learning.html#cb395-15" aria-hidden="true" tabindex="-1"></a><span class="fu">colnames</span>(wine)[<span class="dv">1</span>]<span class="ot">=</span><span class="st">&quot;Wine_type&quot;</span></span>
<span id="cb395-16"><a href="machine-learning.html#cb395-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb395-17"><a href="machine-learning.html#cb395-17" aria-hidden="true" tabindex="-1"></a>wine_dataset <span class="ot">&lt;-</span> <span class="fu">tibble</span>(wine)</span></code></pre></div>
<p>Dimensionality reduction technique via PCA will be applied before clustering to allow coherent patterns to be detected more clearly. As well known, PCA retains most of the information/variance of the data set and by removing features with low variance, a more robust clustering can be generated. In other words, this technique reveals distinct groups if data exhibits clustering and by retaining the components with the highest variance, the clusters tends to be more visible.</p>
<p>As the data set being used contain variables with different units/scales, PCA with scaling will be applied. We will be using the <code>{FactoMineR}</code> package to perform the PCA analysis and <code>{factoextra}</code> to easily extract and visualize the results.</p>
<div class="sourceCode" id="cb396"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb396-1"><a href="machine-learning.html#cb396-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span> (FactoMineR)</span>
<span id="cb396-2"><a href="machine-learning.html#cb396-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span> (factoextra)</span>
<span id="cb396-3"><a href="machine-learning.html#cb396-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb396-4"><a href="machine-learning.html#cb396-4" aria-hidden="true" tabindex="-1"></a>pca_results <span class="ot">&lt;-</span> <span class="fu">PCA</span>(wine_dataset, <span class="at">scale.unit =</span> <span class="cn">TRUE</span>)</span>
<span id="cb396-5"><a href="machine-learning.html#cb396-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb396-6"><a href="machine-learning.html#cb396-6" aria-hidden="true" tabindex="-1"></a>pca_eig <span class="ot">&lt;-</span> <span class="fu">fviz_eig</span>(pca_results, <span class="at">addlabels =</span> <span class="cn">TRUE</span>, <span class="at">ylim =</span> <span class="fu">c</span>(<span class="dv">0</span>,<span class="dv">50</span>))</span>
<span id="cb396-7"><a href="machine-learning.html#cb396-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb396-8"><a href="machine-learning.html#cb396-8" aria-hidden="true" tabindex="-1"></a>pca_plot <span class="ot">&lt;-</span> <span class="fu">fviz_pca_biplot</span>(pca_results, <span class="at">repel =</span> <span class="cn">TRUE</span>,</span>
<span id="cb396-9"><a href="machine-learning.html#cb396-9" aria-hidden="true" tabindex="-1"></a>                            <span class="at">label =</span> <span class="st">&quot;var&quot;</span>,</span>
<span id="cb396-10"><a href="machine-learning.html#cb396-10" aria-hidden="true" tabindex="-1"></a>                            <span class="at">col.var =</span> <span class="st">&quot;red&quot;</span>,</span>
<span id="cb396-11"><a href="machine-learning.html#cb396-11" aria-hidden="true" tabindex="-1"></a>                            <span class="at">col.ind =</span> <span class="st">&quot;black&quot;</span>)</span>
<span id="cb396-12"><a href="machine-learning.html#cb396-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb396-13"><a href="machine-learning.html#cb396-13" aria-hidden="true" tabindex="-1"></a>pca_plot</span>
<span id="cb396-14"><a href="machine-learning.html#cb396-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb396-15"><a href="machine-learning.html#cb396-15" aria-hidden="true" tabindex="-1"></a>reduced_dataset <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(pca_results<span class="sc">$</span>ind<span class="sc">$</span>coord[, <span class="dv">1</span><span class="sc">:</span><span class="dv">2</span>]) <span class="sc">%&gt;%</span></span>
<span id="cb396-16"><a href="machine-learning.html#cb396-16" aria-hidden="true" tabindex="-1"></a>  <span class="fu">tibble</span>()</span></code></pre></div>
<p>The PCA shows that there are apparently 3 distinct groups of wines.</p>
<p>Let‚Äôs now use its results for the clustering analysis. Although agglomerative hierarchical clustering is more common in the sensory and consumer research, it was already shown in Chapter <a href="data-analysis.html#data-analysis">10</a>, so for this example we decided to use a different solution - k-means clustering. K-means clustering is also a very known unsupervised machine learning algorithm for partitioning a given data set in a way that the total intra-cluster variation is minimized. Both approaches (hierarchical clustering and k-means) are fairly used, being the main different the rule of forming clustering and the requirement to pre-specify the number of cluster to be produced the main different between them. Detailed information about clustering methods and analysis can be found in the book <em>Practical Guide to Cluster Analysis in R: Unsupervised Machine Learning</em> by Alboukadel Kassambara (<span class="citation"><a href="#ref-Kassambara2017" role="doc-biblioref">Kassambara</a> (<a href="#ref-Kassambara2017" role="doc-biblioref">2017</a>)</span>).</p>
<p>Here we use k-means clustering as an example. The first step of k-means clustering is to estimate the optimal number of clusters (k), and this can be conveniently done using the function <code>fviz_nbclust ()</code> from <code>{factoextra}</code> package. The plot represents the variance within the clusters and the bend, also called ‚Äúelbow,‚Äù indicates that additional clusters beyond the third have little value. In our situation, we will then classify the observations into 3 clusters.</p>
<div class="sourceCode" id="cb397"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb397-1"><a href="machine-learning.html#cb397-1" aria-hidden="true" tabindex="-1"></a><span class="fu">fviz_nbclust</span>(reduced_dataset, kmeans, <span class="at">method =</span> <span class="st">&quot;wss&quot;</span>)</span></code></pre></div>
<p>As the k-means algorithm starts with k randomly selected centroids, it‚Äôs recommend to initially set a seed, through the use of the function <code>set.seed ()</code>, to make reproducible results. We will then perform k-means clustering with k = 3. In the k-means function, we can also choose the number of random sets, which means the number of times R will try different random starting assignments. The default is 1, but to get more stable results we will specify nstart = 20. The function <code>fviz_cluster</code>, from <code>{factoextra}</code> package, will be used for the visualization.</p>
<div class="sourceCode" id="cb398"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb398-1"><a href="machine-learning.html#cb398-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb398-2"><a href="machine-learning.html#cb398-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb398-3"><a href="machine-learning.html#cb398-3" aria-hidden="true" tabindex="-1"></a>km_dw <span class="ot">&lt;-</span> <span class="fu">kmeans</span>(reduced_dataset, <span class="dv">3</span>, <span class="at">nstart =</span> <span class="dv">20</span>)</span>
<span id="cb398-4"><a href="machine-learning.html#cb398-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb398-5"><a href="machine-learning.html#cb398-5" aria-hidden="true" tabindex="-1"></a><span class="fu">fviz_cluster</span>(</span>
<span id="cb398-6"><a href="machine-learning.html#cb398-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">list</span>(<span class="at">data =</span> reduced_dataset, <span class="at">cluster =</span> km_dw<span class="sc">$</span>cluster),</span>
<span id="cb398-7"><a href="machine-learning.html#cb398-7" aria-hidden="true" tabindex="-1"></a>  <span class="at">ellipse.type =</span> <span class="st">&quot;norm&quot;</span>,</span>
<span id="cb398-8"><a href="machine-learning.html#cb398-8" aria-hidden="true" tabindex="-1"></a>  <span class="at">geom =</span> <span class="st">&quot;point&quot;</span>,</span>
<span id="cb398-9"><a href="machine-learning.html#cb398-9" aria-hidden="true" tabindex="-1"></a>  <span class="at">stand =</span> <span class="cn">FALSE</span></span>
<span id="cb398-10"><a href="machine-learning.html#cb398-10" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
<p>In the resulting plot, we can easily see the observation represented by points, and the color and ellipse identifying each of the 3 clusters. We suggest you to re-run the codes to define the optimal number of clustering and the cluster analysis without dimensionality reduction. You will see how patterns were detected much more clear when this technique was applied.</p>
</div>
</div>
<div id="supervised-learning" class="section level3 hasAnchor" number="12.2.2">
<h3><span class="header-section-number">12.2.2</span> Supervised learning<a href="machine-learning.html#supervised-learning" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>There are many ways to carry out supervised machine learning, and it‚Äôs by itself a big topic. We recommend reading ‚ÄúHands-On Machine Learning with R,‚Äù by Bradley Boehmke and Brandon Greewell (<a href="https://bradleyboehmke.github.io/HOML/" class="uri">https://bradleyboehmke.github.io/HOML/</a>) for more in-depth information. In sensory and consumer science, supervised learning is commonly carried out using a type of regression, where we use for instance consumer ratings as output (target), and products information (i.e.¬†sensory profiles and analytical measurement) as input.</p>
<div id="regression" class="section level4 hasAnchor" number="12.2.2.1">
<h4><span class="header-section-number">12.2.2.1</span> Regression<a href="machine-learning.html#regression" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Regression methods approximate the target variable<a href="#fn47" class="footnote-ref" id="fnref47"><sup>47</sup></a>
with (usually linear) combination of predictor variables. There are multiple regression algorithms varying by type of data they can handle, type of target variable and additional aspects like ability to perform
dimensionality reduction. We will take a walk through the ones most relevant for
sensory and consumer science.</p>
<p><strong>Linear regression</strong>: The simplest and most popular variant is linear regression in which continuous
target variable is approximated as linear combination of predictors in a way that
minimizes sum of squared estimates of errors (SSE). It can be for example used to
predict consumer liking of a product based on it‚Äôs sensory profile, but user has
to keep in mind that linear regression can in some cases return value outside
reasonable range of target values. This can be addressed by capping predictions
to desired range. Functions in R to apply linear regression are: <code>lm()</code> and <code>glm()</code>
or <code>parsnip::linear_reg() %&gt;% parsnip::set_engine("lm")</code> when using <code>tidymodels</code> workflow.</p>
<p><strong>Logistic regression</strong>: Logistic regression is an algorithm which by use of logistic transformation allows
to apply the same approach as linear regression to cases with binary target variables.
It can be used in R with <code>glm(family = "binomial")</code> or
<code>parsnip::logistic_reg() %&gt;% parsnip::set_engine("glm")</code> when using <code>tidymodels</code> workflow.</p>
<p><strong>Penalized regression</strong>: It is often that the data we want to use for modeling have a lot of predictor
variables, possibly with lot of high correlations. In such cases, linear/logistic
regression may become unstable and produce unreasonable predictions. This can be
addressed by use of so called penalized regression. It is a special case where
instead of minimizing pure error term, algorithm minimizes both error and regression
coefficients at the same time. This leads to more stable predictions.</p>
<p>There are three variations of penalized regression and all of them can be accessed
via function <code>glmnet::glmnet()</code> (<span class="math inline">\(\beta\)</span> is set of regression coefficients and
<span class="math inline">\(\lambda\)</span> is a parameter to be set by user or determined from cross-validation):</p>
<ul>
<li>Ridge regression (L2 penalty) minimizes <span class="math inline">\(SSE + \lambda \sum|\beta|^2\)</span> and drives
the coefficients to smaller values</li>
<li>Lasso regression (L1 penalty) <span class="math inline">\(SSE + \lambda \sum|\beta|\)</span> and forces some of the
coefficients to vanish what can be used for variable selection</li>
<li>Elastic-net regression is a combination of the two previous variants
<span class="math inline">\(SSE + \lambda_1 \sum|\beta| + \lambda_2 \sum|\beta|^2\)</span>.</li>
</ul>
<p>Penalized regression can be also ran in <code>tidymodels</code> workflow with
or <code>parsnip::linear_reg() %&gt;% parsnip::set_engine("glmnet")</code>.</p>
<p><strong>MARS</strong>: One limitation of all mentioned so far methods is that they assume linear relationship
between predictor and target variables. Multivariate adaptive regression spline (MARS)
addresses this by modeling non-linearities with piece wise linear function. This
gives a nice balance between simplicity and ability to fit complex data, for example
<span class="math inline">\(\Lambda\)</span>-shaped once where there is a maximal point from which function decreases
in both directions. In R this model can be accessed via <code>earth::earth()</code> function.</p>
<p><strong>PLS</strong>: In case of multiple target variables one can apply partial least squares (PLS) regression
which, similarly to PCA looks for components that maximizes explained variance of
the predictors, but at the same time also maximizes their correlation to target variables.
PLS can be applied with <code>lm()</code> specifying multiple targets or in <code>tidymodels</code> workflow
with <code>plsmod::pls() %&gt;% parsnip::set_engine("mixOmics")</code>.</p>
<p>There are many other ways to perform machine learning as well. Below is some brief introduction of them.</p>
</div>
<div id="k-nearest-neighbors" class="section level4 hasAnchor" number="12.2.2.2">
<h4><span class="header-section-number">12.2.2.2</span> K-nearest neighbors<a href="machine-learning.html#k-nearest-neighbors" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>A very simple, yet useful and robust algorithm that works for both numeric and nominal
target variables is K-nearest neighbors. The idea is that for every new observation
we want to predict the algorithms finds K closest points in training set and use
either their mean value (for numeric targets) or most frequent value (for nominal targets) as prediction. This algorithm can be used with <code>kknn::kknn()</code> function or in <code>tidymodels</code> workflow
with <code>parsnip::nearest_neighbor() %&gt;% parsnip::set_engine("kknn")</code>.</p>
</div>
<div id="decision-trees" class="section level4 hasAnchor" number="12.2.2.3">
<h4><span class="header-section-number">12.2.2.3</span> Decision trees<a href="machine-learning.html#decision-trees" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Decision tree models the data by splitting the training set in smaller subsets
in a way that each split is done by a predictor variable so that it maximizes
the difference in target variable between the subsets. One important advantage
of decision trees is that they can model complex relationships and interactions
between predictors. To use decision tree in R one can use <code>rpart::rpart()</code> or
in <code>tidymodels</code> workflow with <code>parsnip::decision_tree() %&gt;% parsnip::set_engine("rpart")</code>.</p>
</div>
<div id="black-boxes" class="section level4 hasAnchor" number="12.2.2.4">
<h4><span class="header-section-number">12.2.2.4</span> Black boxes<a href="machine-learning.html#black-boxes" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>So called black boxes are class of models that have too complex structure to directly
interpret relationship between predictor variables and a value predicted by the model.
Their advantage usually is ability to model more complicated data than in case of
interpretable models, but they have greater risk of overfitting (fitting to
noise in training data). Also, lack of clear interpretation may be not acceptable
in some business specific use cases. The later problem can be addressed by use of
explanation algorithms that will be discussed in later part of this chapter.</p>
</div>
<div id="random-forests" class="section level4 hasAnchor" number="12.2.2.5">
<h4><span class="header-section-number">12.2.2.5</span> Random forests<a href="machine-learning.html#random-forests" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>A random forest is a set of decision trees, each one trained on random subset
of observations and/or predictors. The final prediction is an average of individual
trees‚Äô predictions, in the way that increasing the number of trees increases the precision
of the outcome. A random forest minimize the limitations of a decision tree algorithm,
reducing the overfitting of datasets and increasing precision.</p>
</div>
</div>
<div id="practical-guide-to-machine-learning" class="section level3 hasAnchor" number="12.2.3">
<h3><span class="header-section-number">12.2.3</span> Practical Guide to Machine Learning<a href="machine-learning.html#practical-guide-to-machine-learning" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Now that we have a general idea of machine learning approach, we will try to build a simple machine learning model in the sensory and consumer context.</p>
<p>R contains fantastic systems for building machine learning models. The tidymodels framework (<a href="https://www.tidymodels.org/" class="uri">https://www.tidymodels.org/</a>) is a collection of packages for modeling and machine learning using tidyverse principles, and among one of the most popular framework in R for machine learning. In this context, we strongly recommend the book ‚ÄúTidy Modeling with R,‚Äù by Max Kuhn and Julia Silge (<a href="https://www.tmwr.org/" class="uri">https://www.tmwr.org/</a>).</p>
<p>Tidymodels contains several core packages, including <code>rsample</code>, <code>parsnip</code>, <code>recipes</code>, <code>workflows</code>, <code>tune</code>, <code>yardstick</code>, <code>broom</code> and <code>dials</code>, along with some other specialized packages. These packages will help you build a variety of models in R and check their performances.</p>
<p>Just like tidyverse, you don‚Äôt need to install/load all the packages separately, installing/loading <code>{tidymodel}</code> will load all the packages you will need for building machine learning models.</p>
<div class="sourceCode" id="cb399"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb399-1"><a href="machine-learning.html#cb399-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidymodels)</span></code></pre></div>
<p>We will still use the wine data set to build our supervised model using the <code>tidymodel</code> packages. Let‚Äôs prepare the data before we go to details for modeling.</p>
<div id="preparing-data-for-ml" class="section level4 hasAnchor" number="12.2.3.1">
<h4><span class="header-section-number">12.2.3.1</span> Preparing data for ML<a href="machine-learning.html#preparing-data-for-ml" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>First we need to mutate the column ‚ÄúWine_type‚Äù to be factors, as this column would be the target later.</p>
<div class="sourceCode" id="cb400"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb400-1"><a href="machine-learning.html#cb400-1" aria-hidden="true" tabindex="-1"></a>wine_classification_dataset <span class="ot">&lt;-</span> wine_dataset <span class="sc">%&gt;%</span> </span>
<span id="cb400-2"><a href="machine-learning.html#cb400-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">Wine_type =</span> <span class="fu">as.factor</span>(Wine_type))</span></code></pre></div>
</div>
<div id="sampling-the-data" class="section level4 hasAnchor" number="12.2.3.2">
<h4><span class="header-section-number">12.2.3.2</span> Sampling the data<a href="machine-learning.html#sampling-the-data" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>The function <code>rsample::initial_split()</code> takes the original data and saves the information on how to make the partitions. We set the <code>strata</code> argument as <code>"Wine_type"</code> to conduct a stratified split. This ensures our training and test data sets would keep roughly the same proportions of all wine types as in the original data, despite the imbalance we noticed in our class variable. <code>prop</code> is set to 0.7 as we are splitting data to be 70% for training and 30% for testing.</p>
<p>After the initial_split, we can use the training() and testing() functions to obtain the two data frames for training and testing.</p>
<div class="sourceCode" id="cb401"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb401-1"><a href="machine-learning.html#cb401-1" aria-hidden="true" tabindex="-1"></a>initial_split <span class="ot">&lt;-</span> <span class="fu">initial_split</span>(<span class="at">data =</span> wine_classification_dataset, <span class="at">strata =</span> <span class="st">&quot;Wine_type&quot;</span>, <span class="at">prop =</span> <span class="fl">0.7</span>)</span>
<span id="cb401-2"><a href="machine-learning.html#cb401-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb401-3"><a href="machine-learning.html#cb401-3" aria-hidden="true" tabindex="-1"></a>wine_train <span class="ot">&lt;-</span> <span class="fu">training</span>(initial_split)</span>
<span id="cb401-4"><a href="machine-learning.html#cb401-4" aria-hidden="true" tabindex="-1"></a>wine_testing <span class="ot">&lt;-</span> <span class="fu">testing</span>(initial_split)</span></code></pre></div>
</div>
<div id="cross-validation" class="section level4 hasAnchor" number="12.2.3.3">
<h4><span class="header-section-number">12.2.3.3</span> Cross Validation<a href="machine-learning.html#cross-validation" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Cross-validation is an important step for checking the model quality later. To do that, we need to use the resampling method to create a series of data sets similar to the training/testing split before building the model. For each data set, a subset is used for creating the model, and the other subset is used to measure the performance. Also noted that resampling is always used with the training set of the data defined earlier.</p>
<p>We use <code>vfold_cv</code> to resample the data. Here we begin with a 5-fold cross-validation first. <code>strata</code> is set to <code>wind_type</code> to conduct stratified sampling, so that each resample is created within the stratification variable.</p>
<div class="sourceCode" id="cb402"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb402-1"><a href="machine-learning.html#cb402-1" aria-hidden="true" tabindex="-1"></a>wine_cv <span class="ot">&lt;-</span> wine_train <span class="sc">%&gt;%</span> <span class="fu">vfold_cv</span>(<span class="at">v =</span> <span class="dv">5</span>,<span class="at">strata =</span> Wine_type)</span></code></pre></div>
<p>Now we have a resampled <code>wine_cv</code> for further building the model.</p>
</div>
<div id="choose-ml-method-using-recipe" class="section level4 hasAnchor" number="12.2.3.4">
<h4><span class="header-section-number">12.2.3.4</span> Choose ML method using ‚Äúrecipe‚Äù<a href="machine-learning.html#choose-ml-method-using-recipe" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>The recipe package is part of <code>tidymodels</code>. It contains a rich set of data manipulation tools which can be used to preprocess data and to define roles for each variable (e.g.¬†outcome and predictor). To add a recipe, we simply use the function <code>recipe</code>. <code>recipe</code> has two arguments: a formula and the data. Any variable on the left-hand side of the tilde (~) is considered the model outcome. In our example, we want to use machine learning model to predict the type of the wine, therefore <code>Wine_type</code> would be the target on the left hand side of the <code>~</code>. On the right-hand side of the tilde are the predictors. One can write out all the variables, but an easier option is to use the dot (.) to indicate all other variables as predictors.</p>
<div class="sourceCode" id="cb403"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb403-1"><a href="machine-learning.html#cb403-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Random forest model definition</span></span>
<span id="cb403-2"><a href="machine-learning.html#cb403-2" aria-hidden="true" tabindex="-1"></a>model_recipe <span class="ot">&lt;-</span> wine_train <span class="sc">%&gt;%</span> </span>
<span id="cb403-3"><a href="machine-learning.html#cb403-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">recipe</span>(Wine_type <span class="sc">~</span> .)</span></code></pre></div>
<p>We will use here random forest classifier for the wine data. <code>rand_forest</code> has 3 hyper-parameters (<code>mtry, trees, min_n</code>) which can be tuned to achieve the best results.</p>
<p>We set all of them as <code>tune()</code> right now. Model tuning is the process to find the best values for the parameters. Most often you start with the default values, and change them along the way. Since the model is not executing when created, these parameters can be changed using the tune() function. This provides a simple placeholder for the value.</p>
<div class="sourceCode" id="cb404"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb404-1"><a href="machine-learning.html#cb404-1" aria-hidden="true" tabindex="-1"></a>rf_spec <span class="ot">&lt;-</span> <span class="fu">rand_forest</span>(</span>
<span id="cb404-2"><a href="machine-learning.html#cb404-2" aria-hidden="true" tabindex="-1"></a>  <span class="at">mtry =</span> <span class="fu">tune</span>(),</span>
<span id="cb404-3"><a href="machine-learning.html#cb404-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">trees =</span> <span class="fu">tune</span>(),</span>
<span id="cb404-4"><a href="machine-learning.html#cb404-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">min_n =</span> <span class="fu">tune</span>()) <span class="sc">%&gt;%</span></span>
<span id="cb404-5"><a href="machine-learning.html#cb404-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">set_mode</span>(<span class="st">&quot;classification&quot;</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb404-6"><a href="machine-learning.html#cb404-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">set_engine</span>(<span class="at">engine =</span> <span class="st">&quot;ranger&quot;</span>)</span></code></pre></div>
</div>
<div id="set-the-whole-process-into-a-workflow" class="section level4 hasAnchor" number="12.2.3.5">
<h4><span class="header-section-number">12.2.3.5</span> Set the whole Process into a workflow<a href="machine-learning.html#set-the-whole-process-into-a-workflow" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Let‚Äôs combine the model and recipe into a single <code>workflow ()</code> object to better manage the two R objects.</p>
<div class="sourceCode" id="cb405"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb405-1"><a href="machine-learning.html#cb405-1" aria-hidden="true" tabindex="-1"></a>rf_wf <span class="ot">&lt;-</span> <span class="fu">workflow</span>() <span class="sc">%&gt;%</span></span>
<span id="cb405-2"><a href="machine-learning.html#cb405-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">add_recipe</span>(model_recipe) <span class="sc">%&gt;%</span> </span>
<span id="cb405-3"><a href="machine-learning.html#cb405-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">add_model</span>(rf_spec)</span></code></pre></div>
</div>
<div id="tuning-the-parameters" class="section level4 hasAnchor" number="12.2.3.6">
<h4><span class="header-section-number">12.2.3.6</span> Tuning the parameters<a href="machine-learning.html#tuning-the-parameters" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>We created placeholders for tuning hyper-parameters earlier. Now it‚Äôs time to define the scope of the search and choose the method for searching the parameter space, in this case it is <code>grid_regular</code>.</p>
<div class="sourceCode" id="cb406"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb406-1"><a href="machine-learning.html#cb406-1" aria-hidden="true" tabindex="-1"></a>params_grid <span class="ot">&lt;-</span> rf_spec <span class="sc">%&gt;%</span></span>
<span id="cb406-2"><a href="machine-learning.html#cb406-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">parameters</span>() <span class="sc">%&gt;%</span></span>
<span id="cb406-3"><a href="machine-learning.html#cb406-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">update</span>(<span class="at">mtry =</span> <span class="fu">mtry</span>(<span class="at">range =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">2</span>)),</span>
<span id="cb406-4"><a href="machine-learning.html#cb406-4" aria-hidden="true" tabindex="-1"></a>         <span class="at">trees =</span> <span class="fu">trees</span>(<span class="at">range =</span> <span class="fu">c</span>(<span class="dv">10</span>, <span class="dv">200</span>))) <span class="sc">%&gt;%</span> </span>
<span id="cb406-5"><a href="machine-learning.html#cb406-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">grid_regular</span>(<span class="at">levels =</span> <span class="dv">5</span>)</span></code></pre></div>
<p>Now that We have defined the hyper-parameter search range, let‚Äôs look for the best combination using <code>tune_grid()</code> function. We will leave the test set aside, and use a cross-validation set for this purpose, so that the model during training certainly will not see the data on which we will be making predictions.</p>
<p>We can use <code>autoplot()</code> function to take a quick look at the <code>tuning</code> object.</p>
<p>Next, we will obtain a reliable estimate of the quality of the model. We first select the best combination of parameters using <code>select_best()</code> function. The quality of the model can be estimated with a number of metrics. Here we decided to use <code>roc_auc</code> (Area Under the Receiver Operating Characteristic Curve).</p>
<div class="sourceCode" id="cb407"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb407-1"><a href="machine-learning.html#cb407-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Best parameters searching</span></span>
<span id="cb407-2"><a href="machine-learning.html#cb407-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb407-3"><a href="machine-learning.html#cb407-3" aria-hidden="true" tabindex="-1"></a>tuning <span class="ot">&lt;-</span> <span class="fu">tune_grid</span>(</span>
<span id="cb407-4"><a href="machine-learning.html#cb407-4" aria-hidden="true" tabindex="-1"></a>  rf_wf,</span>
<span id="cb407-5"><a href="machine-learning.html#cb407-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">resamples =</span> wine_cv,</span>
<span id="cb407-6"><a href="machine-learning.html#cb407-6" aria-hidden="true" tabindex="-1"></a>  <span class="at">grid =</span> params_grid</span>
<span id="cb407-7"><a href="machine-learning.html#cb407-7" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb407-8"><a href="machine-learning.html#cb407-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb407-9"><a href="machine-learning.html#cb407-9" aria-hidden="true" tabindex="-1"></a><span class="fu">autoplot</span>(tuning)</span>
<span id="cb407-10"><a href="machine-learning.html#cb407-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb407-11"><a href="machine-learning.html#cb407-11" aria-hidden="true" tabindex="-1"></a>params_best <span class="ot">&lt;-</span> <span class="fu">select_best</span>(tuning, <span class="st">&quot;roc_auc&quot;</span>)</span></code></pre></div>
</div>
<div id="train-the-final-model" class="section level4 hasAnchor" number="12.2.3.7">
<h4><span class="header-section-number">12.2.3.7</span> Train the final model<a href="machine-learning.html#train-the-final-model" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Now that we have found the best parameters for the model, we can train the final model on the entire training set.</p>
<div class="sourceCode" id="cb408"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb408-1"><a href="machine-learning.html#cb408-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Finalize model </span></span>
<span id="cb408-2"><a href="machine-learning.html#cb408-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb408-3"><a href="machine-learning.html#cb408-3" aria-hidden="true" tabindex="-1"></a>final_model <span class="ot">&lt;-</span> rf_wf <span class="sc">%&gt;%</span></span>
<span id="cb408-4"><a href="machine-learning.html#cb408-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">finalize_workflow</span>(params_best) <span class="sc">%&gt;%</span></span>
<span id="cb408-5"><a href="machine-learning.html#cb408-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">fit</span>(wine_train)</span></code></pre></div>
</div>
<div id="assess-the-model-quality" class="section level4 hasAnchor" number="12.2.3.8">
<h4><span class="header-section-number">12.2.3.8</span> Assess the model quality<a href="machine-learning.html#assess-the-model-quality" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>A very important part in building machine learning models is to assess the quality of the models. To do so, first we can use the model to predict on the testing data set (<code>wine_testing</code>), which the model has not seen yet.</p>
<p><code>predict</code> is a generic function for putting the prediction results from models to convenient tables for further analysis. We combine the <code>wine_testing</code> data with the column of predicted Wine_type from the model by adding the <code>predict(final_model, wine_testing)</code>in the pipe.</p>
<div class="sourceCode" id="cb409"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb409-1"><a href="machine-learning.html#cb409-1" aria-hidden="true" tabindex="-1"></a>validation_data_pred <span class="ot">&lt;-</span> wine_testing <span class="sc">%&gt;%</span></span>
<span id="cb409-2"><a href="machine-learning.html#cb409-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">bind_cols</span>(<span class="fu">predict</span>(final_model, .))</span></code></pre></div>
<p>The <code>validation_data_pred</code> is a data frame with testing data with <code>Wine_type</code> as the actual wine type, and a <code>.pred_class</code> column as the predicted Wind_type at the end. Now we can finally judge the quality of the model by comparing them.</p>
<p>A very pleasant method for visualize the classification results is to use a confusion matrix. Confusion matrix is a table where each row represents instances in the actual class, while each column represents the instances in a predicted class. Using the <code>autoplot()</code> function, We can see that in our wine type prediction, it‚Äôs almost a 100% match!</p>
<div class="sourceCode" id="cb410"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb410-1"><a href="machine-learning.html#cb410-1" aria-hidden="true" tabindex="-1"></a>cm <span class="ot">&lt;-</span> <span class="fu">conf_mat</span>(validation_data_pred, Wine_type, .pred_class)</span>
<span id="cb410-2"><a href="machine-learning.html#cb410-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb410-3"><a href="machine-learning.html#cb410-3" aria-hidden="true" tabindex="-1"></a><span class="fu">autoplot</span>(cm, <span class="at">type =</span> <span class="st">&quot;heatmap&quot;</span>)</span></code></pre></div>

</div>
</div>
</div>
</div>
<h3>Bibliography<a href="bibliography.html#bibliography" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-Kassambara2017" class="csl-entry">
Kassambara, Alboukadel. 2017. <em>Practical Guide to Cluster Analysis in r: Unsupervised Machine Learning</em>. 1st ed. CreateSpace Independent Publishing Platform.
</div>
</div>
<div class="footnotes">
<hr />
<ol start="47">
<li id="fn47"><p>This is a bit of simplification.
In some cases it is some transformation of combination of predictors that
approximates target variable. An example of this is logistic regression.<a href="machine-learning.html#fnref47" class="footnote-back">‚Ü©Ô∏é</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="value-delivery.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="text-analysis.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["i2ds4scc_bookdown.pdf", "i2ds4scc_bookdown.epub"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "section"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>

```{r include=FALSE}
knitr::opts_chunk$set(echo = TRUE, eval = FALSE)
```
# Automated Reporting {#auto-report}

## What and why Automated Reporting?

Effective communication of results is amongst the essential duties of sensory scientists...and so is the data collection, data preparation, data analysis etc. Worst, the sometimes tedious mechanics of report production together with the sheer volume of data that many scientists must process combine to make reporting design and nice story-telling an afterthought in too many cases.
Although this should preferably not be happening, it is necessary sometimes as presentation deadlines approach and time becomes limited. 

Add to this work-load some last-minute changes due to either a change in the data, in the analysis, or maybe an error (e.g. copy/paste the wrong column, etc.) you have just been detected...how can we be sure that the latest version of the report is fully up-to-date, and that all the results/conclusions are correct? As the statistical software (e.g. R) is often separated from the reporting tool (e.g. Microsoft Office), it is easy to miss to transfer updated statistical outputs (e.g. values, tables, figures, etc.) to the report, hence creating inconsistencies.

Let's consider another scenario, in which all the preliminary steps have been successfully done: you are now presenting your report to your manager or clients, and they come with a question such as: "Can we deep-dive into the results by looking at a particular group of consumers (e.g. gender split, or cluster split)?" Do you feel like going through the entire process again?

How would you feel if we would tell you that there is a way to build your report while running the analysis, by using the same script file? This means that in few clicks, say after updating the data to analyze (e.g. filter to the target group of consumers only), your report gets automatically re-generated with all the new updated results. Will you be interesting in such approach?

Such solution seems ideal since it increases efficiency while reducing errors due to manual processing of results. More importantly, this gain in time and effort allow you designing nicer slides and building a better story. 


## Integrating reports within analyses scripts

In this section, let's integrate our report building process within our data analysis. By doing so, we do not focus on building a story yet. Instead, we improve our way of working by exporting directly all the statistical outputs that could^[We say *could* as we are in a process of mass-exportation of results, most of them being used for building the story although they would not be kept in the final deck.] be useful for our future story-telling. By doing so, we increase efficiency (especially if code can then be re-used for other studies) by *killing two birds with one stone*: We simultaneously run our analysis, create usable content for our final presentation, while reducing errors due to manual processing.

Since Microsoft Office is often the tool used for sharing results, we will focus our attention in exporting results to Excel, PowerPoint, and Word. 

<!-- 
Integrating reporting within the analysis part, or integrating the analysis within the reporting part?
 -> Improved WoW
 -> Connection analysis/report reduce risks of mistakes (copy/paste updated values/tables, etc.)
 -> Keep track of what has been done (reproducible research): Explain choices for analysis, table presentation, charts
 -> Sharing code/analysis
 -> Gain in time/efficiency
 -> Massive slide production
 -> Less time require for analysis/slides production, more time for design/story-telling
To improve way of work (efficiency) and to keep track of steps taken along the way
-->


<!--  --------------------------------- Excel ---------------------------------  -->

### Excel

Although Excel is not our preferred tool for automated reporting, it is still one of the major ways to access and share data. Most data collection software offer the possibility to export data and results in Excel, while most data analysis software accept Excel format as inputs.  With the large use of Excel, it is no surprise that many of our colleagues or clients like to share data and results using spreadsheets. It is even less a surprise that R provides multiple solutions to import/export results from/to Excel. 

For importing Excel files, we have already presented the package `{readxl}` among others (see REF). For exporting results, two complementary packages (yet again, among others!) in terms of ease of use and flexibility in the outcome are proposed: `{writexl}` and `{openxlsx}`.

As its name suggests, `{writexl}` is dedicated to exporting tables to Excel through the `write_xlsx()` function. Its use is very simple as it only takes as inputs the table (or list of tables)^[List of tables will generate multiple sheets within the same spreadsheet, one table being placed in each sheet.] to export to the file specified in the `path` parameter. 

Let's illustrate this by using our *Sensory Profile.xlsx* file: Let's imagine that we would like to reduce our data set by only considering products that are high in Protein:


```{r}
library(tidyverse)
library(readxl)
library(writexl)
library(dplyr)

file_path <- file.path("data", "Sensory Profile.xlsx")

product_info <- read_excel(path  = file_path,
                           sheet = "Product Info",
                           range = "A1:D12",
                           col_names = TRUE)

# Selecting Products with High Protein
high_prot <- product_info %>% 
  filter(Protein %in% "High") %>% 
  pull(Product)

# Filter Data to only keep Products with High Protein
high_prot_data <- read_xlsx(path = file_path,
                  sheet = "Data") %>% 
  filter(Product %in% high_prot)

# Exporting Table to Excel
write_xlsx(data, 
           path = file.path("output", "High Protein Products only.xlsx"),
           col_names = TRUE)

```

The export of tables using the `{writexl}` package is easy, yet simplistic as it does not allow formatting the tables (except for some minor possibilities for the header), nor does it allow exporting multiple tables within the same sheet. For more advanced exporting options, the use of **{openxlsx}** package is preferred as it allows more flexibility in structuring and formatting the Excel output.

With `{openxlsx}`, the procedure starts with creating a workbook object (e.g. `wb`) using the `createWorkbook()` function. We can add worksheets to `wb` through the `addWorksheet()` function. 

```{r}
library(openxlsx)

# Create workbook object
wb <- openxlsx::createWorkbook()

# Add a new worksheet
addWorksheet(wb, sheetName = "Mean", gridLines = FALSE)

```


Note that `addWorksheet()` allows controlling further the appearance of the worksheet:
  * show/hide grid lines using `gridLines`;
  * color the sheet using `tabColour`;
  * change the zoom on the sheet through `zoom`;
  * show/hide the tab using `visible`;
  * format the worksheet by specifying its size (`paperSize`) and orientation (`orientation`).

On a given worksheet, any table can be exported using `writeData()` or `writeDataTable()`, which controls where to write the table through the `startRow` and `startCol` options.

Let's imagine we want to compute the sensory profiles of the products, and we want to export that into Excel. Rather then simply exporting the results, we want to customize the output a little bit by applying the Excel style named *TabelStyleLight9*:


```{r}

# Creating the Sensory Profiles with some Product Information
p_info <- read_xlsx(file_path, sheet = "Product Info") %>% 
  dplyr::select(-Type)

sensory <- read_xlsx(file_path, sheet="Data") %>% 
  inner_join(p_info, by="Product") %>% 
  relocate(Protein:Fiber, .after=Product)

senso_mean <- sensory %>% 
  pivot_longer(Shiny:Melting, names_to="Attribute", values_to="Score") %>% 
  dplyr::select(-Judge) %>% 
  pivot_wider(names_from=Attribute, values_from=Score, values_fn=mean)


# Exporting the Results to Excel
writeDataTable(wb,
               sheet = "Mean",
               x = senso_mean, 
               startCol = 1,
               startRow = 1,
               colNames = TRUE, rowNames = FALSE, 
               tableStyle = "TableStyleLight9")

openXL(wb)

```


At any time, you can visualize the Excel file that is being produced without exporting it yet using `openXL()`. This function comes very handy as it allows you checking that the output looks like what you would wish for.

As can be seen, `writeData()` and `writeDataTable()` give us a lot of control on our export. For instance, we can:
  * control where to print the data by using `startRow` and `startCol` (or alternatively `xy`: `xy = c("B",12)` prints the table starting in cell B12), hence allowing exporting multiple tables within the same sheet;
  * include the row names and column names through `rowNames` and `colNames`;
  * format the header using `headerStyle` (incl. color of the text and/or background, font, font size, etc.);
  * apply a specific style to our table using `tableStyle`;
  * shape the borders using predefined solutions through `borders`, or customizing them with `borderStyle` and `borderColour`;
  * add a filter to the table using `withFilter`;
  * convert missing data to "#N/A" or any other string using `keepNA` and `na.string`.


Rather than using some pre-defined formatting as was the case with `tableStyle`, let's consider some more advanced options in which we control (almost) everything. Let's start with setting up the formatting style we would like to apply:


```{r}

# Pre-define options to control the borders 
options("openxlsx.borderColour" = "#4F80BD")
options("openxlsx.borderStyle" = "thin")

# Automatically set Number formats to 3 values after the decimal
options("openxlsx.numFmt" = "0.0")

# Change the font to Calibri size 10
modifyBaseFont(wb,fontName = "Calibri", fontSize = 10)

# Header Style (blue background, top/bottom borders, text centered/bold)
headSty <- createStyle(fgFill = "#DCE6F1",
                       border = "TopBottom",
                       halign = "center",
                       textDecoration = "bold")

```


Note that many more formatting options can be configured through:

  * `options()` to pre-define number formatting, border colors and style, etc.;
  * `modifyBaseFont()` to define the font name and font size;
  * `freezePane()` to freeze the first row and/or column of the table;
  * `createStyle()` to pre-define a style, or `addStyle()` to apply the styling to selected cells;
  * `setColWidths` to control column width;
  * `conditionalFormatting()` to format cells based on pre-defined conditions (see next for an example). 
  
Let's export again the sensory profiles in a second sheet after applying these formatting:


```{r}
addWorksheet(wb, sheetName = "Mean (manual formatting)", gridLines = FALSE)

# Freeze first row and first column
freezePane(wb, sheet=2, firstRow=TRUE, firstCol=TRUE)

# Export the data using writeData
writeData(wb,
          sheet =2,
          x = senso_mean, 
          startCol = 1,
          startRow = 1,
          colNames = TRUE, rowNames = FALSE, 
          headerStyle = headSty)

openXL(wb)

```


You'll notice that the same table is now presented in a fairly different way. 

Let's now consider a third export of the sensory profiles, with an additional twist: for a given variable (i.e. column), the value is colored in red (resp. blue) if it is higher (resp. lower) than its mean. To do so, we need to use conditional formatting.  

Let's start with creating two pre-defined parameters called `pos_style` (red) and `neg_style` (blue) using `createStyle()`that we will use to color the different cells. Let's also compute the overall mean per attribute.


```{r openxlsx}

# Styles for conditional formatting
pos_style <- createStyle(fontColour = "firebrick3", bgFill = "mistyrose1")
neg_style <- createStyle(fontColour = "navy", bgFill = "lightsteelblue")

# Compute the overall mean
overall_mean <- senso_mean %>% 
  summarize(across(where(is.numeric), mean))

```


Let's then create a new worksheet in which we print the data of interest:

```{r}

# Add a new worksheet
addWorksheet(wb, sheetName = "Conditional Formatting", gridLines=FALSE)

# Write table: note that 
writeDataTable(wb,
               sheet = 3,
               x = senso_mean, 
               startCol = 1,
               startRow = 1,
               colNames = TRUE, rowNames = FALSE)

```


Finally, we color the cells according to the rules that was defined earlier. To do so, the decision whether `pos_style` or `neg_style` should be used is defined by the `rule` parameter from the `conditionalFormatting()`^[In `conditionalFormatting()`, you can specify to which `rows` and `cols` the formatting applies. In this example, `cols` takes `2` because the first column contains the row names.] function.


```{r}
# Adding formatting to the second column
for (v in 1:ncol(overall_mean)){
  
  conditionalFormatting(wb,
                        sheet = 3,
                        cols  = v + 3,
                        rows  = 1 + 1:nrow(senso_mean), 
                        rule  = paste0(">", overall_mean[1,v]),
                        style = pos_style)
  
  conditionalFormatting(wb,
                        sheet = 3,
                        cols  = v + 3,
                        rows  = 1 + 1:nrow(senso_mean), 
                        rule  = paste0("<", overall_mean[1,v]),
                        style = neg_style)
  
}

openXL(wb)

```


Few things should be noted: 

  * We want to run this for each sensory attribute, hence the `for` loop that goes from 1 to the number of columns stored in `overall_mean` (`overall_mean` only contains the overall mean scores for the sensory attributes);
  * `senso_mean` however contains 3 extra columns: `Product`, `Protein`, and `Fiber` hence the parameter `cols = v + 3`;
  * We apply the formatting to all the rows except the header, hence `rows = 1 + 1:nrow(senso_mean)`;
  * Finally, we apply `pos_style` (resp. `neg_style`) if the value is larger (resp. lower) than the overall mean for that attribute using `rule = paste0(">", overall_mean[1,v])`.
 

Note that once the spreadsheet is complete, we create the file using `saveWorkbook()` by specifying the name of the workbook `wb` and its path through `file`. In case such workbook already exists, it can be overwritten using `overwrite`. 

```{r}

saveWorbook(wb, file="temp/excel export.xlsx")

```


For more details on using **{openxlsx}** see <https://rdrr.io/cran/openxlsx/>.


<!--  --------------------------------- PowerPoint ---------------------------------  -->


### PowerPoint

#### Creating a PowerPoint Deck


Throughout the years, PowerPoint became one of the main support for presenting results, whether it is in academia, in conference, or in companies. It is hence important for us to show how to generate reports in PowerPoint from R directly. This can be done in different ways, yet we propose to use the `{officer}` package, as its application is vast while still remaining easy to use.


```{r}
library(officer)
```


With `{officer}`, the procedure starts with creating a PowerPoint object (`pptx_obj`) using the `read_pptx()` function. 


```{r 1.1 creating a PPT deck}

pptx_obj <- read_pptx() # new empty file

```


A blank Deck is by default set up with the *Office Theme*. To use a custom theme, we must create a Deck using the PowerPoint software and use it as input. Let's import the *intergral.pptx* template:


```{r themes2}

pptx_obj2 <- read_pptx(file.path("data", "templates", "intergral.pptx"))

```


To inspect the content of the template, we use `layout_summary()`:

```{r}

pptx_obj %>%
  layout_summary()

pptx_obj2 %>% 
  layout_summary()

```


As can be seen by `layout_summary()`, the template imported (also called **master**, which is defined here as *Office Theme*) proposes 7 types of slides including *Title Slide*, *Title and Content*, *Section Header*, *Two Content*, *Comparison*, *Title Only*, and finally *Blank* (the *intergral.pptx* template has 11 different types of slides). Each of these slides present some pre-defined properties (e.g. a box for text of tables/images, a header etc.). Let's look at the properties of *Title and Content* using `layout_properties()`


```{r}
pptx_obj %>% 
  layout_properties() %>% 
  filter(name == "Title and Content")
```


This code provides more details about the different sections, their identifier and position of the slide. This information will be particularly useful when we will want to export certain information in some particular areas.


#### Adding/Moving/Removing Slides


With `{officer}`, various actions can be done on the slides. The first logical action consists in adding a new slide to a presentation, in which we will later on write some text, tables, figures, etc. Such action can be done using `add_slide()`, in which we inform the type of slide to add, and from which master:


```{r}

master = "Office Theme"
pptx_obj <- pptx_obj %>% 
  add_slide(layout = 'Title and Content', master = master)

```


This code will add a *Title and Content* slide to your deck.

Additional operations on the slides themselves can be done. In particular, you can re-organize your deck by changing the orders of your slides using `move_slide()`, delete slides that are no longer needed through `remove_slide()`, or modify a pre-existing slides by making it active using `on_slide()` (by default, the last slide created is the active one).


#### Positioning Information to the Slide


On a given slide, any type of content (text, graph, table, etc.) can be exported. To do so, we need to inform where to write what.

As we will see in the next sections, the *what* can be any R element including simple text, tables, figures, etc. So let's ignore it for the moment, and let's focus on the *where*. 
To inform where to print elements on the slide, the function `ph_with()` (*ph* stands for *placeholder*) is used. In practice, `ph_with()` comes with the parameter `location`, which takes as input a *placeholder location object* pre-defined by the function `ph_location()` or one of its derivative, one of the most useful one being `ph_location_type()`. To do so, simply provide the name stored in the column type from the `layout_properties()` output presented before, as following:


```{r}

my_data <- c("My functions are:", "ph_with", "ph_location_type")

pptx_obj <- pptx_obj %>%
  ph_with(value = "My first title", location = ph_location_type(type = "title")) %>% 
  ph_with(value = my_data, location = ph_location_type(type = 'body'))

```


This will add a title ("My first title") and the text stored in `my_data` to the *body* of the slide (*Title and Content*) created previously.

Other pre-defined alternatives to `ph_location()` include:

 * `ph_location_fullsize()` to produce an output that covers the entire slide;
 * `ph_location_left()` and `ph_location_right()` to write in the left/right box in *Two Content* types of slide;
 * `ph_location_labe()` is similar to `ph_location_type()` except that it uses the label rather than the type.

To gain full control of the exact position of the element to print, `ph_location()` is used. It allows specifying exact positions for content (for left/top/width/height, units are inches):

```{r}

my_data <- "My new text positioned using ph_location()"

pptx_obj <- pptx_obj %>%
  add_slide(layout = "Title and Content", master = master) %>% 
  ph_with(value = my_data, location = ph_location(left = 2, top = 2, width = 3, height = 1))

```


#### Exporting Text


Each new text item added to a PowerPoint via officer is a paragraph object

`fpar()` ("formatted paragraph") creates this object

`block_list()` allows us to wrap multiple paragraphs together

`ftext()` ("formatted text") to edit the text before pasting into paragraphs. `ftext()` requires a second argument called prop which contains the formatting properties.

```{r 3.1 text1}

my_prop <- fp_text(color = "red", font.size = 14)
my_text <- ftext("First Line in Red", prop = my_prop)

my_par <- fpar(my_text) # formatted
blank_line <- fpar("") #optional

my_par2 <- fpar("Second Line") # unformatted
my_list <- block_list(my_par, blank_line, my_par2)

pptx_obj <- read_pptx() %>%
  add_slide(layout = "Title and Content", master = "Office Theme") %>% 
  ph_with(value = my_list, location = ph_location_type(type = "body") )

pptx_obj %>%
  print(target = file.path("output","example_4.pptx"))
```

For more details on using **{officer}** see <https://davidgohel.github.io/officer>.


#### Exporting Tables with `{flextable}`

`ph_with` accepts a data.frame as value and renders it in a default format

```{r 4.1 basic code}
ft_data <- senso_mean %>%
  dplyr::select(Salty, Sweet, Sour, Bitter) %>% 
  tibble::rownames_to_column() %>% 
  rename(Product = rowname) %>% 
  mutate(across(Salty:Bitter, as.numeric)) %>% 
  bind_rows(summarise(.,
                      across(where(is.numeric), mean),
                      across(where(is.character), ~"Average"))) %>% 
  mutate(across(where(is.numeric), round, 2)) 

pptx_obj <- read_pptx() %>%
  add_slide(layout = "Title and Content", master = "Office Theme") %>%
  ph_with(value = ft_data, location = ph_location_type(type = "body")) %>%
  print(target = file.path("output","table_1.pptx"))
```

##### Introduction to flextable

With `{flextable}`, the procedure starts with creating a flextable object `ft_table` using the `flextable()` function.
Flextable objects are compatible with `{officer}` and therefore are our primary tool for table formatting.
Through different functions, many custom formatting procedure can be applied:  

**key functions:**
 `align()` `bold()` `font()` `color()` `bg()` `height()` & `width()` 
 `border_outer()` & `border_inner()` & `border_inner_h()` `border_inner_v()` `autofit()`

Additional function to learn: `merge()`, `compose()` & `as_chunk()`, `style()`

```{r flextable2}
library(flextable)

# Create a flextable object
ft_table <- ft_data %>% 
  flextable()

# Flextable objects can be found in the Viewer tab of Rstudio
print(ft_table)

```

##### Formatting examples

```{r 4.4 demonstration}
ft_table <- ft_table %>%
  autofit() %>% # column width
  # alignment of header: we use part argument
  align(align = "center", part = "header") %>%
  # alignment of content: we can use part = "body" or specify exact lines 
  align(i = 1:nrow(ft_data), j = 1:ncol(ft_data), align = "center") 

print(ft_table)

```

Set font names, sizes and colors
```{r 4.5 demonstration cont.1}
ft_table <- ft_table %>% 
  # main formatting
  fontsize(size = 11) %>%
  font(fontname = "Calibri") %>% # since no i or j are input, change is for all data
  font(fontname = "Roboto", part = "header") %>% #different font for header
  color(color = "white", part = "header") %>%
  bold(part = "header") %>%
  # format last row
  bold(i = nrow(ft_data), j = 1:ncol(ft_data)) %>% #
  italic(i = nrow(ft_data), j = ~Product + Salty + Sweet + Sour + Bitter) %>% # using ~ notation
  color(i =  nrow(ft_data), j = ~Sour, color = "red") %>%
  color(i =  nrow(ft_data), j = ~Sweet, color = "orange") %>%
  # background colors
  bg(bg = "#324C63", part = "header") %>% # a custom background for the header
  bg(i = 1:nrow(ft_data), bg = "#EDEDED") # a custom background for some cells

print(ft_table)
```

Set borders and adjust cells heights and widths
```{r 4.6 demonstration cont.2}
#BORDERS
# For borders we need to use nested functions (similar to fpar>ftext>fp_text)
# fp_border() is the second level function we will use to specify border"s characteristics
# as argument it takes color, style, and width
my_border <- officer::fp_border(color = "black", style = "solid", width = 1)

# We use this second level function inside various main border functions
# border_outer(), border_inner(), border_inner_h(), border_inner_v()
ft_table <- ft_table %>%
  border_outer(part = "all", border = my_border) %>% # using predefined border
  border_inner(part = "body", border = officer::fp_border(style = "dashed")) %>% 

  # all measurements are in inches
  width(j = 1, width = 1.2) %>% # column 1 wider
  height(i = 12, height = 1) # last row's height

print(ft_table)
```


##### Add flextable object to a powerpoint slide

```{r 4.7 original example}
# Add table to slide
pptx_obj <- read_pptx() %>%
  add_slide(layout = "Title and Content", master = "Office Theme") %>%
  ph_with(value = ft_table, ph_location(left = 2, top = 2, width = 4)) %>% 
  print(target = file.path("output","table_2.pptx"))
```

For more details on using **{flextable}** see <https://davidgohel.github.io/flextable/>.

#### Exporting Plots


```{r 5.1 rvg package}
# Using ggplot2 as plotting library
chart_to_plot <- senso_mean %>%
  dplyr::select(Salty, Sweet, Sour, Bitter) %>% 
  tibble::rownames_to_column() %>% 
  rename(Product = rowname) %>%
  pivot_longer(cols = Salty:Bitter, names_to = 'Attribute', values_to = 'Value') %>% 
  ggplot(aes(x = Product, y = Value, fill = Attribute)) + 
  geom_col(position = 'dodge')

print(chart_to_plot) #in Plots window of Rstudio
```

##### rvg package

rvg is providing two graphics devices that produces Vector Graphics outputs in `DrawingML` format for Microsoft PowerPoint with dml_pptx and for Microsoft Excel with dml_xlsx.

```{r 5.2 rvg example}
# body location
library(rvg)

# all items on the chart inside the pptx can be editable
pptx_obj <- read_pptx() %>%
  add_slide(layout = "Title and Content", master = "Office Theme") %>%
  ph_with(value = dml(ggobj = chart_to_plot, editable = TRUE),
          location= ph_location_type(type = 'body')) %>% 
  print(target = file.path("output","rvg_1.pptx"))

#custom location, all units are in inches
pptx_obj <- read_pptx() %>%
  add_slide(layout = "Title and Content", master = "Office Theme") %>%
  ph_with(value = dml(ggobj = chart_to_plot, editable = FALSE),
          location =  ph_location(left = 1, top = 1, width = 8, height = 6))  %>%
  print(target = file.path("output","rvg_2.pptx"))


```

##### mschart package

```{r 5.3 mschart example}
library(mschart)
# sample dataframe
mydata <- senso_mean %>%
  dplyr::select(Salty, Sweet, Sour, Bitter) %>% 
  tibble::rownames_to_column() %>% 
  rename(Product = rowname) %>%
  pivot_longer(cols = Salty:Bitter, names_to = 'Attribute', values_to = 'Value')

# syntaxis is similar to ggplot2's aes() with x,y,group
my_barchart <- ms_barchart(data = mydata,
                           x = "Product",
                           y = "Value",
                           group = "Attribute")

#the chart is a Powerpoint native object and can be viewed using the preview option in print
print(my_barchart, preview = TRUE)
#the command will work on machines with a Powerpoint Viewer

# to add the object to a powerpoint slide we can use the officer's native ph_with
pptx_obj <- read_pptx() %>%
  add_slide(layout = "Title and Content", master = "Office Theme") %>%
  ph_with(value = my_barchart, location = ph_location_type(type = "body")) %>%
  print(target = file.path("output","rvg_2.pptx"))
```

#### Finalizing the Document


<!--  --------------------------------- Word ---------------------------------  -->


### Word

Word documents are created using `read_docx()`. 

`body_add_par()` to add a text paragraph. Paragraphs are automatically separated by line breaks.

```{r 6.1 word doc1}
my_doc <- read_docx() %>% 
  body_add_par(value = "My Text", style = "Normal") %>%
  body_add_par(value = "Other Text", style = "Normal") %>% 
  body_add_par(value = "Conclusion", style = "Normal") %>% 
  print(target = file.path("output","doc_1.docx"))
```

Unlike a pptx with separate slides, a word document is a continuous object. To create a new page and continue to write on it `body_add_break()` is used.

```{r 6.2 word doc2}
my_doc <- read_docx() %>% 
  body_add_par(value = "My Text", style = "Normal") %>%
  body_add_break() %>% 
  body_add_par(value = "Conclusion", style = "Normal") %>% 
  print(target = file.path("output","doc_2.docx"))
```

`body_add_fpar()` to add a formatted text paragraph
`body_add_table()` to add a table

```{r 6.3 word doc3}
my_format <- fp_text(font.family = 'Calibri', font.size = 14, bold = TRUE, color = 'blue')
my_text <- ftext('My dataset is:', my_format)
my_par <- fpar(my_text)

doc <- read_docx() %>% 
  body_add_par(value = "Document Title", style = "heading 1") %>% 
  body_add_par(value = "", style = "Normal") %>% 
  body_add_fpar(my_par, style = "Normal") %>% #formatted paragraph function
  body_add_par(value = "", style = "Normal") %>% 
  body_add_table(value = head(mtcars)[, 1:4], style = "table_template" ) %>% 
  print(target = file.path("output","doc_3.docx"))

```


### Notes on applying corporate branding


You may have noticed that we have been consistent with our approach to export results to reports, regardless of the final output:
We start with pre-defining our styling parameters that we then apply to our different tables, slides, etc. This is not a formal rule, yet we strongly recommend you adopting this way of working. 

If you create your different styling parameters at the start of your script file, these lines of code do not interfere with your analyses. At a later stage, you will thank yourself for keeping well-structured code as it gains in clarity, and hence facilitates debugging your code in case of error or changes.

In fact, we would recommend you going one step further and store all this styling parameters in a separate file that you can  load any time you need using `source()`. This process **reduces** the size of your script file (increasing clarity), while **harmonizing** all your exports by **centralizing** your *formatting code* in one unique place. The last point is particularly important since any changes required, or update made only need to be done once, yet they will be applied to all your reports.


## Integrating analyses scripts within reporting tools

Integrating reporting within the analysis part, or integrating the analysis within the reporting part?
 -> Keep track of what has been done (reproducible research): Explain choices for analysis, table presentation, charts
 -> Sharing code/analysis
To improve way of work (efficiency) and to keep track of steps taken along the way

Rmarkdown










In this section, we review recent advances in automated report production that:

1. Connects our analysis tool to our preferred reporting tool;
2. Liberate resources for scientists to focus on the interpretation and communication of results...
3. ...while simultaneously reducing errors and increasing the consistency of their analyses. 


Through this section, we will show you how to generate directly from R different types of report within the Microsoft Office suit. More precisely, we will start by showing you how to export results to Excel, which we will then extend to PowerPoint, and Word. With this approach, you can then incorporate some code within your analysis script, meaning that as soon as your data change, a new updated report will be generated. 

Details of how to customize the final presentation (PowerPoint) to incorporate corporate branding - such as logos, font choices, and color palettes - is also tackled here.


RMarkdown, HTML output, etc. (mention but donâ€™t focus)
Packages for Microsoft office production
Officer suite (PowerPoint, Word)
Charts, especially RVG
Extract from Word/PowerPoint
Index
Flextable
Images?
Packages for formatting
extrafont
extrafontdb
Rcolorbrewer


## To go further...

Creating dashboards using shiny, that generate the reports as well
Building report and sending them automatically by email to clients/partners
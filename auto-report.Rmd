```{r include=FALSE}
knitr::opts_chunk$set(echo = TRUE, eval = FALSE)
```
# Automated Reporting {#auto-report}

## What and why Automated Reporting?

Effective communication of results is amongst the essential duties of sensory scientists...and so is the data collection, data preparation, data analysis etc. Worst, the sometimes tedious mechanics of report production together with the sheer volume of data that many scientists must process combine to make reporting design and nice story-telling an afterthought in too many cases.
Although this should preferably not be happening, it is necessary sometimes as presentation deadlines approach and time becomes limited. 

Add to this work-load some last-minute changes due to either a change in the data, in the analysis, or maybe an error (e.g. copy/paste the wrong column, etc.) you have just been detected...how can we be sure that the latest version of the report is fully up-to-date, and that all the results/conclusions are correct? As the statistical software (e.g. R) is often separated from the reporting tool (e.g. Microsoft Office), it is easy to miss to transfer updated statistical outputs (e.g. values, tables, figures, etc.) to the report, hence creating inconsistencies.

Let's consider another scenario, in which all the preliminary steps have been successfully done: you are now presenting your report to your manager or clients, and they come with a question such as: "Can we deep-dive into the results by looking at a particular group of consumers (e.g. gender split, or cluster split)?" Do you feel like going through the entire process again?

How would you feel if we would tell you that there is a way to build your report while running the analysis, by using the same script file? This means that in few clicks, say after updating the data to analyze (e.g. filter to the target group of consumers only), your report gets automatically re-generated with all the new updated results. Will you be interesting in such approach?

Such solution seems ideal since it increases efficiency while reducing errors due to manual processing of results. More importantly, this gain in time and effort allow you designing nicer slides and building a better story. 


## Integrating reports within analyses scripts

In this section, let's integrate our report building process within our data analysis. By doing so, we do not focus on building a story yet. Instead, we improve our way of working by exporting directly all the statistical outputs that could^[We say *could* as we are in a process of mass-exportation of results, most of them being used for building the story although they would not be kept in the final deck.] be useful for our future story-telling. By doing so, we increase efficiency (especially if code can then be re-used for other studies) by *killing two birds with one stone*: We simultaneously run our analysis, create usable content for our final presentation, while reducing errors due to manual processing.

Since Microsoft Office is often the tool used for sharing results, we will focus our attention in exporting results to Excel, PowerPoint, and Word. 

<!-- 
Integrating reporting within the analysis part, or integrating the analysis within the reporting part?
 -> Improved WoW
 -> Connection analysis/report reduce risks of mistakes (copy/paste updated values/tables, etc.)
 -> Keep track of what has been done (reproducible research): Explain choices for analysis, table presentation, charts
 -> Sharing code/analysis
 -> Gain in time/efficiency
 -> Massive slide production
 -> Less time require for analysis/slides production, more time for design/story-telling
To improve way of work (efficiency) and to keep track of steps taken along the way
-->

### Excel

Although Excel is not our preferred tool for automated reporting, it is still one of the major ways to access and share data. Most data collection software offer the possibility to export data and results in Excel, while most data analysis software accept Excel format as inputs.  With the large use of Excel, it is no surprise that many of our colleagues or clients like to share data and results using spreadsheets. It is even less a surprise that R provides multiple solutions to import/export results from/to Excel. 

For importing Excel files, we have already presented the package `{readxl}` among others (see REF). For exporting results, two complementary packages (yet again, among others!) in terms of ease of use and flexibility in the outcome are proposed: `{writexl}` and `{openxlsx}`.

As its name suggests, `{writexl}` is dedicated to exporting tables to Excel through the `write_xlsx()` function. Its use is very simple as it only takes as inputs the table (or list of tables)^[List of tables will generate multiple sheets within the same spreadsheet, one table being placed in each sheet.] to export to the file specified in the `path` parameter. 

Let's illustrate this by using our *Sensory Profile.xlsx* file: Let's imagine that we would like to reduce our data set by only considering products that are high in Protein:


```{r}
library(tidyverse)
library(readxl)
library(writexl)
library(dplyr)

file_path <- file.path("data", "Sensory Profile.xlsx")

product_info <- read_excel(path  = file_path,
                           sheet = "Product Info",
                           range = "A1:D12",
                           col_names = TRUE)

# Selecting Products with High Protein
high_prot <- product_info %>% 
  filter(Protein %in% "High") %>% 
  pull(Product)

# Filter Data to only keep Products with High Protein
high_prot_data <- read_xlsx(path = file_path,
                  sheet = "Data") %>% 
  filter(Product %in% high_prot)

# Exporting Table to Excel
write_xlsx(data, 
           path = file.path("output", "High Protein Products only.xlsx"),
           col_names = TRUE)

```

The export of tables using the `{writexl}` package is easy, yet simplistic as it does not allow formatting the tables (except for some minor possibilities for the header), nor does it allow exporting multiple tables within the same sheet. For more advanced exporting options, the use of **{openxlsx}** package is preferred as it allows more flexibility in structuring and formatting the Excel output.

With `{openxlsx}`, the procedure starts with creating a workbook object (e.g. `wb`) using the `createWorkbook()` function. We can add worksheets to `wb` through the `addWorksheet()` function. 

```{r}
library(openxlsx)

# Create workbook object
wb <- openxlsx::createWorkbook()

# Add a new worksheet
addWorksheet(wb, sheetName = "Mean", gridLines = FALSE)

```


Note that `addWorksheet()` allows controlling further the appearance of the worksheet:
  * show/hide grid lines using `gridLines`;
  * color the sheet using `tabColour`;
  * change the zoom on the sheet through `zoom`;
  * show/hide the tab using `visible`;
  * format the worksheet by specifying its size (`paperSize`) and orientation (`orientation`).

On a given worksheet, any table can be exported using `writeData()` or `writeDataTable()`, which controls where to write the table through the `startRow` and `startCol` options.

Let's imagine we want to compute the sensory profiles of the products, and we want to export that into Excel. Rather then simply exporting the results, we want to customize the output a little bit by applying the Excel style named *TabelStyleLight9*:


```{r}

# Creating the Sensory Profiles with some Product Information
p_info <- read_xlsx(file_path, sheet = "Product Info") %>% 
  dplyr::select(-Type)

sensory <- read_xlsx(file_path, sheet="Data") %>% 
  inner_join(p_info, by="Product") %>% 
  relocate(Protein:Fiber, .after=Product)

senso_mean <- sensory %>% 
  pivot_longer(Shiny:Melting, names_to="Attribute", values_to="Score") %>% 
  dplyr::select(-Judge) %>% 
  pivot_wider(names_from=Attribute, values_from=Score, values_fn=mean)


# Exporting the Results to Excel
writeDataTable(wb,
               sheet = "Mean",
               x = senso_mean, 
               startCol = 1,
               startRow = 1,
               colNames = TRUE, rowNames = FALSE, 
               tableStyle = "TableStyleLight9")

```

Here again, `writeData()` and `writeDataTable()` gives us a lot of control on our export. For instance, we can:
  * control where to print the data by using `startRow` and `startCol` (or alternatively `xy`: `xy = c("B",12)` prints the table starting in cell B12), hence allowing exporting multiple tables within the same sheet;
  * include the row names and column names through `rowNames` and `colNames`;
  * format the header using `headerStyle` (incl. color of the text and/or background, font, font size, etc.);
  * apply a specific style to our table using `tableStyle`;
  * shape the borders using predefined solutions through `borders`, or customizing them with `borderStyle` and `borderColour`;
  * add a filter to the table using `withFilter`;
  * convert missing data to "#N/A" or any other string using `keepNA` and `na.string`.
  
- Additional formatting can be controlled using:
  * `options()` to pre-define number formatting, border colors and style that will be applied automatically to each table;
  * `modifyBaseFont()` to define the font name and font size;
  * `freezePane()` to freeze the first row and/or column of the table using `firstRow = TRUE` and `firstCol = TRUE`;
  * `createStyle()` to pre-define a style, or `addStyle()` to apply the styling to selected cells;
  * `setColWidths` to control column width;
  * `conditionalFormatting()` styling of cells when they meet pre-defined rules, as for instance to highlight significant p-values. 
  
When using `{openxlsx}`, we recommend to following procedure (same will apply for PowerPoint and Word): 

- Start with setting the default parameters that should be applied to each table;
- Create styles for text or table headers that you save in different elements, and that you apply where needed. 

For illustration, let's consider *Sensory Profile.xlsx*. More precisely, we want to export the sensory profiles into a newly create Excel spreadsheet.


```{r}
p_info <- read_xlsx(file_path, sheet = "Product Info") %>% 
  dplyr::select(-Type)

sensory <- read_xlsx(file_path, sheet="Data") %>% 
  inner_join(p_info, by="Product") %>% 
  relocate(Protein:Fiber, .after=Product)

senso_mean <- sensory %>% 
  pivot_longer(Shiny:Melting, names_to="Attribute", values_to="Score") %>% 
  dplyr::select(-Judge) %>% 
  pivot_wider(names_from=Attribute, values_from=Score, values_fn=mean)

```


To introduce conditional formatting with `{openxlsx}`, the sensory profiles are color coded as following: for each cell, the value is compared to the overall mean computed for that column and is colored in red (resp. blue) if it's higher (resp. lower) than the mean.
In practice, the color style is pre-defined in two parameters called `pos_style` (red) and `neg_style` (blue) using `createStyle()`. The decision whether `pos_style` or `neg_style` should be used is defined by the `rule` parameter from the `conditionalFormatting()`^[In `conditionalFormatting()`, you can specify to which `rows` and `cols` the formatting applies. In this example, `cols` takes `2` because the first column contains the row names.] function.


```{r openxlsx}
library(openxlsx)

# Pre-define options to control the borders 
options("openxlsx.borderColour" = "#4F80BD")
options("openxlsx.borderStyle" = "thin")

# Automatically set Number formats to 3 values after the decimal
options("openxlsx.numFmt" = "0.000")

# Create a header style in which 
  # a blue background is used,
  # borders on top and on the bottom, 
  # the text is centered and is bold

headSty <- createStyle(fgFill = "#DCE6F1",
                       border = "TopBottom",
                       halign = "center",
                       textDecoration = "bold")

# Data preparation
senso_mean <- sensory %>% 
  group_by(Product) %>% 
  summarise(across(where(is.numeric), mean)) %>% 
  tibble::column_to_rownames(var = "Product")

overall_mean <- apply(senso_mean, 2, mean)

# Create workbook object
wb <- openxlsx::createWorkbook()

# Change the font to Calibri size 10
modifyBaseFont(wb,fontName = "Calibri", fontSize = 10)

# Add a new worksheet
addWorksheet(wb, sheetName = "Mean", gridLines = FALSE)

# Write table: note that 
writeDataTable(wb,
               sheet = "Mean",
               x = senso_mean, 
               startCol = 1,
               startRow = 1,
               colNames = TRUE, rowNames = TRUE, 
               tableStyle = "TableStyleLight9")

# Freezing the table
freezePane(wb, sheet = "Mean", firstRow = TRUE, firstCol = TRUE)

# Styles for conditional formatting
pos_style <- createStyle(fontColour = "firebrick3", bgFill = "mistyrose1")
neg_style <- createStyle(fontColour = "navy", bgFill = "lightsteelblue")

# Adding formatting to the second column
conditionalFormatting(wb,
                      sheet = "Mean", 
                      cols  = 2,
                      rows  = 1 + 1:nrow(senso_mean), 
                      rule  = paste0(">",overall_mean[2]),
                      style = pos_style)

conditionalFormatting(wb,
                      sheet = "Mean",
                      cols  = 2,
                      rows  = 1 + 1:nrow(senso_mean), 
                      rule  = paste0("<",overall_mean[2]),
                      style = neg_style)

setColWidths(wb, sheet = "Mean",
             cols = 1:(1+ncol(senso_mean)), widths = 12)

```


The file is created using `saveWorkbook()` by specifying the name of the workbook `wb` and its path through `file`. In case such workbook already exists, it can be overwritten using `overwrite`. 

TIPS: At any time, you can visualize your file using `openXL()`: This function opens within Excel the temporary file that is currently being built, hence allowing you to double-check that your code matches your expectations.

For more details on using **{openxlsx}** see <https://rdrr.io/cran/openxlsx/>.

### PowerPoint

```{r}
library(tidyverse)
library(officer)
library(flextable)
```

With `{officer}`, the procedure starts with creating a powerpoint object `pptx_obj` using the `read_pptx()` function, to which we add slides through the `add_slide()` function. 
On a given worksheet, any type of content (text, graph, table) can be exported using `ph_with()` (ph ~ placeholder) which controls where to write the content through the `location` and `ph_location` options.

Through these different functions, many additional formatting procedure can be applied.

- `add_slide()` with arguments:
  * `layout` type of slide;
  * `master` theme of the deck;
  


#### Creating a PowerPoint Deck

**Key functions:**
`read_pptx(path)` `add_slide(x, layout, master)` `layout_summary(x)` 

```{r 1.1 creating a PPT deck}
pptx_obj <- read_pptx() # new empty file
pptx_obj <- pptx_obj %>% 
  add_slide(layout  = 'Title and Content', master = "Office Theme")

class(pptx_obj)

pptx_obj %>%
  layout_summary()

pptx_obj %>% 
  print(target = file.path("output","example_1.pptx"))
```

#### PowerPoint Themes

A blank Deck is by default set up with the *Office Theme*. To use a custom theme, we must create a Deck using the Powerpoint software and use it as input.

Loading a template with a custom theme
```{r themes2}
pptx_obj <- read_pptx(file.path("data", "templates", "intergral.pptx"))

pptx_obj %>% 
  layout_summary()

pptx_obj <- pptx_obj %>% # add slide
  add_slide(layout = "Title and Content", master = "Integral")

```


#### Placeholders and Shapes

- `ph_location_type()` allows use predefined placeholders for content:
  * title, body
  * ctrTitle, subTitle, dt, ftr, sldNum

```{r 2.1 shapes1}
# Example 1
my_data <- c("My functions are:", "ph_with", "ph_location_type")

# first slide
pptx_obj <- read_pptx() %>%
  add_slide(layout = "Title and Content", master = "Office Theme")

pptx_obj <- pptx_obj %>%
  ph_with(value = my_data, location = ph_location_type(type = 'body'))

pptx_obj <- pptx_obj %>% 
  on_slide(index = 1) # set active slide

slide_summary(pptx_obj) # technical content summary

my_data <- head(mtcars)[,1:4]

# second slide
pptx_obj <- pptx_obj %>% 
    add_slide(layout = "Title and Content", master = "Office Theme")

pptx_obj <- pptx_obj %>% 
  ph_with(value = my_data, location = ph_location_type(type = 'body')) 

pptx_obj %>%
  print(target = file.path("output","example_2.pptx"))

```

- `ph_location()` allows to specify exact positions for content
  * for left/top/width/height units are inches

```{r 2.3 shapes3}
# Example 3
# We add a text box item in a custom position
# The same can be done for an image, logo, custom objects, etc.

my_data <- "My text"

pptx_obj <- read_pptx() %>%
  add_slide(layout = "Title and Content", master = "Office Theme")

pptx_obj <- pptx_obj %>%
  ph_with(value = my_data, location = ph_location(left = 2, top = 2, width = 3, height = 1))

pptx_obj %>%
  print(target = file.path("output","example_3.pptx"))
```

#### Working with Text

Each new text item added to a PowerPoint via officer is a paragraph object

`fpar()` ("formatted paragraph") creates this object

`block_list()` allows us to wrap multiple paragraphs together

`ftext()` ("formatted text") to edit the text before pasting into paragraphs. `ftext()` requires a second argument called prop which contains the formatting properties.

```{r 3.1 text1}

my_prop <- fp_text(color = "red", font.size = 14)
my_text <- ftext("First Line in Red", prop = my_prop)

my_par <- fpar(my_text) # formatted
blank_line <- fpar("") #optional

my_par2 <- fpar("Second Line") # unformatted
my_list <- block_list(my_par, blank_line, my_par2)

pptx_obj <- read_pptx() %>%
  add_slide(layout = "Title and Content", master = "Office Theme") %>% 
  ph_with(value = my_list, location = ph_location_type(type = "body") )

pptx_obj %>%
  print(target = file.path("output","example_4.pptx"))
```

For more details on using **{officer}** see <https://davidgohel.github.io/officer>.


### Tables

`ph_with` accepts a data.frame as value and renders it in a default format

```{r 4.1 basic code}
ft_data <- senso_mean %>%
  dplyr::select(Salty, Sweet, Sour, Bitter) %>% 
  tibble::rownames_to_column() %>% 
  rename(Product = rowname) %>% 
  mutate(across(Salty:Bitter, as.numeric)) %>% 
  bind_rows(summarise(.,
                      across(where(is.numeric), mean),
                      across(where(is.character), ~"Average"))) %>% 
  mutate(across(where(is.numeric), round, 2)) 

pptx_obj <- read_pptx() %>%
  add_slide(layout = "Title and Content", master = "Office Theme") %>%
  ph_with(value = ft_data, location = ph_location_type(type = "body")) %>%
  print(target = file.path("output","table_1.pptx"))
```

#### Introduction to flextable

With `{flextable}`, the procedure starts with creating a flextable object `ft_table` using the `flextable()` function.
Flextable objects are compatible with `{officer}` and therefore are our primary tool for table formatting.
Through different functions, many custom formatting procedure can be applied:  

**key functions:**
 `align()` `bold()` `font()` `color()` `bg()` `height()` & `width()` 
 `border_outer()` & `border_inner()` & `border_inner_h()` `border_inner_v()` `autofit()`

Additional function to learn: `merge()`, `compose()` & `as_chunk()`, `style()`

```{r flextable2}
library(flextable)

# Create a flextable object
ft_table <- ft_data %>% 
  flextable()

# Flextable objects can be found in the Viewer tab of Rstudio
print(ft_table)

```

#### Formatting examples

```{r 4.4 demonstration}
ft_table <- ft_table %>%
  autofit() %>% # column width
  # alignment of header: we use part argument
  align(align = "center", part = "header") %>%
  # alignment of content: we can use part = "body" or specify exact lines 
  align(i = 1:nrow(ft_data), j = 1:ncol(ft_data), align = "center") 

print(ft_table)

```

Set font names, sizes and colors
```{r 4.5 demonstration cont.1}
ft_table <- ft_table %>% 
  # main formatting
  fontsize(size = 11) %>%
  font(fontname = "Calibri") %>% # since no i or j are input, change is for all data
  font(fontname = "Roboto", part = "header") %>% #different font for header
  color(color = "white", part = "header") %>%
  bold(part = "header") %>%
  # format last row
  bold(i = nrow(ft_data), j = 1:ncol(ft_data)) %>% #
  italic(i = nrow(ft_data), j = ~Product + Salty + Sweet + Sour + Bitter) %>% # using ~ notation
  color(i =  nrow(ft_data), j = ~Sour, color = "red") %>%
  color(i =  nrow(ft_data), j = ~Sweet, color = "orange") %>%
  # background colors
  bg(bg = "#324C63", part = "header") %>% # a custom background for the header
  bg(i = 1:nrow(ft_data), bg = "#EDEDED") # a custom background for some cells

print(ft_table)
```

Set borders and adjust cells heights and widths
```{r 4.6 demonstration cont.2}
#BORDERS
# For borders we need to use nested functions (similar to fpar>ftext>fp_text)
# fp_border() is the second level function we will use to specify border"s characteristics
# as argument it takes color, style, and width
my_border <- officer::fp_border(color = "black", style = "solid", width = 1)

# We use this second level function inside various main border functions
# border_outer(), border_inner(), border_inner_h(), border_inner_v()
ft_table <- ft_table %>%
  border_outer(part = "all", border = my_border) %>% # using predefined border
  border_inner(part = "body", border = officer::fp_border(style = "dashed")) %>% 

  # all measurements are in inches
  width(j = 1, width = 1.2) %>% # column 1 wider
  height(i = 12, height = 1) # last row's height

print(ft_table)
```


#### Add flextable object to a powerpoint slide

```{r 4.7 original example}
# Add table to slide
pptx_obj <- read_pptx() %>%
  add_slide(layout = "Title and Content", master = "Office Theme") %>%
  ph_with(value = ft_table, ph_location(left = 2, top = 2, width = 4)) %>% 
  print(target = file.path("output","table_2.pptx"))
```

For more details on using **{flextable}** see <https://davidgohel.github.io/flextable/>.

### Charts

#### Adding charts as images

```{r 5.1 rvg package}
# Using ggplot2 as plotting library
chart_to_plot <- senso_mean %>%
  dplyr::select(Salty, Sweet, Sour, Bitter) %>% 
  tibble::rownames_to_column() %>% 
  rename(Product = rowname) %>%
  pivot_longer(cols = Salty:Bitter, names_to = 'Attribute', values_to = 'Value') %>% 
  ggplot(aes(x = Product, y = Value, fill = Attribute)) + 
  geom_col(position = 'dodge')

print(chart_to_plot) #in Plots window of Rstudio
```

#### rvg package

rvg is providing two graphics devices that produces Vector Graphics outputs in `DrawingML` format for Microsoft PowerPoint with dml_pptx and for Microsoft Excel with dml_xlsx.

```{r 5.2 rvg example}
# body location
library(rvg)

# all items on the chart inside the pptx can be editable
pptx_obj <- read_pptx() %>%
  add_slide(layout = "Title and Content", master = "Office Theme") %>%
  ph_with(value = dml(ggobj = chart_to_plot, editable = TRUE),
          location= ph_location_type(type = 'body')) %>% 
  print(target = file.path("output","rvg_1.pptx"))

#custom location, all units are in inches
pptx_obj <- read_pptx() %>%
  add_slide(layout = "Title and Content", master = "Office Theme") %>%
  ph_with(value = dml(ggobj = chart_to_plot, editable = FALSE),
          location =  ph_location(left = 1, top = 1, width = 8, height = 6))  %>%
  print(target = file.path("output","rvg_2.pptx"))


```

#### mschart package

```{r 5.3 mschart example}
library(mschart)
# sample dataframe
mydata <- senso_mean %>%
  dplyr::select(Salty, Sweet, Sour, Bitter) %>% 
  tibble::rownames_to_column() %>% 
  rename(Product = rowname) %>%
  pivot_longer(cols = Salty:Bitter, names_to = 'Attribute', values_to = 'Value')

# syntaxis is similar to ggplot2's aes() with x,y,group
my_barchart <- ms_barchart(data = mydata,
                           x = "Product",
                           y = "Value",
                           group = "Attribute")

#the chart is a Powerpoint native object and can be viewed using the preview option in print
print(my_barchart, preview = TRUE)
#the command will work on machines with a Powerpoint Viewer

# to add the object to a powerpoint slide we can use the officer's native ph_with
pptx_obj <- read_pptx() %>%
  add_slide(layout = "Title and Content", master = "Office Theme") %>%
  ph_with(value = my_barchart, location = ph_location_type(type = "body")) %>%
  print(target = file.path("output","rvg_2.pptx"))
```

### Word

Word documents are created using `read_docx()`. 

`body_add_par()` to add a text paragraph. Paragraphs are automatically separated by line breaks.

```{r 6.1 word doc1}
my_doc <- read_docx() %>% 
  body_add_par(value = "My Text", style = "Normal") %>%
  body_add_par(value = "Other Text", style = "Normal") %>% 
  body_add_par(value = "Conclusion", style = "Normal") %>% 
  print(target = file.path("output","doc_1.docx"))
```

Unlike a pptx with separate slides, a word document is a continuous object. To create a new page and continue to write on it `body_add_break()` is used.

```{r 6.2 word doc2}
my_doc <- read_docx() %>% 
  body_add_par(value = "My Text", style = "Normal") %>%
  body_add_break() %>% 
  body_add_par(value = "Conclusion", style = "Normal") %>% 
  print(target = file.path("output","doc_2.docx"))
```

`body_add_fpar()` to add a formatted text paragraph
`body_add_table()` to add a table

```{r 6.3 word doc3}
my_format <- fp_text(font.family = 'Calibri', font.size = 14, bold = TRUE, color = 'blue')
my_text <- ftext('My dataset is:', my_format)
my_par <- fpar(my_text)

doc <- read_docx() %>% 
  body_add_par(value = "Document Title", style = "heading 1") %>% 
  body_add_par(value = "", style = "Normal") %>% 
  body_add_fpar(my_par, style = "Normal") %>% #formatted paragraph function
  body_add_par(value = "", style = "Normal") %>% 
  body_add_table(value = head(mtcars)[, 1:4], style = "table_template" ) %>% 
  print(target = file.path("output","doc_3.docx"))

```


### Notes on applying corporate branding

Pre-define parameters/options (fonts, logos, etc.) in a separate file that you can source at the start and call easily.
Import company templates (PowerPoint, Word) that already includes pre-defined options.



## Integrating analyses scripts within reporting tools

Integrating reporting within the analysis part, or integrating the analysis within the reporting part?
 -> Keep track of what has been done (reproducible research): Explain choices for analysis, table presentation, charts
 -> Sharing code/analysis
To improve way of work (efficiency) and to keep track of steps taken along the way

Rmarkdown










In this section, we review recent advances in automated report production that:

1. Connects our analysis tool to our preferred reporting tool;
2. Liberate resources for scientists to focus on the interpretation and communication of results...
3. ...while simultaneously reducing errors and increasing the consistency of their analyses. 


Through this section, we will show you how to generate directly from R different types of report within the Microsoft Office suit. More precisely, we will start by showing you how to export results to Excel, which we will then extend to PowerPoint, and Word. With this approach, you can then incorporate some code within your analysis script, meaning that as soon as your data change, a new updated report will be generated. 

Details of how to customize the final presentation (PowerPoint) to incorporate corporate branding - such as logos, font choices, and color palettes - is also tackled here.


RMarkdown, HTML output, etc. (mention but donâ€™t focus)
Packages for Microsoft office production
Officer suite (PowerPoint, Word)
Charts, especially RVG
Extract from Word/PowerPoint
Index
Flextable
Images?
Packages for formatting
extrafont
extrafontdb
Rcolorbrewer
